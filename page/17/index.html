<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
  <meta name="theme-color" content="#222">
  <meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>
  <script id="hexo-configurations">
    var NexT = window.NexT ||
    {};
    var CONFIG = {
      "hostname": "cuiqingcai.com",
      "root": "/",
      "scheme": "Pisces",
      "version": "7.8.0",
      "exturl": false,
      "sidebar":
      {
        "position": "right",
        "width": 360,
        "display": "post",
        "padding": 18,
        "offset": 12,
        "onmobile": false,
        "widgets": [
          {
            "type": "image",
            "name": "阿布云",
            "enable": true,
            "url": "https://www.abuyun.com/http-proxy/introduce.html",
            "src": "https://qiniu.cuiqingcai.com/88au8.jpg",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "天验",
            "enable": true,
            "url": "https://tutorial.lengyue.video/?coupon=12ef4b1a-a3db-11ea-bb37-0242ac130002_cqx_850",
            "src": "https://qiniu.cuiqingcai.com/bco2a.png",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "华为云",
            "enable": false,
            "url": "https://activity.huaweicloud.com/2020_618_promotion/index.html?bpName=5f9f98a29e2c40b780c1793086f29fe2&bindType=1&salesID=wangyubei",
            "src": "https://qiniu.cuiqingcai.com/y42ik.jpg",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "张小鸡",
            "enable": false,
            "url": "http://www.zxiaoji.com/",
            "src": "https://qiniu.cuiqingcai.com/fm72f.png",
            "width": "100%"
      },
          {
            "type": "image",
            "name": "Luminati",
            "src": "https://qiniu.cuiqingcai.com/ikkq9.jpg",
            "url": "https://luminati-china.io/?affiliate=ref_5fbbaaa9647883f5c6f77095",
            "width": "100%",
            "enable": true
      },
          {
            "type": "tags",
            "name": "标签云",
            "enable": true
      },
          {
            "type": "categories",
            "name": "分类",
            "enable": true
      },
          {
            "type": "friends",
            "name": "友情链接",
            "enable": true
      },
          {
            "type": "hot",
            "name": "猜你喜欢",
            "enable": true
      }]
      },
      "copycode":
      {
        "enable": true,
        "show_result": true,
        "style": "mac"
      },
      "back2top":
      {
        "enable": true,
        "sidebar": false,
        "scrollpercent": true
      },
      "bookmark":
      {
        "enable": false,
        "color": "#222",
        "save": "auto"
      },
      "fancybox": false,
      "mediumzoom": false,
      "lazyload": false,
      "pangu": true,
      "comments":
      {
        "style": "tabs",
        "active": "gitalk",
        "storage": true,
        "lazyload": false,
        "nav": null,
        "activeClass": "gitalk"
      },
      "algolia":
      {
        "hits":
        {
          "per_page": 10
        },
        "labels":
        {
          "input_placeholder": "Search for Posts",
          "hits_empty": "We didn't find any results for the search: ${query}",
          "hits_stats": "${hits} results found in ${time} ms"
        }
      },
      "localsearch":
      {
        "enable": true,
        "trigger": "auto",
        "top_n_per_article": 10,
        "unescape": false,
        "preload": false
      },
      "motion":
      {
        "enable": false,
        "async": false,
        "transition":
        {
          "post_block": "bounceDownIn",
          "post_header": "slideDownIn",
          "post_body": "slideDownIn",
          "coll_header": "slideLeftIn",
          "sidebar": "slideUpIn"
        }
      },
      "path": "search.xml"
    };

  </script>
  <meta name="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
  <meta property="og:type" content="website">
  <meta property="og:title" content="静觅">
  <meta property="og:url" content="https://cuiqingcai.com/page/17/index.html">
  <meta property="og:site_name" content="静觅">
  <meta property="og:description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
  <meta property="og:locale" content="zh_CN">
  <meta property="article:author" content="崔庆才">
  <meta property="article:tag" content="崔庆才">
  <meta property="article:tag" content="静觅">
  <meta property="article:tag" content="PHP">
  <meta property="article:tag" content="Java">
  <meta property="article:tag" content="Python">
  <meta property="article:tag" content="Spider">
  <meta property="article:tag" content="爬虫">
  <meta property="article:tag" content="Web">
  <meta property="article:tag" content="Kubernetes">
  <meta property="article:tag" content="深度学习">
  <meta property="article:tag" content="机器学习">
  <meta property="article:tag" content="数据分析">
  <meta property="article:tag" content="网络">
  <meta property="article:tag" content="IT">
  <meta property="article:tag" content="技术">
  <meta property="article:tag" content="博客">
  <meta name="twitter:card" content="summary">
  <link rel="canonical" href="https://cuiqingcai.com/page/17/">
  <script id="page-configurations">
    // https://hexo.io/docs/variables.html
    CONFIG.page = {
      sidebar: "",
      isHome: true,
      isPost: false,
      lang: 'zh-CN'
    };

  </script>
  <title>静觅丨崔庆才的个人站点</title>
  <meta name="google-site-verification" content="p_bIcnvirkFzG2dYKuNDivKD8-STet5W7D-01woA2fc" />
  <noscript>
    <style>
      .use-motion .brand,
      .use-motion .menu-item,
      .sidebar-inner,
      .use-motion .post-block,
      .use-motion .pagination,
      .use-motion .comments,
      .use-motion .post-header,
      .use-motion .post-body,
      .use-motion .collection-header
      {
        opacity: initial;
      }

      .use-motion .site-title,
      .use-motion .site-subtitle
      {
        opacity: initial;
        top: initial;
      }

      .use-motion .logo-line-before i
      {
        left: initial;
      }

      .use-motion .logo-line-after i
      {
        right: initial;
      }

    </style>
  </noscript>
  <link rel="alternate" href="/atom.xml" title="静觅" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner">
        <div class="site-brand-container">
          <div class="site-nav-toggle">
            <div class="toggle" aria-label="切换导航栏">
              <span class="toggle-line toggle-line-first"></span>
              <span class="toggle-line toggle-line-middle"></span>
              <span class="toggle-line toggle-line-last"></span>
            </div>
          </div>
          <div class="site-meta">
            <a href="/" class="brand" rel="start">
              <span class="logo-line-before"><i></i></span>
              <h1 class="site-title">静觅 <span class="site-subtitle"> 崔庆才的个人站点 </span>
              </h1>
              <span class="logo-line-after"><i></i></span>
            </a>
          </div>
          <div class="site-nav-right">
            <div class="toggle popup-trigger">
              <i class="fa fa-search fa-fw fa-lg"></i>
            </div>
          </div>
        </div>
        <nav class="site-nav">
          <ul id="menu" class="main-menu menu">
            <li class="menu-item menu-item-home">
              <a href="/" rel="section">首页</a>
            </li>
            <li class="menu-item menu-item-archives">
              <a href="/archives/" rel="section">文章列表</a>
            </li>
            <li class="menu-item menu-item-tags">
              <a href="/tags/" rel="section">文章标签</a>
            </li>
            <li class="menu-item menu-item-categories">
              <a href="/categories/" rel="section">文章分类</a>
            </li>
            <li class="menu-item menu-item-about">
              <a href="/about/" rel="section">关于博主</a>
            </li>
            <li class="menu-item menu-item-message">
              <a href="/message/" rel="section">给我留言</a>
            </li>
            <li class="menu-item menu-item-search">
              <a role="button" class="popup-trigger">搜索 </a>
            </li>
          </ul>
        </nav>
        <div class="search-pop-overlay">
          <div class="popup search-popup">
            <div class="search-header">
              <span class="search-icon">
                <i class="fa fa-search"></i>
              </span>
              <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input">
              </div>
              <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
              </span>
            </div>
            <div id="search-result">
              <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>
    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
      <span>0%</span>
    </div>
    <div class="reading-progress-bar"></div>
    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div class="content index posts-expand">
            <div class="carousel">
              <div id="wowslider-container">
                <div class="ws_images">
                  <ul>
                    <li><a target="_blank" href="https://cuiqingcai.com/5052.html"><img title="Python3网络爬虫开发实战教程" src="https://qiniu.cuiqingcai.com/ipy96.jpg" /></a></li>
                    <li><a target="_blank" href="https://t.lagou.com/fRCBRsRCSN6FA"><img title="52讲轻松搞定网络爬虫" src="https://qiniu.cuiqingcai.com/fqq5e.png" /></a></li>
                    <li><a target="_blank" href="https://cuiqingcai.com/4320.html"><img title="Python3网络爬虫开发视频教程" src="https://qiniu.cuiqingcai.com/bjrny.jpg" /></a></li>
                    <li><a target="_blank" href="https://cuiqingcai.com/1052.html"><img title="Python2爬虫学习系列教程" src="https://qiniu.cuiqingcai.com/uyl5v.jpg" /></a></li>
                    <li><a target="_blank" href="https://cuiqingcai.com/5094.html"><img title="爬虫代理哪家强？十大付费代理详细对比评测出炉！" src="https://qiniu.cuiqingcai.com/nifs6.jpg" /></a></li>
                  </ul>
                </div>
                <div class="ws_thumbs">
                  <div>
                    <a target="_blank" href="#"><img src="https://qiniu.cuiqingcai.com/ipy96.jpg" /></a>
                    <a target="_blank" href="#"><img src="https://qiniu.cuiqingcai.com/fqq5e.png" /></a>
                    <a target="_blank" href="#"><img src="https://qiniu.cuiqingcai.com/bjrny.jpg" /></a>
                    <a target="_blank" href="#"><img src="https://qiniu.cuiqingcai.com/uyl5v.jpg" /></a>
                    <a target="_blank" href="#"><img src="https://qiniu.cuiqingcai.com/nifs6.jpg" /></a>
                  </div>
                </div>
                <div class="ws_shadow"></div>
              </div>
            </div>
            <link rel="stylesheet" href="/lib/wowslide/slide.css">
            <script src="/lib/wowslide/jquery.min.js"></script>
            <script src="/lib/wowslide/slider.js"></script>
            <script>
              jQuery("#wowslider-container").wowSlider(
              {
                effect: "cube",
                prev: "",
                next: "",
                duration: 20 * 100,
                delay: 20 * 100,
                width: 716,
                height: 297,
                autoPlay: true,
                playPause: true,
                stopOnHover: false,
                loop: false,
                bullets: 0,
                caption: true,
                captionEffect: "slide",
                controls: true,
                onBeforeStep: 0,
                images: 0
              });

            </script>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4791.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4791.html" class="post-title-link" itemprop="url">轻型爬虫框架</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h1 id="大家好，我是四毛-不是崔老师。"><a href="#大家好，我是四毛-不是崔老师。" class="headerlink" title="大家好，我是四毛,  不是崔老师。"></a>大家好，我是四毛, 不是崔老师。</h1>
                  <h1 id="恩，今天的内容很短-主要都写在了README-md里面。"><a href="#恩，今天的内容很短-主要都写在了README-md里面。" class="headerlink" title="恩，今天的内容很短, 主要都写在了README.md里面。"></a>恩，今天的内容很短, 主要都写在了README.md里面。</h1>
                  <p> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a> </p>
                  <h3 id="写了一个将爬虫基本步骤都封装起来的小框架，地址在https-github-com-xiaosimao-AiSpider，-欢迎Star。"><a href="#写了一个将爬虫基本步骤都封装起来的小框架，地址在https-github-com-xiaosimao-AiSpider，-欢迎Star。" class="headerlink" title="写了一个将爬虫基本步骤都封装起来的小框架，地址在https://github.com/xiaosimao/AiSpider， 欢迎Star。"></a><strong>写了一个将爬虫基本步骤都封装起来的小框架，地址在<a href="https://github.com/xiaosimao/AiSpider" target="_blank" rel="noopener">https://github.com/xiaosimao/AiSpider</a>， 欢迎Star。</strong></h3>
                  <h3 id="写的很基础，很简单，大道至简（对，其实就是不会写）。"><a href="#写的很基础，很简单，大道至简（对，其实就是不会写）。" class="headerlink" title="写的很基础，很简单，大道至简（对，其实就是不会写）。"></a><strong>写的很基础，很简单，大道至简（对，其实就是不会写）。</strong></h3>
                  <p><strong>最近也在学一些设计模式的东西。</strong></p>
                  <h3 id="欢迎有兴趣的同学共同研究，readme-md中有我的微信（加的时候麻烦注明一下来自静觅），提出存在的问题和你的想法，这样大家可以共同讨论，共同进步。"><a href="#欢迎有兴趣的同学共同研究，readme-md中有我的微信（加的时候麻烦注明一下来自静觅），提出存在的问题和你的想法，这样大家可以共同讨论，共同进步。" class="headerlink" title="欢迎有兴趣的同学共同研究，readme.md中有我的微信（加的时候麻烦注明一下来自静觅），提出存在的问题和你的想法，这样大家可以共同讨论，共同进步。"></a><strong>欢迎有兴趣的同学共同研究，readme.md中有我的微信（加的时候麻烦注明一下来自静觅），提出存在的问题和你的想法，这样大家可以共同讨论，共同进步。</strong></h3>
                  <h1 id="BE-A-SPIDERMAN。"><a href="#BE-A-SPIDERMAN。" class="headerlink" title="BE A SPIDERMAN。"></a><em><strong>BE A SPIDERMAN。</strong></em></h1>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/四毛" class="author" itemprop="url" rel="index">四毛</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-09-12 17:02:38" itemprop="dateCreated datePublished" datetime="2017-09-12T17:02:38+08:00">2017-09-12</time>
                </span>
                <span id="/4791.html" class="post-meta-item leancloud_visitors" data-flag-title="轻型爬虫框架" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>240</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4778.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4778.html" class="post-title-link" itemprop="url">Neo4j简介及Py2Neo的用法</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>Neo4j是一个世界领先的开源图形数据库，由 Java 编写。图形数据库也就意味着它的数据并非保存在表或集合中，而是保存为节点以及节点之间的关系。 Neo4j 的数据由下面几部分构成：</p>
                  <ul>
                    <li>节点</li>
                    <li>边</li>
                    <li>属性</li>
                  </ul>
                  <p>Neo4j 除了顶点（Node）和边（Relationship），还有一种重要的部分——属性。无论是顶点还是边，都可以有任意多的属性。属性的存放类似于一个 HashMap，Key 为一个字符串，而 Value 必须是基本类型或者是基本类型数组。 在Neo4j中，节点以及边都能够包含保存值的属性，此外：</p>
                  <ul>
                    <li>可以为节点设置零或多个标签（例如 Author 或 Book）</li>
                    <li>每个关系都对应一种类型（例如 WROTE 或 FRIEND_OF）</li>
                    <li>关系总是从一个节点指向另一个节点（但可以在不考虑指向性的情况下进行查询）</li>
                  </ul>
                  <p>具体介绍可以参考：<a href="https://www.w3cschool.cn/neo4j" target="_blank" rel="noopener">https://www.w3cschool.cn/neo4j</a>。</p>
                  <h2 id="Neo4j的特点"><a href="#Neo4j的特点" class="headerlink" title="Neo4j的特点"></a>Neo4j的特点</h2>
                  <ul>
                    <li>它拥有简单的查询语言 Neo4j CQL</li>
                    <li>它遵循属性图数据模型</li>
                    <li>它通过使用 Apache Lucence 支持索引</li>
                    <li>它支持 UNIQUE 约束</li>
                    <li>它包含一个用于执行 CQL 命令的 UI：Neo4j 数据浏览器</li>
                    <li>它支持完整的 ACID（原子性，一致性，隔离性和持久性）规则</li>
                    <li>它采用原生图形库与本地 GPE（图形处理引擎）</li>
                    <li>它支持查询的数据导出到 Json 和 XLS 格式</li>
                    <li>它提供了 REST API，可以被任何编程语言（如 Java，Spring，Scala 等）访问</li>
                    <li>它提供了可以通过任何 UI MVC 框架（如 Node JS ）访问的 Java 脚本</li>
                    <li>它支持两种 Java API：Cypher API 和 Native Java API 来开发 Java 应用程序</li>
                  </ul>
                  <h2 id="Neo4j安装"><a href="#Neo4j安装" class="headerlink" title="Neo4j安装"></a>Neo4j安装</h2>
                  <p>可以到官网直接下载安装包安装即可，链接：<a href="https://neo4j.com/download/" target="_blank" rel="noopener">https://neo4j.com/download/</a>。</p>
                  <h2 id="Neo4j-CQL命令"><a href="#Neo4j-CQL命令" class="headerlink" title="Neo4j CQL命令"></a>Neo4j CQL命令</h2>
                  <p>Neo4j 的 CQL 是非常重要的命令，类似于 SQL 语句，具体的用法可以参考：<a href="https://www.w3cschool.cn/neo4j/neo4j_cql_introduction.html" target="_blank" rel="noopener">https://www.w3cschool.cn/neo4j/neo4j_cql_introduction.html</a>。</p>
                  <h2 id="Py2Neo用法"><a href="#Py2Neo用法" class="headerlink" title="Py2Neo用法"></a>Py2Neo用法</h2>
                  <p>Py2Neo 是用来对接 Neo4j 的 Python 库，接下来对其详细介绍。</p>
                  <h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3>
                  <ul>
                    <li>官方文档：<a href="http://py2neo.org/v3/index.html" target="_blank" rel="noopener">http://py2neo.org/v3/index.html</a></li>
                    <li>GitHub：<a href="https://github.com/technige/py2neo" target="_blank" rel="noopener">https://github.com/technige/py2neo</a></li>
                  </ul>
                  <h3 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a>安装方法</h3>
                  <p>使用 Pip 安装即可：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> py2neo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="Node-amp-Relationship"><a href="#Node-amp-Relationship" class="headerlink" title="Node &amp; Relationship"></a>Node &amp; Relationship</h3>
                  <p>Neo4j 里面最重要的两个数据结构就是节点和关系，即 Node 和 Relationship，可以通过 Node 或 Relationship 对象创建，实例如下：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import <span class="keyword">Node</span><span class="title">, Relationship</span></span><br><span class="line"></span><br><span class="line">a = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Alice')</span><br><span class="line">b = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Bob')</span><br><span class="line">r = Relationship(a, 'KNOWS', b)</span><br><span class="line">print(a, b, r)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Alice"</span>&#125;) (<span class="selector-tag">bob</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Bob"</span>&#125;) (<span class="selector-tag">alice</span>)<span class="selector-tag">-</span><span class="selector-attr">[:KNOWS]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">bob</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就成功创建了两个 Node 和两个 Node 之间的 Relationship。 Node 和 Relationship 都继承了 PropertyDict 类，它可以赋值很多属性，类似于字典的形式，例如可以通过如下方式对 Node 或 Relationship 进行属性赋值，接着上面的代码，实例如下:</p>
                  <figure class="highlight stylus">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">a</span>[<span class="string">'age'</span>] = <span class="number">20</span></span><br><span class="line"><span class="selector-tag">b</span>[<span class="string">'age'</span>] = <span class="number">21</span></span><br><span class="line">r[<span class="string">'time'</span>] = <span class="string">'2017/08/31'</span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(a, b, r)</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">20</span>,name:<span class="string">"Alice"</span>&#125;) (<span class="selector-tag">bob</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,name:<span class="string">"Bob"</span>&#125;) (<span class="selector-tag">alice</span>)<span class="selector-tag">-</span><span class="selector-attr">[:KNOWS &#123;time:<span class="string">"2017/08/31"</span>&#125;]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">bob</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可见通过类似字典的操作方法就可以成功实现属性赋值。 另外还可以通过 setdefault() 方法赋值默认属性，例如：</p>
                  <figure class="highlight stylus">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">a</span>.setdefault(<span class="string">'location'</span>, <span class="string">'北京'</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(a)</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">20</span>,location:<span class="string">"北京"</span>,name:<span class="string">"Alice"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可见没有给 a 对象赋值 location 属性，现在就会使用默认属性。 但如果赋值了 location 属性，则它会覆盖默认属性，例如：</p>
                  <figure class="highlight stylus">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">a</span>[<span class="string">'location'</span>] = <span class="string">'上海'</span></span><br><span class="line"><span class="selector-tag">a</span>.setdefault(<span class="string">'location'</span>, <span class="string">'北京'</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(a)</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">20</span>,location:<span class="string">"上海"</span>,name:<span class="string">"Alice"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外也可以使用 update() 方法对属性批量更新，接着上面的例子实例如下：</p>
                  <figure class="highlight stylus">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'Amy'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">21</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-tag">a</span>.update(data)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(a)</span></span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,location:<span class="string">"上海"</span>,name:<span class="string">"Amy"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到这里更新了 a 对象的 name 和 age 属性，没有更新 location 属性，则 name 和 age 属性会更新，location 属性则会保留。</p>
                  <h3 id="Subgraph"><a href="#Subgraph" class="headerlink" title="Subgraph"></a>Subgraph</h3>
                  <p>Subgraph，子图，是 Node 和 Relationship 的集合，最简单的构造子图的方式是通过关系运算符，实例如下：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import <span class="keyword">Node</span><span class="title">, Relationship</span></span><br><span class="line"></span><br><span class="line">a = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Alice')</span><br><span class="line">b = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Bob')</span><br><span class="line">r = Relationship(a, 'KNOWS', b)</span><br><span class="line">s = a | b | r</span><br><span class="line">print(s)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(&#123;(<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;), (<span class="name">bob:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;)&#125;, &#123;(<span class="name">alice</span>)-[<span class="symbol">:KNOWS</span>]-&gt;(<span class="name">bob</span>)&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样就组成了一个 Subgraph。 另外还可以通过 nodes() 和 relationships() 方法获取所有的 Node 和 Relationship，实例如下：</p>
                  <figure class="highlight lisp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">print(<span class="name">s</span>.nodes())</span><br><span class="line">print(<span class="name">s</span>.relationships())</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight lisp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">frozenset(&#123;(<span class="name">alice</span><span class="symbol">:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;), (<span class="name">bob</span><span class="symbol">:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;)&#125;)</span><br><span class="line">frozenset(&#123;(<span class="name">alice</span>)-[<span class="symbol">:KNOWS</span>]-&gt;(<span class="name">bob</span>)&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到结果是 frozenset 类型。 另外还可以利用 &amp; 取 Subgraph 的交集，例如：</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">s1 = a <span class="string">| b | r</span></span><br><span class="line">s2 = a <span class="string">| b</span></span><br><span class="line">print(s1 <span class="meta">&amp; s2)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(&#123;(<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;), (<span class="name">bob:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;)&#125;, &#123;&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到结果是二者的交集。 另外我们还可以分别利用 keys()、labels()、nodes()、relationships()、types() 分别获取 Subgraph 的 Key、Label、Node、Relationship、Relationship Type，实例如下：</p>
                  <figure class="highlight gauss">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">s = a | b | r</span><br><span class="line"><span class="keyword">print</span>(s.<span class="built_in">keys</span>())</span><br><span class="line"><span class="keyword">print</span>(s.<span class="built_in">labels</span>())</span><br><span class="line"><span class="keyword">print</span>(s.<span class="built_in">nodes</span>())</span><br><span class="line"><span class="keyword">print</span>(s.<span class="built_in">relationships</span>())</span><br><span class="line"><span class="keyword">print</span>(s.<span class="built_in">types</span>())</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight lisp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">frozenset(&#123;'name'&#125;)</span><br><span class="line">frozenset(&#123;'Person'&#125;)</span><br><span class="line">frozenset(&#123;(<span class="name">alice</span><span class="symbol">:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;), (<span class="name">bob</span><span class="symbol">:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;)&#125;)</span><br><span class="line">frozenset(&#123;(<span class="name">alice</span>)-[<span class="symbol">:KNOWS</span>]-&gt;(<span class="name">bob</span>)&#125;)</span><br><span class="line">frozenset(&#123;'KNOWS'&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外还可以用 order() 或 size() 方法来获取 Subgraph 的 Node 数量和 Relationship 数量，实例如下：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import <span class="keyword">Node</span><span class="title">, Relationship</span>, size, order</span><br><span class="line">s = a | b | r</span><br><span class="line">print(order(s))</span><br><span class="line">print(size(s))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">1</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="Walkable"><a href="#Walkable" class="headerlink" title="Walkable"></a>Walkable</h3>
                  <p>Walkable 是增加了遍历信息的 Subgraph，我们通过 + 号便可以构建一个 Walkable 对象，例如：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import <span class="keyword">Node</span><span class="title">, Relationship</span></span><br><span class="line"></span><br><span class="line">a = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Alice')</span><br><span class="line">b = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Bob')</span><br><span class="line">c = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Mike')</span><br><span class="line">ab = Relationship(a, <span class="string">"KNOWS"</span>, b)</span><br><span class="line">ac = Relationship(a, <span class="string">"KNOWS"</span>, c)</span><br><span class="line">w = ab + Relationship(b, <span class="string">"LIKES"</span>, c) + ac</span><br><span class="line">print(w)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight elixir">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(alice)-[<span class="symbol">:KNOWS</span>]-&gt;(bob)-[<span class="symbol">:LIKES</span>]-&gt;(mike)&lt;-[<span class="symbol">:KNOWS</span>]-(alice)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就形成了一个 Walkable 对象。 另外我们可以调用 walk() 方法实现遍历，实例如下：</p>
                  <figure class="highlight applescript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import walk</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">item</span> <span class="keyword">in</span> walk(w):</span><br><span class="line">    print(<span class="built_in">item</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Alice"</span>&#125;)</span><br><span class="line">(<span class="selector-tag">alice</span>)<span class="selector-tag">-</span><span class="selector-attr">[:KNOWS]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">bob</span>)</span><br><span class="line">(<span class="selector-tag">bob</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Bob"</span>&#125;)</span><br><span class="line">(<span class="selector-tag">bob</span>)<span class="selector-tag">-</span><span class="selector-attr">[:LIKES]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">mike</span>)</span><br><span class="line">(<span class="selector-tag">mike</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Mike"</span>&#125;)</span><br><span class="line">(<span class="selector-tag">alice</span>)<span class="selector-tag">-</span><span class="selector-attr">[:KNOWS]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">mike</span>)</span><br><span class="line">(<span class="selector-tag">alice</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">name</span>:<span class="string">"Alice"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到它从 a 这个 Node 开始遍历，然后到 b，再到 c，最后重新回到 a。 另外还可以利用 start_node()、end_node()、nodes()、relationships() 方法来获取起始 Node、终止 Node、所有 Node 和 Relationship，例如：</p>
                  <figure class="highlight lisp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">print(<span class="name">w</span>.start_node())</span><br><span class="line">print(<span class="name">w</span>.end_node())</span><br><span class="line">print(<span class="name">w</span>.nodes())</span><br><span class="line">print(<span class="name">w</span>.relationships())</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;)</span><br><span class="line">(<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;)</span><br><span class="line">((<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;), (<span class="name">bob:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;), (<span class="name">mike:Person</span> &#123;name:<span class="string">"Mike"</span>&#125;), (<span class="name">alice:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;))</span><br><span class="line">((<span class="name">alice</span>)-[<span class="symbol">:KNOWS</span>]-&gt;(<span class="name">bob</span>), (<span class="name">bob</span>)-[<span class="symbol">:LIKES</span>]-&gt;(<span class="name">mike</span>), (<span class="name">alice</span>)-[<span class="symbol">:KNOWS</span>]-&gt;(<span class="name">mike</span>))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以看到本例中起始和终止 Node 都是同一个，这和 walk() 方法得到的结果是一致的。</p>
                  <h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3>
                  <p>在 database 模块中包含了和 Neo4j 数据交互的 API，最重要的当属 Graph，它代表了 Neo4j 的图数据库，同时 Graph 也提供了许多方法来操作 Neo4j 数据库。 Graph 在初始化的时候需要传入连接的 URI，初始化参数有 bolt、secure、host、http_port、https_port、bolt_port、user、password，详情说明可以参考：<a href="http://py2neo.org/v3/database.html#py2neo.database.Graph" target="_blank" rel="noopener">http://py2neo.org/v3/database.html#py2neo.database.Graph</a>。 初始化的实例如下：</p>
                  <figure class="highlight isbl">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="variable">from</span> <span class="variable">py2neo</span> <span class="variable">import</span> <span class="variable">Graph</span></span><br><span class="line"><span class="variable">graph_1</span> = <span class="function"><span class="title">Graph</span>()</span></span><br><span class="line"><span class="variable">graph_2</span> = <span class="function"><span class="title">Graph</span>(<span class="variable">host</span>=<span class="string">"localhost"</span>)</span></span><br><span class="line"><span class="variable">graph_3</span> = <span class="function"><span class="title">Graph</span>(<span class="string">"http://localhost:7474/db/data/"</span>)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外我们还可以利用 create() 方法传入 Subgraph 对象来将关系图添加到数据库中，实例如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Node, Relationship, Graph</span><br><span class="line"></span><br><span class="line">a = Node(<span class="string">'Person'</span>, <span class="attribute">name</span>=<span class="string">'Alice'</span>)</span><br><span class="line">b = Node(<span class="string">'Person'</span>, <span class="attribute">name</span>=<span class="string">'Bob'</span>)</span><br><span class="line">r = Relationship(a, <span class="string">'KNOWS'</span>, b)</span><br><span class="line">s = a | b | r</span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">graph.create(s)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里必须确保 Neo4j 正常运行，其密码为 123456，这里调用 create() 方法即可完成图的创建，结果如下： <img src="https://germey.gitbooks.io/ai/content/assets/2017-08-31-21-35-08.jpg" alt=""> 另外我们也可以单独添加单个 Node 或 Relationship，实例如下：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> Graph, Node, Relationship</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="keyword">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">a = Node(<span class="string">'Person'</span>, <span class="type">name</span>=<span class="string">'Alice'</span>)</span><br><span class="line">graph.<span class="keyword">create</span>(a)</span><br><span class="line">b = Node(<span class="string">'Person'</span>, <span class="type">name</span>=<span class="string">'Bob'</span>)</span><br><span class="line">ab = Relationship(a, <span class="string">'KNOWS'</span>, b)</span><br><span class="line">graph.<span class="keyword">create</span>(ab)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果如下： <img src="https://germey.gitbooks.io/ai/content/assets/2017-08-31-22-00-02.jpg" alt=""> 另外还可以利用 data() 方法来获取查询结果：</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> py2neo <span class="keyword">import</span> Graph</span><br><span class="line"></span><br><span class="line"><span class="title">graph</span> = <span class="type">Graph</span>(password='<span class="number">123456</span>')</span><br><span class="line"><span class="class"><span class="keyword">data</span> = graph.<span class="keyword">data</span>('<span class="type">MATCH</span> (<span class="title">p</span>:<span class="type">Person</span>) return p')</span></span><br><span class="line"><span class="title">print</span>(<span class="class"><span class="keyword">data</span>)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[&#123;'p': (<span class="name">e0d0f96:Person</span> &#123;name:<span class="string">"Alice"</span>&#125;)&#125;, &#123;'p': (<span class="name">cfe57d0:Person</span> &#123;name:<span class="string">"Bob"</span>&#125;)&#125;]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里是通过 CQL 语句实现的查询，输出结果即 CQL 语句的返回结果，是列表形式。 另外输出结果还可以直接转化为 DataFrame 对象，实例如下：</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> py2neo <span class="keyword">import</span> Graph</span><br><span class="line"><span class="title">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="title">graph</span> = <span class="type">Graph</span>(password='<span class="number">123456</span>')</span><br><span class="line"><span class="class"><span class="keyword">data</span> = graph.<span class="keyword">data</span>('<span class="type">MATCH</span> (<span class="title">p</span>:<span class="type">Person</span>) return p')</span></span><br><span class="line"><span class="title">df</span> = <span class="type">DataFrame</span>(<span class="class"><span class="keyword">data</span>)</span></span><br><span class="line"><span class="title">print</span>(df)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight stylus">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">                   p</span><br><span class="line"><span class="number">0</span>  &#123;<span class="string">'name'</span>: <span class="string">'Alice'</span>&#125;</span><br><span class="line"><span class="number">1</span>    &#123;<span class="string">'name'</span>: <span class="string">'Bob'</span>&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外可以使用 find_one() 或 find() 方法进行 Node 的查找，可以利用 match() 或 match_one() 方法对 Relationship 进行查找：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Graph</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">node = graph.find_one(<span class="attribute">label</span>=<span class="string">'Person'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(node)</span><br><span class="line">relationship = graph.match_one(<span class="attribute">rel_type</span>=<span class="string">'KNOWS'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(relationship)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">c7402c7</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,name:<span class="string">"Alice"</span>&#125;)</span><br><span class="line">(<span class="selector-tag">c7402c7</span>)<span class="selector-tag">-</span><span class="selector-attr">[:KNOWS]</span><span class="selector-tag">-</span>&gt;(<span class="selector-tag">e2c42fc</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果想要更新 Node 的某个属性可以使用 push() 方法，例如：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import Graph, <span class="keyword">Node</span><span class="title"></span></span><br><span class="line"><span class="title"></span></span><br><span class="line"><span class="title">graph</span> = Graph(<span class="attr">password=</span>'<span class="number">123456</span>')</span><br><span class="line">a = <span class="keyword">Node</span><span class="title">('Person</span>', <span class="attr">name=</span>'Alice')</span><br><span class="line"><span class="keyword">node</span> <span class="title">= graph</span>.find_one(<span class="attr">label=</span>'Person')</span><br><span class="line"><span class="keyword">node</span><span class="title">['age</span>'] = <span class="number">21</span></span><br><span class="line">graph.push(<span class="keyword">node</span><span class="title">)</span></span><br><span class="line"><span class="title">print</span>(graph.find_one(<span class="attr">label=</span>'Person'))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">a90a763</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,name:<span class="string">"Alice"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果想要删除某个 Node 可以使用 delete() 方法，例如：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Graph</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">node = graph.find_one(<span class="attribute">label</span>=<span class="string">'Person'</span>)</span><br><span class="line">relationship = graph.match_one(<span class="attribute">rel_type</span>=<span class="string">'KNOWS'</span>)</span><br><span class="line">graph.delete(relationship)</span><br><span class="line">graph.delete(node)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在删除 Node 时必须先删除其对应的 Relationship，否则无法删除 Node。 另外我们也可以通过 run() 方法直接执行 CQL 语句，例如：</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">from</span> py2neo <span class="keyword">import</span> Graph</span><br><span class="line"></span><br><span class="line"><span class="title">graph</span> = <span class="type">Graph</span>(password='<span class="number">123456</span>')</span><br><span class="line"><span class="class"><span class="keyword">data</span> = graph.run('<span class="type">MATCH</span> (<span class="title">p</span>:<span class="type">Person</span>) <span class="type">RETURN</span> p <span class="type">LIMIT</span> 5')</span></span><br><span class="line"><span class="title">print</span>(list(<span class="class"><span class="keyword">data</span>))</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[(<span class="name">'p':</span> (<span class="name">b6f61ff:Person</span> &#123;age:20,name:<span class="string">"Alice"</span>&#125;)), (<span class="name">'p':</span> (<span class="name">cc238b1:Person</span> &#123;age:20,name:<span class="string">"Alice"</span>&#125;)), (<span class="name">'p':</span> (<span class="name">b09e672:Person</span> &#123;age:20,name:<span class="string">"Alice"</span>&#125;))]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="NodeSelector"><a href="#NodeSelector" class="headerlink" title="NodeSelector"></a>NodeSelector</h3>
                  <p>Graph 有时候用起来不太方便，比如如果要根据多个条件进行 Node 的查询是做不到的，在这里更方便的查询方法是利用 NodeSelector，我们首先新建如下的 Node 和 Relationship，实例如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Graph, Node, Relationship</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">a = Node(<span class="string">'Person'</span>, <span class="attribute">name</span>=<span class="string">'Alice'</span>, <span class="attribute">age</span>=21, <span class="attribute">location</span>=<span class="string">'广州'</span>)</span><br><span class="line">b = Node(<span class="string">'Person'</span>, <span class="attribute">name</span>=<span class="string">'Bob'</span>, <span class="attribute">age</span>=22, <span class="attribute">location</span>=<span class="string">'上海'</span>)</span><br><span class="line">c = Node(<span class="string">'Person'</span>, <span class="attribute">name</span>=<span class="string">'Mike'</span>, <span class="attribute">age</span>=21, <span class="attribute">location</span>=<span class="string">'北京'</span>)</span><br><span class="line">r1 = Relationship(a, <span class="string">'KNOWS'</span>, b)</span><br><span class="line">r2 = Relationship(b, <span class="string">'KNOWS'</span>, c)</span><br><span class="line">graph.create(a)</span><br><span class="line">graph.create(r1)</span><br><span class="line">graph.create(r2)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果： <img src="https://germey.gitbooks.io/ai/content/assets/2017-08-31-23-38-27.jpg" alt=""> 在这里我们用 NodeSelector 来筛选 age 为 21 的 Person Node，实例如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Graph, NodeSelector</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">selector = NodeSelector(graph)</span><br><span class="line">persons = selector.select(<span class="string">'Person'</span>, <span class="attribute">age</span>=21)</span><br><span class="line"><span class="builtin-name">print</span>(list(persons))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[(<span class="string">d195b2e:</span>Person &#123;<span class="string">age:</span><span class="number">21</span>,<span class="string">location:</span><span class="string">"广州"</span>,<span class="string">name:</span><span class="string">"Alice"</span>&#125;), (<span class="string">eefe475:</span>Person &#123;<span class="string">age:</span><span class="number">21</span>,<span class="string">location:</span><span class="string">"北京"</span>,<span class="string">name:</span><span class="string">"Mike"</span>&#125;)]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外也可以使用 where() 进行更复杂的查询，例如查找 name 是 A 开头的 Person Node，实例如下：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> Graph, NodeSelector</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="keyword">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">selector = NodeSelector(graph)</span><br><span class="line">persons = selector.<span class="keyword">select</span>(<span class="string">'Person'</span>).<span class="keyword">where</span>(<span class="string">'_.name =~ "A.*"'</span>)</span><br><span class="line">print(list(persons))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight clojure">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[(<span class="name">bcd8072:Person</span> &#123;age:21,location:<span class="string">"广州"</span>,name:<span class="string">"Alice"</span>&#125;)]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里用了正则表达式匹配查询。 另外也可以使用 order_by() 进行排序：</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from py2neo import Graph, NodeSelector</span><br><span class="line"></span><br><span class="line">graph = <span class="constructor">Graph(<span class="params">password</span>='123456')</span></span><br><span class="line">selector = <span class="constructor">NodeSelector(<span class="params">graph</span>)</span></span><br><span class="line">persons = selector.select('Person').order<span class="constructor">_by('<span class="params">_</span>.<span class="params">age</span>')</span></span><br><span class="line">print(<span class="built_in">list</span>(persons))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[(<span class="string">e3fc3d7:</span>Person &#123;<span class="string">age:</span><span class="number">21</span>,<span class="string">location:</span><span class="string">"广州"</span>,<span class="string">name:</span><span class="string">"Alice"</span>&#125;), (<span class="string">da0179d:</span>Person &#123;<span class="string">age:</span><span class="number">21</span>,<span class="string">location:</span><span class="string">"北京"</span>,<span class="string">name:</span><span class="string">"Mike"</span>&#125;), (<span class="string">cafa16e:</span>Person &#123;<span class="string">age:</span><span class="number">22</span>,<span class="string">location:</span><span class="string">"上海"</span>,<span class="string">name:</span><span class="string">"Bob"</span>&#125;)]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>前面返回的都是列表，如果要查询单个节点的话，可以使用 first() 方法，实例如下：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> Graph, NodeSelector</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="keyword">password</span>=<span class="string">'123456'</span>)</span><br><span class="line">selector = NodeSelector(graph)</span><br><span class="line">person = selector.<span class="keyword">select</span>(<span class="string">'Person'</span>).<span class="keyword">where</span>(<span class="string">'_.name =~ "A.*"'</span>).first()</span><br><span class="line">print(person)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">ea81c04</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,location:<span class="string">"广州"</span>,name:<span class="string">"Alice"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>更详细的内容可以查看：<a href="http://py2neo.org/v3/database.html#cypher-utilities" target="_blank" rel="noopener">http://py2neo.org/v3/database.html#cypher-utilities</a>。</p>
                  <h3 id="OGM"><a href="#OGM" class="headerlink" title="OGM"></a>OGM</h3>
                  <p>OGM 类似于 ORM，意为 Object Graph Mapping，这样可以实现一个对象和 Node 的关联，例如：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo.ogm <span class="keyword">import</span> GraphObject, Property, RelatedTo, RelatedFrom</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="symbol">Movie</span>(<span class="symbol">GraphObject</span>):</span><br><span class="line">    <span class="symbol">__primarykey__</span> = '<span class="symbol">title</span>'</span><br><span class="line"></span><br><span class="line">    <span class="symbol">title</span> = <span class="symbol">Property</span>()</span><br><span class="line">    <span class="symbol">released</span> = <span class="symbol">Property</span>()</span><br><span class="line">    <span class="symbol">actors</span> = <span class="symbol">RelatedFrom</span>('<span class="symbol">Person</span>', '<span class="symbol">ACTED_IN</span>')</span><br><span class="line">    <span class="symbol">directors</span> = <span class="symbol">RelatedFrom</span>('<span class="symbol">Person</span>', '<span class="symbol">DIRECTED</span>')</span><br><span class="line">    <span class="symbol">producers</span> = <span class="symbol">RelatedFrom</span>('<span class="symbol">Person</span>', '<span class="symbol">PRODUCED</span>')</span><br><span class="line"></span><br><span class="line"><span class="symbol">class</span> <span class="symbol">Person</span>(<span class="symbol">GraphObject</span>):</span><br><span class="line">    <span class="symbol">__primarykey__</span> = '<span class="symbol">name</span>'</span><br><span class="line"></span><br><span class="line">    <span class="symbol">name</span> = <span class="symbol">Property</span>()</span><br><span class="line">    <span class="symbol">born</span> = <span class="symbol">Property</span>()</span><br><span class="line">    <span class="symbol">acted_in</span> = <span class="symbol">RelatedTo</span>('<span class="symbol">Movie</span>')</span><br><span class="line">    <span class="symbol">directed</span> = <span class="symbol">RelatedTo</span>('<span class="symbol">Movie</span>')</span><br><span class="line">    <span class="symbol">produced</span> = <span class="symbol">RelatedTo</span>('<span class="symbol">Movie</span>')</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们可以用它来结合 Graph 查询，例如：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo import Graph</span><br><span class="line"><span class="keyword">from</span> py2neo.ogm import GraphObject, Property</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="attribute">password</span>=<span class="string">'123456'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Person(GraphObject):</span><br><span class="line">    __primarykey__ = <span class="string">'name'</span></span><br><span class="line"></span><br><span class="line">    name = Property()</span><br><span class="line">    age = Property()</span><br><span class="line">    location = Property()</span><br><span class="line"></span><br><span class="line">person = Person.select(graph).where(<span class="attribute">age</span>=21).first()</span><br><span class="line"><span class="builtin-name">print</span>(person)</span><br><span class="line"><span class="builtin-name">print</span>(person.name)</span><br><span class="line"><span class="builtin-name">print</span>(person.age)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">&lt;Person <span class="attribute">name</span>=<span class="string">'Alice'</span>&gt;</span><br><span class="line">Alice</span><br><span class="line">21</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就成功实现了对象和 Node 的映射。 我们可以用它动态改变 Node 的属性，例如修改某个 Node 的 age 属性，实例如下：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">person = Person.select(graph).where(<span class="attr">age=</span><span class="number">21</span>).first()</span><br><span class="line">print(person.__ogm__.<span class="keyword">node</span><span class="title">)</span></span><br><span class="line"><span class="title">person</span>.age = <span class="number">22</span></span><br><span class="line">print(person.__ogm__.<span class="keyword">node</span><span class="title">)</span></span><br><span class="line"><span class="title">graph</span>.push(person)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">(<span class="selector-tag">ccf5640</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">21</span>,location:<span class="string">"北京"</span>,name:<span class="string">"Mike"</span>&#125;)</span><br><span class="line">(<span class="selector-tag">ccf5640</span><span class="selector-pseudo">:Person</span> &#123;<span class="attribute">age</span>:<span class="number">22</span>,location:<span class="string">"北京"</span>,name:<span class="string">"Mike"</span>&#125;)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>另外我们也可以通过映射关系进行 Relationship 的调整，例如通过 Relationship 添加一个关联 Node，实例如下：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> Graph</span><br><span class="line"><span class="keyword">from</span> py2neo.ogm <span class="keyword">import</span> GraphObject, Property, RelatedTo</span><br><span class="line"></span><br><span class="line">graph = Graph(<span class="keyword">password</span>=<span class="string">'123456'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Person(GraphObject):</span><br><span class="line">    __primarykey__ = <span class="string">'name'</span></span><br><span class="line"></span><br><span class="line">    <span class="type">name</span> = Property()</span><br><span class="line">    age = Property()</span><br><span class="line">    <span class="keyword">location</span> = Property()</span><br><span class="line">    knows = RelatedTo(<span class="string">'Person'</span>, <span class="string">'KNOWS'</span>)</span><br><span class="line"></span><br><span class="line">person = Person.<span class="keyword">select</span>(graph).<span class="keyword">where</span>(age=<span class="number">21</span>).first()</span><br><span class="line">print(list(person.knows))</span><br><span class="line">new_person = Person()</span><br><span class="line">new_person.name = <span class="string">'Durant'</span></span><br><span class="line">new_person.age = <span class="number">28</span></span><br><span class="line">person.knows.<span class="keyword">add</span>(new_person)</span><br><span class="line">print(list(person.knows))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行结果：</p>
                  <figure class="highlight fsharp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">[&lt;Person name='Bob'&gt;]</span></span><br><span class="line"><span class="meta">[&lt;Person name='Bob'&gt;, &lt;Person name='Durant'&gt;]</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就完成了 Node 和 Relationship 的添加，同时由于设置了 primarykey 为 name，所以不会重复添加。 但是注意此时数据库并没有更新，只是对象更新了，如果要更新到数据库中还需要调用 Graph 对象的 push() 或 pull() 方法，添加如下代码即可：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">graph</span><span class="selector-class">.push</span>(<span class="selector-tag">person</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>也可以通过 remove() 方法移除某个关联 Node，实例如下：</p>
                  <figure class="highlight fortran">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">person = Person.<span class="keyword">select</span>(graph).<span class="keyword">where</span>(<span class="keyword">name</span>=<span class="string">'Alice'</span>).first()</span><br><span class="line"><span class="keyword">target</span> = Person.<span class="keyword">select</span>(graph).<span class="keyword">where</span>(<span class="keyword">name</span>=<span class="string">'Durant'</span>).first()</span><br><span class="line">person.knows.remove(<span class="keyword">target</span>)</span><br><span class="line">graph.push(person)</span><br><span class="line">graph.delete(<span class="keyword">target</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这里 target 是 name 为 Durant 的 Node，代码运行完毕后即可删除关联 Relationship 和删除 Node。 以上便是 OGM 的用法，查询修改非常方便，推荐使用此方法进行 Node 和 Relationship 的修改。 更多内容可以查看：<a href="http://py2neo.org/v3/ogm.html#module-py2neo.ogm" target="_blank" rel="noopener">http://py2neo.org/v3/ogm.html#module-py2neo.ogm</a>。</p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>以上便是对 Neo4j 的相关介绍。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-09-01 01:29:20" itemprop="dateCreated datePublished" datetime="2017-09-01T01:29:20+08:00">2017-09-01</time>
                </span>
                <span id="/4778.html" class="post-meta-item leancloud_visitors" data-flag-title="Neo4j简介及Py2Neo的用法" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>12k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>11 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4759.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4759.html" class="post-title-link" itemprop="url">记scikit-learn贝叶斯文本分类的坑（弄了个笨办法解决了，有其它办法的小哥儿请指点）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>基本步骤： 1、训练素材分类： 我是参考官方的目录结构： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s01.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s01.png" alt=""></a> 每个目录中放对应的文本，一个txt文件一篇对应的文章：就像下面这样 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s02.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s02.png" alt=""></a> 需要注意的是所有素材比例请保持在相同的比例（根据训练结果酌情调整、不可比例过于悬殊、容易造成过拟合（通俗点就是大部分文章都给你分到素材最多的那个类别去了）） 废话不多说直接上代码吧（测试代码的丑得一逼；将就着看看吧） 需要一个小工具： pip install chinese-tokenizer 这是训练器：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> chinese_tokenizer.tokenizer <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer, TfidfTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line">jie_ba_tokenizer = Tokenizer().jie_ba_tokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">training_data = load_files(<span class="string">'./data'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># x_train txt内容 y_train 是类别（正 负 中 ）</span></span><br><span class="line">x_train, _, y_train, _ = train_test_split(training_data.data, training_data.target)</span><br><span class="line">print(<span class="string">'开始建模.....'</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'training_data.target'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(training_data.target_names))</span><br><span class="line"><span class="comment"># tokenizer参数是用来对文本进行分词的函数（就是上面我们结巴分词）</span></span><br><span class="line">count_vect = CountVectorizer(tokenizer=jieba_tokenizer)</span><br><span class="line"></span><br><span class="line">tfidf_transformer = TfidfTransformer()</span><br><span class="line">X_train_counts = count_vect.fit_transform(x_train)</span><br><span class="line"></span><br><span class="line">X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)</span><br><span class="line">print(<span class="string">'正在训练分类器.....'</span>)</span><br><span class="line"><span class="comment"># 多项式贝叶斯分类器训练</span></span><br><span class="line">clf = MultinomialNB().fit(X_train_tfidf, y_train)</span><br><span class="line"><span class="comment"># 保存分类器（好在其它程序中使用）</span></span><br><span class="line">joblib.dump(clf, <span class="string">'model.pkl'</span>)</span><br><span class="line"><span class="comment"># 保存矢量化（坑在这儿！！需要使用和训练器相同的 矢量器 不然会报错！！！！！！ 提示 ValueError dimension mismatch··）</span></span><br><span class="line">joblib.dump(count_vect, <span class="string">'count_vect'</span>)</span><br><span class="line">print(<span class="string">"分类器的相关信息："</span>)</span><br><span class="line">print(clf)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>下面是是使用训练好的分类器分类文章： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s03.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/08/s03.png" alt=""></a> 需要分类的文章放在predict_data目录中：照样是一篇文章一个txt文件</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"># -*- coding: utf<span class="number">-8</span> -*-</span><br><span class="line"># @<span class="type">Time</span>    : <span class="number">2017</span>/<span class="number">8</span>/<span class="number">23</span> <span class="number">18</span>:<span class="number">02</span></span><br><span class="line"># @Author  : 哎哟卧槽</span><br><span class="line"># @Site    : </span><br><span class="line"># @File    : 贝叶斯分类器.py</span><br><span class="line"># @Software: PyCharm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> <span class="type">json</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_files</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer, TfidfTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 加载分类器</span><br><span class="line">clf = joblib.<span class="keyword">load</span>(<span class="string">'model.pkl'</span>)</span><br><span class="line"></span><br><span class="line">count_vect = joblib.<span class="keyword">load</span>(<span class="string">'count_vect'</span>)</span><br><span class="line">testing_data = load_files(<span class="string">'./predict_data'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">target_names = <span class="type">json</span>.loads(<span class="keyword">open</span>(<span class="string">'training_data.target'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>).<span class="keyword">read</span>())</span><br><span class="line">#     # 字符串处理</span><br><span class="line">tfidf_transformer = TfidfTransformer()</span><br><span class="line"></span><br><span class="line">X_new_counts = count_vect.<span class="keyword">transform</span>(testing_data.data)</span><br><span class="line">X_new_tfidf = tfidf_transformer.fit_transform(X_new_counts)</span><br><span class="line"># 进行预测</span><br><span class="line">predicted = clf.predict(X_new_tfidf)</span><br><span class="line"><span class="keyword">for</span> title, category <span class="keyword">in</span> zip(testing_data.filenames, predicted):</span><br><span class="line">    print(<span class="string">'%r =&gt; %s'</span> % (title, target_names[category]))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 这个样子将训练好的分类器在新的程序中使用时候 就不报错： ValueError dimension mismatch·· 这儿有个demo 仅供参考：<a href="https://github.com/thsheep/sklearn_naive_bayes_classification" target="_blank" rel="noopener">GitHub地址</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-08-23 18:49:44" itemprop="dateCreated datePublished" datetime="2017-08-23T18:49:44+08:00">2017-08-23</time>
                </span>
                <span id="/4759.html" class="post-meta-item leancloud_visitors" data-flag-title="记scikit-learn贝叶斯文本分类的坑（弄了个笨办法解决了，有其它办法的小哥儿请指点）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2.4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4725.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4725.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第五篇（Scrapy-Splash配合CrawlSpider；瞎几把整的）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>估摸着各位小伙伴儿被想使用CrawlSpider的Rule来抓取JS，相当受折磨； CrawlSpider Rule总是不能和Splash结合。 废话不多说，手疼···· </p>
                  <h1 id="方法1："><a href="#方法1：" class="headerlink" title="方法1："></a><strong>方法1：</strong></h1>
                  <p>写一个自定义的函数，使用Rule中的process_request参数；来替换掉Rule本身Request的逻辑。 参考官方文档： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/07/QQ20170712-002911.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/07/QQ20170712-002911.png" alt=""></a> 1、将请求更换为SplashRequest请求： 2、每次请求将本次请求的URL使用Meta参数传递下去； 3、重写 _requests_to_follow 方法：替换响应Response的URL为我们传递的URL（否则会格式为Splash的地址） 就像下面这样</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'innda'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(url, dont_process_response=<span class="literal">True</span>, args=&#123;<span class="string">'wait'</span>: <span class="number">0.5</span>&#125;, meta=&#123;<span class="string">'real_url'</span>: url&#125;)</span><br><span class="line">        </span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'node_\d+\.htm'</span>,)), process_request=<span class="string">'splash_request'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'content_\d+\.htm'</span>,)), callback=<span class="string">"one_parse"</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">splash_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param request: Request对象（是一个字典；怎么取值就不说了吧！！）</span></span><br><span class="line"><span class="string">        :return: SplashRequest的请求</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># dont_process_response=True 参数表示不更改响应对象类型（默认为：HTMLResponse；更改后为：SplashTextResponse）</span></span><br><span class="line">        <span class="comment"># args=&#123;'wait': 0.5&#125; 表示传递等待参数0.5（Splash会渲染0.5s的时间）</span></span><br><span class="line">        <span class="comment"># meta 传递请求的当前请求的URL</span></span><br><span class="line">        <span class="keyword">return</span> SplashRequest(url=request.url, dont_process_response=<span class="literal">True</span>, args=&#123;<span class="string">'wait'</span>: <span class="number">0.5</span>&#125;, meta=&#123;<span class="string">'real_url'</span>: request.url&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_requests_to_follow</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""重写的函数哈！这个函数是Rule的一个方法</span></span><br><span class="line"><span class="string">        :param response: 这货是啥看名字都知道了吧（这货也是个字典，然后你懂的ｄ(･∀･*)♪ﾟ）</span></span><br><span class="line"><span class="string">        :return: 追踪的Request</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(response, HtmlResponse):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        seen = set()</span><br><span class="line">        <span class="comment"># 将Response的URL更改为我们传递下来的URL</span></span><br><span class="line">        <span class="comment"># 需要注意哈！ 不能直接直接改！只能通过Response.replace这个魔术方法来改！（当然你改无所谓啦！反正会用报错来报复你 (`皿´) ）并且！！！</span></span><br><span class="line">        <span class="comment"># 敲黑板！！！！划重点！！！！！注意了！！！ 这货只能赋给一个新的对象（你说变量也行，怎么说都行！(*ﾟ∀ﾟ)=3）</span></span><br><span class="line">        newresponse = response.replace(url=response.meta.get(<span class="string">'real_url'</span>))</span><br><span class="line">        <span class="keyword">for</span> n, rule <span class="keyword">in</span> enumerate(self._rules):</span><br><span class="line">            <span class="comment"># 我要长一点不然有人看不见------------------------------------newresponse 看见没！别忘了改！！！</span></span><br><span class="line">            links = [lnk <span class="keyword">for</span> lnk <span class="keyword">in</span> rule.link_extractor.extract_links(newresponse)</span><br><span class="line">                     <span class="keyword">if</span> lnk <span class="keyword">not</span> <span class="keyword">in</span> seen]</span><br><span class="line">            <span class="keyword">if</span> links <span class="keyword">and</span> rule.process_links:</span><br><span class="line">                links = rule.process_links(links)</span><br><span class="line">            <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">                seen.add(link)</span><br><span class="line">                r = self._build_request(n, link)</span><br><span class="line">                <span class="keyword">yield</span> rule.process_request(r)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">one_parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="方法2"><a href="#方法2" class="headerlink" title="方法2:"></a>方法2:</h2>
                  <p>这就很简单啦！干掉类型检查就是了(/≧▽≦)/ 就像这样：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'innda'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(url, args=&#123;<span class="string">'wait'</span>: <span class="number">0.5</span>&#125;)</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'node_\d+\.htm'</span>,)), process_request=<span class="string">'splash_request'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'content_\d+\.htm'</span>,)), callback=<span class="string">"one_parse"</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">splash_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param request: Request对象（是一个字典；怎么取值就不说了吧！！）</span></span><br><span class="line"><span class="string">        :return: SplashRequest的请求</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># dont_process_response=True 参数表示不更改响应对象类型（默认为：HTMLResponse；更改后为：SplashTextResponse）</span></span><br><span class="line">        <span class="comment"># args=&#123;'wait': 0.5&#125; 表示传递等待参数0.5（Splash会渲染0.5s的时间）</span></span><br><span class="line">        <span class="comment"># meta 传递请求的当前请求的URL</span></span><br><span class="line">        <span class="keyword">return</span> SplashRequest(url=request.url, args=&#123;<span class="string">'wait'</span>: <span class="number">0.5</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_requests_to_follow</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""重写的函数哈！这个函数是Rule的一个方法</span></span><br><span class="line"><span class="string">        :param response: 这货是啥看名字都知道了吧（这货也是个字典，然后你懂的ｄ(･∀･*)♪ﾟ）</span></span><br><span class="line"><span class="string">        :return: 追踪的Request</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># *************请注意我就是被注释注释掉的类型检查o(TωT)o </span></span><br><span class="line">        <span class="comment"># if not isinstance(response, HtmlResponse):</span></span><br><span class="line">        <span class="comment">#     return</span></span><br><span class="line">        <span class="comment"># ************************************************</span></span><br><span class="line">        seen = set()</span><br><span class="line">        <span class="comment"># 将Response的URL更改为我们传递下来的URL</span></span><br><span class="line">        <span class="comment"># 需要注意哈！ 不能直接直接改！只能通过Response.replace这个魔术方法来改！并且！！！</span></span><br><span class="line">        <span class="comment"># 敲黑板！！！！划重点！！！！！注意了！！！ 这货只能赋给一个新的对象（你说变量也行，怎么说都行！(*ﾟ∀ﾟ)=3）</span></span><br><span class="line">        <span class="comment"># newresponse = response.replace(url=response.meta.get('real_url'))</span></span><br><span class="line">        <span class="keyword">for</span> n, rule <span class="keyword">in</span> enumerate(self._rules):</span><br><span class="line">            <span class="comment"># 我要长一点不然有人看不见------------------------------------newresponse 看见没！别忘了改！！！</span></span><br><span class="line">            links = [lnk <span class="keyword">for</span> lnk <span class="keyword">in</span> rule.link_extractor.extract_links(response)</span><br><span class="line">                     <span class="keyword">if</span> lnk <span class="keyword">not</span> <span class="keyword">in</span> seen]</span><br><span class="line">            <span class="keyword">if</span> links <span class="keyword">and</span> rule.process_links:</span><br><span class="line">                links = rule.process_links(links)</span><br><span class="line">            <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">                seen.add(link)</span><br><span class="line">                r = self._build_request(n, link)</span><br><span class="line">                <span class="keyword">yield</span> rule.process_request(r)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>以上完毕@_@!!</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-07-12 00:48:25" itemprop="dateCreated datePublished" datetime="2017-07-12T00:48:25+08:00">2017-07-12</time>
                </span>
                <span id="/4725.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第五篇（Scrapy-Splash配合CrawlSpider；瞎几把整的）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>3.4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>3 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4652.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4652.html" class="post-title-link" itemprop="url">利用新接口抓取微信公众号的所有文章</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>各位小伙儿伴儿，一定深受过采集微信公众号之苦吧！特别是！！！！！！公共号历史信息！！！这丫除了通过中间代理采集APP、还真没什么招数能拿到数据啊！ <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt=""></a> 直到············ 前天晚上微信官方发布了一个文章：<a href="http://mp.weixin.qq.com/s/67sk-uKz9Ct4niT-f4u1KA" target="_blank" rel="noopener">点我</a> 大致意思是说以后发布文章的时候可以直接插入其它公众号的文章了。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021224219.gif" alt=""></a> 诶妈呀！这不是一直需要的采集接口嘛！啧啧 天助我也啊！来来·········下面大致的说一下方法。</p>
                  <h2 id="1、首先你需要一个订阅号！-公众号、和企业号是否可行我不清楚。因为我木有·····"><a href="#1、首先你需要一个订阅号！-公众号、和企业号是否可行我不清楚。因为我木有·····" class="headerlink" title="1、首先你需要一个订阅号！ 公众号、和企业号是否可行我不清楚。因为我木有·····"></a>1、首先你需要一个订阅号！ 公众号、和企业号是否可行我不清楚。因为我木有·····</h2>
                  <h2 id="2、其次你需要登录！"><a href="#2、其次你需要登录！" class="headerlink" title="2、其次你需要登录！"></a><strong>2、其次你需要登录！</strong></h2>
                  <p>微信公众号登录我没仔细看。 这个暂且不说了，我使用的是selenium 驱动浏览器获取Cookie的方法、来达到登录的效果。</p>
                  <h2 id="3、使用requests携带Cookie、登录获取URL的token（这玩意儿很重要每一次请求都需要带上它）像下面这样："><a href="#3、使用requests携带Cookie、登录获取URL的token（这玩意儿很重要每一次请求都需要带上它）像下面这样：" class="headerlink" title="3、使用requests携带Cookie、登录获取URL的token（这玩意儿很重要每一次请求都需要带上它）像下面这样："></a>3、使用requests携带Cookie、登录获取URL的token（这玩意儿很重要每一次请求都需要带上它）像下面这样：</h2>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/TIM截图20170607085814.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/TIM截图20170607085814.png" alt=""></a></p>
                  <h2 id="4、使用获取到的token、和公众号的微信号（就是数字-字符那种）、获取到公众号的fakeid（你可以理解公众号的标识）"><a href="#4、使用获取到的token、和公众号的微信号（就是数字-字符那种）、获取到公众号的fakeid（你可以理解公众号的标识）" class="headerlink" title="4、使用获取到的token、和公众号的微信号（就是数字+字符那种）、获取到公众号的fakeid（你可以理解公众号的标识）"></a>4、使用获取到的token、和公众号的微信号（就是数字+字符那种）、获取到公众号的fakeid（你可以理解公众号的标识）</h2>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/2.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/2.png" alt=""></a></p>
                  <h3 id="我们在搜索公众号的时候浏览器带着参数以GET方法想红框中的URL发起了请求。请求参数如下："><a href="#我们在搜索公众号的时候浏览器带着参数以GET方法想红框中的URL发起了请求。请求参数如下：" class="headerlink" title="我们在搜索公众号的时候浏览器带着参数以GET方法想红框中的URL发起了请求。请求参数如下："></a>我们在搜索公众号的时候浏览器带着参数以GET方法想红框中的URL发起了请求。请求参数如下：</h3>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/3.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/3.png" alt=""></a></p>
                  <h3 id="请求相应如下："><a href="#请求相应如下：" class="headerlink" title="请求相应如下："></a><strong>请求相应如下：</strong></h3>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/4.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/4.png" alt=""></a></p>
                  <h3 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a><strong>代码如下：</strong></h3>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/5.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/5.png" alt=""></a></p>
                  <h1 id="好了-我们再继续："><a href="#好了-我们再继续：" class="headerlink" title="好了 我们再继续："></a>好了 我们再继续：</h1>
                  <h2 id="5、点击我们搜索到的公众号之后、又发现一个请求："><a href="#5、点击我们搜索到的公众号之后、又发现一个请求：" class="headerlink" title="5、点击我们搜索到的公众号之后、又发现一个请求："></a><strong>5、点击我们搜索到的公众号之后、又发现一个请求：</strong></h2>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/6.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/6.png" alt=""></a></p>
                  <h3 id="请求参数如下："><a href="#请求参数如下：" class="headerlink" title="请求参数如下："></a>请求参数如下：</h3>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/7.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/7.png" alt=""></a></p>
                  <h3 id="返回如下："><a href="#返回如下：" class="headerlink" title="返回如下："></a>返回如下：</h3>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/8.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/8.png" alt=""></a></p>
                  <h3 id="代码如下：-1"><a href="#代码如下：-1" class="headerlink" title="代码如下："></a>代码如下：</h3>
                  <p> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/9.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/9.png" alt=""></a></p>
                  <h2 id="好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下："><a href="#好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下：" class="headerlink" title="好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下："></a>好了···最后一步、获取所有文章需要处理一下翻页、翻页请求如下：</h2>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/10.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/10.png" alt=""></a></p>
                  <h4 id="我大概看了一下、极客学院每一页大概至少有5条信息、也就是总文章数-5-就是有多少页。但是有小数、我们取整，然后加1就是总页数了。"><a href="#我大概看了一下、极客学院每一页大概至少有5条信息、也就是总文章数-5-就是有多少页。但是有小数、我们取整，然后加1就是总页数了。" class="headerlink" title="我大概看了一下、极客学院每一页大概至少有5条信息、也就是总文章数/5 就是有多少页。但是有小数、我们取整，然后加1就是总页数了。"></a><strong>我大概看了一下、极客学院每一页大概至少有5条信息、也就是总文章数/5 就是有多少页。但是有小数、我们取整，然后加1就是总页数了。</strong></h4>
                  <h4 id="代码如下：-2"><a href="#代码如下：-2" class="headerlink" title="代码如下："></a><strong>代码如下：</strong></h4>
                  <p> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/11.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/11.png" alt=""></a></p>
                  <h2 id="item-get-‘link’-就是我们需要的公众号文章连接啦！继续请求这个URL提取里面的内容就是啦！"><a href="#item-get-‘link’-就是我们需要的公众号文章连接啦！继续请求这个URL提取里面的内容就是啦！" class="headerlink" title="item.get(‘link’)就是我们需要的公众号文章连接啦！继续请求这个URL提取里面的内容就是啦！"></a><strong>item.get(‘link’)就是我们需要的公众号文章连接啦！继续请求这个URL提取里面的内容就是啦！</strong></h2>
                  <h1 id="以下是完整的测试代码："><a href="#以下是完整的测试代码：" class="headerlink" title="以下是完整的测试代码："></a><strong>以下是完整的测试代码：</strong></h1>
                  <figure class="highlight xl">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> <span class="built_in">time</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">from pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">post = &#123;&#125;</span><br><span class="line"></span><br><span class="line">driver = webdriver.Chrome(executable_path=<span class="string">'C:\chromedriver.exe'</span>)</span><br><span class="line">driver.get(<span class="string">'https://mp.weixin.qq.com/'</span>)</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">2</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='account']"</span>).clear()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='account']"</span>).send_keys(<span class="string">'你的帐号'</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='pwd']"</span>).clear()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//input[@id='pwd']"</span>).send_keys(<span class="string">'你的密码'</span>)</span><br><span class="line"># 在自动输完密码之后记得点一下记住我</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">5</span>)</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"./*//a[@id='loginBt']"</span>).click()</span><br><span class="line"># 拿手机扫二维码！</span><br><span class="line"><span class="built_in">time</span>.sleep(<span class="number">15</span>)</span><br><span class="line">driver.get(<span class="string">'https://mp.weixin.qq.com/'</span>)</span><br><span class="line">cookie_items = driver.get_cookies()</span><br><span class="line"><span class="keyword">for</span> cookie_item <span class="built_in">in</span> cookie_items:</span><br><span class="line">    post[cookie_item[<span class="string">'name'</span>]] = cookie_item[<span class="string">'value'</span>]</span><br><span class="line">cookie_str = json.dumps(post)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>, <span class="string">'w+'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(cookie_str)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import redis</span><br><span class="line">import json</span><br><span class="line">import re</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">gzlist = [<span class="string">'yq_Butler'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://mp.weixin.qq.com'</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">"HOST"</span>: <span class="string">"mp.weixin.qq.com"</span>,</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">with open(<span class="string">'cookie.txt'</span>, <span class="string">'r'</span>, <span class="attribute">encoding</span>=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">    cookie = f.read()</span><br><span class="line">cookies = json.loads(cookie)</span><br><span class="line">response = requests.<span class="builtin-name">get</span>(<span class="attribute">url</span>=url, <span class="attribute">cookies</span>=cookies)</span><br><span class="line">token = re.findall(r<span class="string">'token=(\d+)'</span>, str(response.url))[0]</span><br><span class="line"><span class="keyword">for</span> query <span class="keyword">in</span> gzlist:</span><br><span class="line">    query_id = &#123;</span><br><span class="line">        <span class="string">'action'</span>: <span class="string">'search_biz'</span>,</span><br><span class="line">        <span class="string">'token'</span> : token,</span><br><span class="line">        <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">        <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'random'</span>: random.random(),</span><br><span class="line">        <span class="string">'query'</span>: query,</span><br><span class="line">        <span class="string">'begin'</span>: <span class="string">'0'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    search_url = <span class="string">'https://mp.weixin.qq.com/cgi-bin/searchbiz?'</span></span><br><span class="line">    search_response = requests.<span class="builtin-name">get</span>(search_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id)</span><br><span class="line">    lists = search_response.json().<span class="builtin-name">get</span>(<span class="string">'list'</span>)[0]</span><br><span class="line">    fakeid = lists.<span class="builtin-name">get</span>(<span class="string">'fakeid'</span>)</span><br><span class="line">    query_id_data = &#123;</span><br><span class="line">        <span class="string">'token'</span>: token,</span><br><span class="line">        <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">        <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'random'</span>: random.random(),</span><br><span class="line">        <span class="string">'action'</span>: <span class="string">'list_ex'</span>,</span><br><span class="line">        <span class="string">'begin'</span>: <span class="string">'0'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">        <span class="string">'query'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'fakeid'</span>: fakeid,</span><br><span class="line">        <span class="string">'type'</span>: <span class="string">'9'</span></span><br><span class="line">    &#125;</span><br><span class="line">    appmsg_url = <span class="string">'https://mp.weixin.qq.com/cgi-bin/appmsg?'</span></span><br><span class="line">    appmsg_response = requests.<span class="builtin-name">get</span>(appmsg_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id_data)</span><br><span class="line">    max_num = appmsg_response.json().<span class="builtin-name">get</span>(<span class="string">'app_msg_cnt'</span>)</span><br><span class="line">    num = int(int(max_num) / 5)</span><br><span class="line">    begin = 0</span><br><span class="line">    <span class="keyword">while</span> num + 1 &gt; 0 :</span><br><span class="line">        query_id_data = &#123;</span><br><span class="line">            <span class="string">'token'</span>: token,</span><br><span class="line">            <span class="string">'lang'</span>: <span class="string">'zh_CN'</span>,</span><br><span class="line">            <span class="string">'f'</span>: <span class="string">'json'</span>,</span><br><span class="line">            <span class="string">'ajax'</span>: <span class="string">'1'</span>,</span><br><span class="line">            <span class="string">'random'</span>: random.random(),</span><br><span class="line">            <span class="string">'action'</span>: <span class="string">'list_ex'</span>,</span><br><span class="line">            <span class="string">'begin'</span>: <span class="string">'&#123;&#125;'</span>.format(str(begin)),</span><br><span class="line">            <span class="string">'count'</span>: <span class="string">'5'</span>,</span><br><span class="line">            <span class="string">'query'</span>: <span class="string">''</span>,</span><br><span class="line">            <span class="string">'fakeid'</span>: fakeid,</span><br><span class="line">            <span class="string">'type'</span>: <span class="string">'9'</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="builtin-name">print</span>(<span class="string">'翻页###################'</span>,begin)</span><br><span class="line">        query_fakeid_response = requests.<span class="builtin-name">get</span>(appmsg_url, <span class="attribute">cookies</span>=cookies, <span class="attribute">headers</span>=header, <span class="attribute">params</span>=query_id_data)</span><br><span class="line">        fakeid_list = query_fakeid_response.json().<span class="builtin-name">get</span>(<span class="string">'app_msg_list'</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> fakeid_list:</span><br><span class="line">            <span class="builtin-name">print</span>(item.<span class="builtin-name">get</span>(<span class="string">'link'</span>))</span><br><span class="line">        num -= 1</span><br><span class="line">        begin = int(begin)</span><br><span class="line">        begin+=5</span><br><span class="line">        time.sleep(2)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h1 id="以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频"><a href="#以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频" class="headerlink" title="以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：点我看视频"></a><strong>以上完毕！这就是个测试、代码写得奇丑、各位将就着看啊！看不明白？没关系！看这儿：<a href="http://www.bilibili.com/video/av11127609/" target="_blank" rel="noopener">点我看视频</a></strong></h1>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-06-07 09:44:51" itemprop="dateCreated datePublished" datetime="2017-06-07T09:44:51+08:00">2017-06-07</time>
                </span>
                <span id="/4652.html" class="post-meta-item leancloud_visitors" data-flag-title="利用新接口抓取微信公众号的所有文章" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>3.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>3 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4607.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4607.html" class="post-title-link" itemprop="url">获取知乎问题答案并转换为MarkDown文件</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <blockquote>
                    <h2 id="20170609-更新"><a href="#20170609-更新" class="headerlink" title="20170609 更新:"></a>20170609 更新:</h2>
                    <p><strong>感谢一介草民与ftzz的反馈</strong></p>
                    <h3 id="1-修复中文路径保存问题"><a href="#1-修复中文路径保存问题" class="headerlink" title="(1) 修复中文路径保存问题"></a>(1) 修复中文路径保存问题</h3>
                    <h3 id="2-修复offset问题"><a href="#2-修复offset问题" class="headerlink" title="(2) 修复offset问题"></a>(2) 修复offset问题</h3>
                    <h3 id="3-修复第一个问题"><a href="#3-修复第一个问题" class="headerlink" title="(3) 修复第一个问题"></a>(3) 修复第一个问题</h3>
                    <h2 id="来个好玩的东西"><a href="#来个好玩的东西" class="headerlink" title="来个好玩的东西"></a>来个好玩的东西</h2>
                    <h2 id=""><a href="#" class="headerlink" title="     "></a><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/6f19c6ad326822c9e267d2d961cf1fec_r.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/6f19c6ad326822c9e267d2d961cf1fec_r.png" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/154e026013e7ec53e8ce94c8b4417973_r.jpeg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/154e026013e7ec53e8ce94c8b4417973_r.jpeg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/0838fb7d2c9d61070605148ab57f90cb_r.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/0838fb7d2c9d61070605148ab57f90cb_r.png" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/a1e43e58c01f1e36630f4a1394811b67_r.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/a1e43e58c01f1e36630f4a1394811b67_r.png" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/d851605dddb3e14ad9946a3eccc0ae05_r.jpeg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/d851605dddb3e14ad9946a3eccc0ae05_r.jpeg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/f8acc0c27d15fcfd8b2c9682aabe6633_r.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/f8acc0c27d15fcfd8b2c9682aabe6633_r.png" alt=""></a></h2>
                    <h2 id="20170607-更新"><a href="#20170607-更新" class="headerlink" title="20170607 更新:"></a>20170607 更新:</h2>
                    <h3 id="1-感谢Ftzz提醒-将图片替换为原图"><a href="#1-感谢Ftzz提醒-将图片替换为原图" class="headerlink" title="(1) 感谢Ftzz提醒, 将图片替换为原图"></a>(1) 感谢Ftzz提醒, 将图片替换为原图</h3>
                    <h3 id="2-将文件保存到本地-解决了最大的缺点问题-不用联网也可以看了"><a href="#2-将文件保存到本地-解决了最大的缺点问题-不用联网也可以看了" class="headerlink" title="(2) 将文件保存到本地,解决了最大的缺点问题,不用联网也可以看了"></a>(2) 将文件保存到本地,解决了最大的缺点问题,不用联网也可以看了</h3>
                  </blockquote>
                  <p> 大家好，我是四毛。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a> <strong>写在前面的话</strong> 在开始前，给大家分享一个前段时间逛Github时看到的某个爬虫脚本中的内容： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/lvshi.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/lvshi.jpg" alt=""></a> 所以，大家爬网站的时候，还是友善一点为好，且爬且珍惜啊。 好了，言归正传。 今天主要讲一下如何将某一个知乎问题的所有答案转换为本地MarkDown文件。</p>
                  <h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2>
                  <blockquote>
                    <p>python2.7 html2text markdownpad(这里随意，只要可以支持md就行) 会抓包。。。。。 最重要的是你要有代理，因为知乎开始封IP了</p>
                  </blockquote>
                  <h2 id="1-什么是MarkDown文件"><a href="#1-什么是MarkDown文件" class="headerlink" title="1.什么是MarkDown文件"></a><strong>1.什么是MarkDown文件</strong></h2>
                  <p>Markdown 是一种用来写作的轻量级<strong>「标记语言」</strong>，它用简洁的语法代替排版，而不像一般我们用的字处理软件 <em>Word</em> 或 <em>Pages</em> 有大量的排版、字体设置。它使我们专心于码字，用「标记」语法，来代替常见的排版格式。例如此文从内容到格式，甚至插图，键盘就可以通通搞定了。 恩，上面是我抄的，哈哈。想多了解的可以看看<a href="http://www.jianshu.com/p/1e402922ee32/" target="_blank" rel="noopener">这里</a>。</p>
                  <h2 id="2-为什么要将答案转为MarkDwon"><a href="#2-为什么要将答案转为MarkDwon" class="headerlink" title="2.为什么要将答案转为MarkDwon"></a><strong>2.为什么要将答案转为MarkDwon</strong></h2>
                  <p>因为。。。。。。懒，哈哈，开个玩笑。最重要的原因还是markdown看着比较舒服。平时写脚本的时候，也一直在思考一个问题，如何将一个文字与图片穿插的网页原始的保存下来呢。如果借助工具的话，那就很多了，CTRL+P 打印的时候，选择另存为PDF，或者搞个印象笔记，直接保存整个网页。那么，我们如何用爬虫实现呢？正好前几天看到了<a href="https://github.com/egrcc/zhihu-python" target="_blank" rel="noopener">这个项目</a>，仔细研究了一下，大受启发。</p>
                  <h2 id="3-原理"><a href="#3-原理" class="headerlink" title="3.原理"></a><strong>3.原理</strong></h2>
                  <p>原理说起来很简单：获取请求到的内容的BODY部分，然后重新构建一个HTML文件，接着利用html2text这个模块将其转换为markdown文件，最后对图片及标题按照markdown的格式做一些处理就好了。目前应用的场景主要是在知乎。</p>
                  <h2 id="4-Show-Code"><a href="#4-Show-Code" class="headerlink" title="4.Show Code"></a><strong>4.Show Code</strong></h2>
                  <h3 id="4-1获取知乎答案"><a href="#4-1获取知乎答案" class="headerlink" title="4.1获取知乎答案"></a>4.1获取知乎答案</h3>
                  <p>写代码的时候，主要考虑了两种使用场景。第一，获取某一特定答案的数据然后进行转换；第二，获取某一个问题的所有答案进行然后挨个进行转换，在这里可以 通过赞同数来对要获取的答案进行质量控制。 <strong> 4.1.1、某一个特定答案的数据获取</strong></p>
                  <blockquote>
                    <p>url：<a href="https://www.zhihu.com/question/27621722/answer/48658220（前面那个是问题ID，后边的是答案ID）" target="_blank" rel="noopener">https://www.zhihu.com/question/27621722/answer/48658220（前面那个是问题ID，后边的是答案ID）</a></p>
                  </blockquote>
                  <p>这一数据的获取我这里分为了两个部分，第一部分请求上述网址，拿到答案主体数据以及赞同数，第二部分请求下面这个接口：</p>
                  <blockquote>
                    <p><a href="https://www.zhihu.com/api/v4/answers/48658220" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/answers/48658220</a></p>
                  </blockquote>
                  <p>为什么会这样？因为这个接口得到的答案正文数据不是完整数据，所以只能分两步了。 <strong> 4.1.2、某一个特定答案的数据获取</strong> 这一个数据就可以通过很简单的方式得到了，接口如下：</p>
                  <blockquote>
                    <p><a href="https://www.zhihu.com/api/v4/questions/27621722/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/questions/27621722/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3</a></p>
                  </blockquote>
                  <p>返回的都是JSON数据，很方便获取。但是这里有一个地方需要注意，从这里面取的答案正文数据就是文本数据，不是一个完整的html文件，所以需要在构造一下。 <strong> 4.1.2、保存的字段</strong></p>
                  <blockquote>
                    <p>author_name 回答用户名 answer_id 答案ID question_id 问题ID question_title 问题 vote_up_count 赞同数 create_time 创建时间 答案主体 </p>
                  </blockquote>
                  <h3 id="4-2-Code"><a href="#4-2-Code" class="headerlink" title="4.2 Code"></a>4.2 Code</h3>
                  <p>主脚本：zhihu.py</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by shimeng on 17-6-5</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> html2text</span><br><span class="line"><span class="keyword">from</span> parse_content <span class="keyword">import</span> parse</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">just for study and fun</span></span><br><span class="line"><span class="string">Talk is cheap</span></span><br><span class="line"><span class="string">show me your code</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhiHu</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">         self.request_content = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request</span><span class="params">(self, url, retry_times=<span class="number">10</span>)</span>:</span></span><br><span class="line">        header = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'</span>,</span><br><span class="line">            <span class="string">'authorization'</span>: <span class="string">'oauth c3cef7c66a1843f8b3a9e6a1e3160e20'</span>,</span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'www.zhihu.com'</span></span><br><span class="line">        &#125;</span><br><span class="line">        times = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> retry_times&gt;<span class="number">0</span>:</span><br><span class="line">            times += <span class="number">1</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">'request %s, times: %d'</span> %(url, times)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                ip = <span class="string">'your proxy ip'</span></span><br><span class="line">                <span class="keyword">if</span> ip:</span><br><span class="line">                    proxy = &#123;</span><br><span class="line">                        <span class="string">'http'</span>: <span class="string">'http://%s'</span> % ip,</span><br><span class="line">                        <span class="string">'https'</span>: <span class="string">'http://%s'</span> % ip</span><br><span class="line">                    &#125;</span><br><span class="line">                    self.request_content = requests.get(url, headers=header, proxies=proxy, timeout=<span class="number">10</span>).content</span><br><span class="line">            <span class="keyword">except</span> Exception, e:</span><br><span class="line">                <span class="keyword">print</span> e</span><br><span class="line">                retry_times -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.request_content</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_answer_content</span><span class="params">(self, question_id, flag=<span class="number">2</span>)</span>:</span></span><br><span class="line">        first_url_format = <span class="string">'https://www.zhihu.com/api/v4/questions/&#123;&#125;/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=3'</span></span><br><span class="line">        first_url = first_url_format.format(question_id)</span><br><span class="line">        response = self.request(first_url)</span><br><span class="line">        <span class="keyword">if</span> response:</span><br><span class="line">            contents = json.loads(response)</span><br><span class="line">            <span class="keyword">print</span> contents.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>)</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> contents.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>):</span><br><span class="line">                <span class="keyword">for</span> content <span class="keyword">in</span> contents.get(<span class="string">'data'</span>):</span><br><span class="line">                    self.parse_content(content, flag)</span><br><span class="line">                next_page_url = contents.get(<span class="string">'paging'</span>).get(<span class="string">'next'</span>).replace(<span class="string">'http'</span>, <span class="string">'https'</span>)</span><br><span class="line">                contents = json.loads(self.request(next_page_url))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_single_answer_content</span><span class="params">(self, answer_url, flag=<span class="number">1</span>)</span>:</span></span><br><span class="line">        all_content = &#123;&#125;</span><br><span class="line">        question_id, answer_id = re.findall(<span class="string">'https://www.zhihu.com/question/(\d+)/answer/(\d+)'</span>, answer_url)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        html_content = self.request(answer_url)</span><br><span class="line">        <span class="keyword">if</span> html_content:</span><br><span class="line">            all_content[<span class="string">'main_content'</span>] = html_content</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span>  ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">        ajax_answer_url = <span class="string">'https://www.zhihu.com/api/v4/answers/&#123;&#125;'</span>.format(answer_id)</span><br><span class="line">        ajax_content = self.request(ajax_answer_url)</span><br><span class="line">        <span class="keyword">if</span> ajax_content:</span><br><span class="line">            all_content[<span class="string">'ajax_content'</span>] = json.loads(ajax_content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span>  ValueError(<span class="string">'request failed, quit......'</span>)</span><br><span class="line"></span><br><span class="line">        self.parse_content(all_content, flag, )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_content</span><span class="params">(self, content, flag=None)</span>:</span></span><br><span class="line">        data = parse(content, flag)</span><br><span class="line">        self.transform_to_markdown(data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform_to_markdown</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        content = data[<span class="string">'content'</span>]</span><br><span class="line">        author_name = data[<span class="string">'author_name'</span>]</span><br><span class="line">        answer_id = data[<span class="string">'answer_id'</span>]</span><br><span class="line">        question_id = data[<span class="string">'question_id'</span>]</span><br><span class="line">        question_title = data[<span class="string">'question_title'</span>]</span><br><span class="line">        vote_up_count = data[<span class="string">'vote_up_count'</span>]</span><br><span class="line">        create_time = data[<span class="string">'create_time'</span>]</span><br><span class="line"></span><br><span class="line">        file_name = <span class="string">u'%s--%s的回答[%d].md'</span> % (question_title, author_name,answer_id)</span><br><span class="line">        folder_name = <span class="string">u'%s'</span> % (question_title)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(os.getcwd(),folder_name)):</span><br><span class="line">            os.mkdir(folder_name)</span><br><span class="line">        os.chdir(folder_name)</span><br><span class="line"></span><br><span class="line">        f = open(file_name, <span class="string">"wt"</span>)</span><br><span class="line">        f.write(<span class="string">"-"</span> * <span class="number">40</span> + <span class="string">"\n"</span>)</span><br><span class="line">        origin_url = <span class="string">'https://www.zhihu.com/question/&#123;&#125;/answer/&#123;&#125;'</span>.format(question_id, answer_id)</span><br><span class="line">        f.write(<span class="string">"## 本答案原始链接: "</span> + origin_url + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### question_title: "</span> + question_title.encode(<span class="string">'utf-8'</span>) + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Author_Name: "</span> + author_name.encode(<span class="string">'utf-8'</span>) + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Answer_ID: %d"</span> % answer_id + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Question_ID %d: "</span> % question_id + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### VoteCount: %s"</span> % vote_up_count + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"### Create_Time: "</span> + create_time + <span class="string">"\n"</span>)</span><br><span class="line">        f.write(<span class="string">"-"</span> * <span class="number">40</span> + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">        text = html2text.html2text(content.decode(<span class="string">'utf-8'</span>)).encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        <span class="comment"># 标题</span></span><br><span class="line">        r = re.findall(<span class="string">r'**(.*?)**'</span>, text, re.S)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            <span class="keyword">if</span> i != <span class="string">" "</span>:</span><br><span class="line">                text = text.replace(i, i.strip())</span><br><span class="line"></span><br><span class="line">        r = re.findall(<span class="string">r'_(.*)_'</span>, text)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            <span class="keyword">if</span> i != <span class="string">" "</span>:</span><br><span class="line">                text = text.replace(i, i.strip())</span><br><span class="line">        text = text.replace(<span class="string">'_ _'</span>, <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图片</span></span><br><span class="line">        r = re.findall(<span class="string">r'![]\((?:.*?)\)'</span>, text)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> r:</span><br><span class="line">            text = text.replace(i, i + <span class="string">"\n\n"</span>)</span><br><span class="line"></span><br><span class="line">        f.write(text)</span><br><span class="line"></span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    zhihu = ZhiHu()</span><br><span class="line">    url = <span class="string">'https://www.zhihu.com/question/27621722/answer/105331078'</span></span><br><span class="line">    zhihu.get_single_answer_content(url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># question_id = '27621722'</span></span><br><span class="line">    <span class="comment"># zhihu.get_all_answer_content(question_id)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>zhihu.py为主脚本，内容很简单，发起请求，调用解析函数进行解析，最后再进行保存。 解析函数脚本：parse_content.py</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Created by shimeng on 17-6-5</span></span><br><span class="line">import time</span><br><span class="line"><span class="keyword">from</span> bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def html_template(data):</span><br><span class="line">    # api content</span><br><span class="line">    html = <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        &lt;html&gt;</span></span><br><span class="line"><span class="string">        &lt;head&gt;</span></span><br><span class="line"><span class="string">        &lt;body&gt;</span></span><br><span class="line"><span class="string">        %s</span></span><br><span class="line"><span class="string">        &lt;/body&gt;</span></span><br><span class="line"><span class="string">        &lt;/head&gt;</span></span><br><span class="line"><span class="string">        &lt;/html&gt;</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span> % data</span><br><span class="line">    return html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(content, <span class="attribute">flag</span>=None):</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> flag == 1:</span><br><span class="line">        # single</span><br><span class="line">        main_content = content.<span class="builtin-name">get</span>(<span class="string">'main_content'</span>)</span><br><span class="line">        ajax_content = content.<span class="builtin-name">get</span>(<span class="string">'ajax_content'</span>)</span><br><span class="line"></span><br><span class="line">        soup = BeautifulSoup(main_content.decode(<span class="string">"utf-8"</span>), <span class="string">"lxml"</span>)</span><br><span class="line">        answer = soup.<span class="builtin-name">find</span>(<span class="string">"span"</span>, <span class="attribute">class_</span>=<span class="string">"RichText CopyrightRichText-richText"</span>)</span><br><span class="line"></span><br><span class="line">        author_name = ajax_content.<span class="builtin-name">get</span>(<span class="string">'author'</span>).<span class="builtin-name">get</span>(<span class="string">'name'</span>)</span><br><span class="line">        answer_id = ajax_content.<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_id = ajax_content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_title = ajax_content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'title'</span>)</span><br><span class="line">        vote_up_count = soup.<span class="builtin-name">find</span>(<span class="string">"meta"</span>, <span class="attribute">itemprop</span>=<span class="string">"upvoteCount"</span>)[<span class="string">"content"</span>]</span><br><span class="line">        create_time = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(ajax_content.<span class="builtin-name">get</span>(<span class="string">'created_time'</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        # all</span><br><span class="line">        answer_content = content.<span class="builtin-name">get</span>(<span class="string">'content'</span>)</span><br><span class="line"></span><br><span class="line">        author_name = content.<span class="builtin-name">get</span>(<span class="string">'author'</span>).<span class="builtin-name">get</span>(<span class="string">'name'</span>)</span><br><span class="line">        answer_id = content.<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_id = content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">        question_title = content.<span class="builtin-name">get</span>(<span class="string">'question'</span>).<span class="builtin-name">get</span>(<span class="string">'title'</span>)</span><br><span class="line">        vote_up_count = content.<span class="builtin-name">get</span>(<span class="string">'voteup_count'</span>)</span><br><span class="line">        create_time = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(content.<span class="builtin-name">get</span>(<span class="string">'created_time'</span>)))</span><br><span class="line"></span><br><span class="line">        content = html_template(answer_content)</span><br><span class="line">        soup = BeautifulSoup(content, <span class="string">'lxml'</span>)</span><br><span class="line">        answer = soup.<span class="builtin-name">find</span>(<span class="string">"body"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="builtin-name">print</span> author_name,answer_id,question_id,question_title,vote_up_count,create_time</span><br><span class="line">    # 这里非原创，看了别人的代码，修改了一下</span><br><span class="line">    soup.body.extract()</span><br><span class="line">    soup.head.insert_after(soup.new_tag(<span class="string">"body"</span>, **&#123;<span class="string">'class'</span>: <span class="string">'zhi'</span>&#125;))</span><br><span class="line"></span><br><span class="line">    soup.body.append(answer)</span><br><span class="line"></span><br><span class="line">    img_list = soup.find_all(<span class="string">"img"</span>, <span class="attribute">class_</span>=<span class="string">"content_image lazy"</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        img[<span class="string">"src"</span>] = img[<span class="string">"data-actualsrc"</span>]</span><br><span class="line">    img_list = soup.find_all(<span class="string">"img"</span>, <span class="attribute">class_</span>=<span class="string">"origin_image zh-lightbox-thumb lazy"</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        img[<span class="string">"src"</span>] = img[<span class="string">"data-actualsrc"</span>]</span><br><span class="line">    noscript_list = soup.find_all(<span class="string">"noscript"</span>)</span><br><span class="line">    <span class="keyword">for</span> noscript <span class="keyword">in</span> noscript_list:</span><br><span class="line">        noscript.extract()</span><br><span class="line"></span><br><span class="line">    data[<span class="string">'content'</span>] = soup</span><br><span class="line">    data[<span class="string">'author_name'</span>] = author_name</span><br><span class="line">    data[<span class="string">'answer_id'</span>] = answer_id</span><br><span class="line">    data[<span class="string">'question_id'</span>] = question_id</span><br><span class="line">    data[<span class="string">'question_title'</span>] = question_title</span><br><span class="line">    data[<span class="string">'vote_up_count'</span>] = vote_up_count</span><br><span class="line">    data[<span class="string">'create_time'</span>] = create_time</span><br><span class="line"></span><br><span class="line">    return data</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>parse_content.py主要负责构造新的html，然后对其进行解析，获取数据。</p>
                  <h2 id="5-测试结果展示"><a href="#5-测试结果展示" class="headerlink" title="5.测试结果展示"></a><strong>5.测试结果展示</strong></h2>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/result.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/result.jpg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/result_2.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/06/result_2.jpg" alt=""></a> 恩，下面还有，就不截图了。</p>
                  <h2 id="6-缺点与不足"><a href="#6-缺点与不足" class="headerlink" title="6.缺点与不足"></a><strong>6.缺点与不足</strong></h2>
                  <p>下面聊一聊这种方法的缺点： 这种方法的最大缺点就是：</p>
                  <h1 id="一定要联网！"><a href="#一定要联网！" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <h1 id="一定要联网！-1"><a href="#一定要联网！-1" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <h1 id="一定要联网！-2"><a href="#一定要联网！-2" class="headerlink" title="一定要联网！"></a>一定要联网！</h1>
                  <p>因为。。。。。。 在md文件中我们只是写了个图片的网址，这就意味着markdown的编辑器帮我们去存放图片的服务器上对这个图片进行了获取，所以断网也就意味着你看不到图片了；同时也意味着如果用户删除了这张图片，你也就看不到了。 但是，后来我又发现在markdownpad中将文件导出为html时，即使是断网了，依然可以看到全部的内容，包括图片，所以如果你真的喜欢某一个答案，保存到印象笔记肯定是不错的选择，PDF直接保存也不错，如果是使用了这个方法，记得转为html最好。 还有一个缺点就是html2text转换过后的效果其实并不是特别好，还是需要后期在进行处理的。</p>
                  <h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a><strong>7.总结</strong></h2>
                  <p>代码还有很多可以改进之处，欢迎大家与我交流：QQ:549411552 （注明来自静觅） 国际惯例：<a href="https://github.com/xiaosimao/transfrom_zhihu_answer_to_md" target="_blank" rel="noopener">代码在这</a> 收工。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/四毛" class="author" itemprop="url" rel="index">四毛</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-06-05 23:50:07" itemprop="dateCreated datePublished" datetime="2017-06-05T23:50:07+08:00">2017-06-05</time>
                </span>
                <span id="/4607.html" class="post-meta-item leancloud_visitors" data-flag-title="获取知乎问题答案并转换为MarkDown文件" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>9.1k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4596.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4596.html" class="post-title-link" itemprop="url">使用Tornado+Redis维护ADSL拨号服务器代理池</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>我们尝试维护过一个免费的代理池，但是代理池效果用过就知道了，毕竟里面有大量免费代理，虽然这些代理是可用的，但是既然我们能刷到这个免费代理，别人也能呀，所以就导致这个代理同时被很多人使用来抓取网站，所以当我们兴致勃勃地拿他来抓取某个网站的时候，会发现它还是被网站封禁的状态，所以在某些情况下免费代理池的成功率还是比较低的。 当然我们也可以去购买一些代理，比如几块钱提取几百几千个的代理，然而经过测试后质量也是很一般，也可以去购买专线代理，不过价格也是不菲的。那么目前最稳定而且又保证可用的代理方法就是设置ADSL拨号代理了。 本篇来讲解一下ADSL拨号代理服务器的相关设置。</p>
                  <h2 id="什么是ADSL"><a href="#什么是ADSL" class="headerlink" title="什么是ADSL"></a>什么是ADSL</h2>
                  <p>大家可能对ADSL比较陌生，ADSL全称叫做Asymmetric Digital Subscriber Line，非对称数字用户环路，因为它的上行和下行带宽不对称。它采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。 有种主机叫做动态拨号VPS主机，这种主机在连接上网的时候是需要拨号的，只有拨号成功后才可以上网，每拨一次号，主机就会获取一个新的IP，也就是它的IP并不是固定的，而且IP量特别大，几乎不会拨到相同的IP，如果我们用它来搭建代理，既能保证高度可用，又可以自由控制拨号切换。 经测试发现这也是最稳定最有效的代理方式，本节详细介绍一下ADSL拨号代理服务器的搭建方法。</p>
                  <h2 id="购买动态拨号VPS主机"><a href="#购买动态拨号VPS主机" class="headerlink" title="购买动态拨号VPS主机"></a>购买动态拨号VPS主机</h2>
                  <p>所以在开始之前，我们需要先购买一台动态拨号VPS主机，这样的主机在百度搜索一下，服务商还是相当多的，在这里推荐一家<a href="http://www.yunlifang.cn/dynamicvps.asp" target="_blank" rel="noopener">云立方</a>，感觉还是比较良心的，非广告。 配置的话可以自行选择，看下带宽是否可以满足需求就好了。 购买完成之后，就需要安装操作系统了，进入拨号主机的后台，首先预装一个操作系统。 <img src="https://blog-10039692.file.myqcloud.com/1495175818199_5646_1495175827700.jpg" alt=""> 在这里推荐安装CentOS7系统。 然后找到远程管理面板找到远程连接的用户名和密码，也就是SSH远程连接服务器的信息。 比如我这边的IP端口分别是 153.36.65.214:20063，用户名是root。 命令行下输入：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">ssh <span class="symbol">root@</span><span class="number">153.36</span><span class="number">.65</span><span class="number">.214</span> -p <span class="number">20063</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 然后输入管理密码，就可以连接上远程服务器了。 进入之后，可以发现有一个可用的脚本文件，叫做ppp.sh，这是拨号初始化的脚本，运行它会让我们输入拨号的用户名和密码，然后它就会开始各种拨号配置，一次配置成功，后面的拨号就不需要重复输入用户名和密码了。 运行ppp.sh脚本，输入用户名密码等待它的配置完成。 <img src="https://blog-10039692.file.myqcloud.com/1495175987975_6876_1495175998841.jpg" alt=""> 都提示成功之后就可以进行拨号了。 在拨号之前如果我们测试ping任何网站都是不通的，因为当前网络还没联通，输入拨号命令：</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">adsl-<span class="literal">start</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>可以发现拨号命令成功运行，没有任何报错信息，这就证明拨号成功完成了，耗时约几秒钟。接下来如果再去ping外网就可以通了。 如果要停止拨号可以输入：</p>
                  <figure class="highlight arduino">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">adsl-<span class="built_in">stop</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>停止之后，可以发现又连不通网络了。</p>
                  <p>所以只有拨号之后才可以建立网络连接。 <img src="https://blog-10039692.file.myqcloud.com/1495176020258_290_1495176022867.jpg" alt=""> 所以断线重播的命令就是二者组合起来，先执行<code>adsl-stop</code>再执行<code>adsl-start</code>，每拨一次号，<code>ifocnfig</code>命令观察一下主机的IP，发现主机的IP一直是在变化的，网卡名称叫做ppp0。 <img src="https://blog-10039692.file.myqcloud.com/1495176189060_6947_1495176191282.jpg" alt=""> 所以，到这里我们就可以知道它作为代理服务器的巨大优势了，如果将这台主机作为代理服务器，如果我们一直拨号换IP，就不怕遇到IP被封的情况了，即使某个IP被封了，重新拨一次号就好了。 所以接下来我们要做的就有两件事，一是怎样将主机设置为代理服务器，二是怎样实时获取拨号主机的IP。</p>
                  <h2 id="设置代理服务器"><a href="#设置代理服务器" class="headerlink" title="设置代理服务器"></a>设置代理服务器</h2>
                  <p>之前我们经常听说代理服务器，也设置过不少代理了，但是可能没有自己设置吧，自己有一台主机怎样设置为代理服务器呢？接下来我们就亲自试验下怎样搭建HTTP代理服务器。 在Linux下搭建HTTP代理服务器，推荐TinyProxy和Squid，配置都非常简单，在这里我们以TinyProxy为例来讲解一下怎样搭建代理服务器。</p>
                  <h3 id="安装TinyProxy"><a href="#安装TinyProxy" class="headerlink" title="安装TinyProxy"></a>安装TinyProxy</h3>
                  <p>当然第一步就是安装TinyProxy这个软件了，在这里我使用的系统是CentOS，所以使用yum来安装，如果是其他系统如Ubuntu可以选择apt-get等命令安装，都是类似的。 命令行执行yum安装指令：</p>
                  <figure class="highlight sql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yum <span class="keyword">install</span> -y epel-<span class="keyword">release</span></span><br><span class="line">yum <span class="keyword">update</span> -y</span><br><span class="line">yum <span class="keyword">install</span> -y tinyproxy</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>运行完成之后就可以完成tinyproxy的安装了。</p>
                  <h3 id="配置TinyProxy"><a href="#配置TinyProxy" class="headerlink" title="配置TinyProxy"></a>配置TinyProxy</h3>
                  <p>安装完成之后还需要配置一下TinyProxy才可以用作代理服务器，需要编辑配置文件，它一般的路径是<code>/etc/tinyproxy/tinyproxy.conf</code>。 可以看到有一行</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Port <span class="number">8888</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>在这里可以设置代理的端口，默认是8888。 然后继续向下找，有这么一行</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">Allow <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这是被允许连接的主机的IP，如果想任何主机都可以连接，那就直接将它注释即可，所以在这里我们选择直接注释，也就是任何主机都可以使用这台主机作为代理服务器了。 修改为</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"># Allow <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>设置完成之后重启TinyProxy即可。</p>
                  <figure class="highlight crmsh">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">service tinyproxy <span class="literal">start</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>验证TinyProxy 好了，这样我们就成功搭建好代理服务器了，首先<code>ifconfig</code>查看下当前主机的IP，比如当前我的主机拨号IP为<code>112.84.118.216</code>，在其他的主机运行测试一下。 比如用curl命令设置代理请求一下httpbin，检测下代理是否生效。</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">curl -x <span class="number">112.84</span><span class="number">.118</span><span class="number">.216</span>:<span class="number">8888</span> httpbin.org/<span class="keyword">get</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p><img src="https://blog-10039692.file.myqcloud.com/1495176207822_2326_1495176209195.jpg" alt=""> 如果有正常的结果输出并且origin的值为代理IP的地址，就证明TinyProxy配置成功了。 好，那到现在，我们接下来要做的就是需要动态实时获取主机的IP了。</p>
                  <h2 id="动态获取IP"><a href="#动态获取IP" class="headerlink" title="动态获取IP"></a>动态获取IP</h2>
                  <p>真正的好戏才开始呢，我们怎样动态获取主机的IP呢？可能你首先想到的是DDNS也就是动态域名解析服务，我们需要使用一个域名来解析，也就是虽然IP是变的，但域名解析的地址可以随着IP的变化而变化。 它的原理其实是拨号主机向固定的服务器发出请求，服务器获取客户端的IP，然后再将域名解析到这个IP上就可以了。 国内比较有名的服务就是<a href="http://hsk.oray.com/" target="_blank" rel="noopener">花生壳</a>了，也提供了免费版的动态域名解析，另外DNSPOD也提供了解析接口来动态修改域名解析设置，<a href="https://www.dnspod.cn/docs/records.html#dns" target="_blank" rel="noopener">DNSPOD</a>，但是这样的方式都有一个通病，那就是慢！ 原因在于DNS修改后到完全生效是需要一定时间的，所以如果在前一秒拨号了，这一秒的域名解析的可能还是原来的IP，时间长的话可能需要几分钟，也就是说这段时间内，服务器IP已经变了，但是域名还是上一次拨号的IP，所以代理是不能用的，对于爬虫这种秒级响应的需求，是完全不能接受的。 所以根据花生壳的原理，可以完全自己实现一下动态获取IP的方法。 所以本节重点介绍的就是怎样来实现实时获取拨号主机IP的方法。 要实现这个需要两台主机，一台主机就是这台动态拨号VPS主机，另一台是具有固定公网IP的主机。动态VPS主机拨号成功之后就请求远程的固定主机，远程主机获取动态VPS主机的IP，就可以得到这个代理，将代理保存下来，这样拨号主机每拨号一次，远程主机就会及时得到拨号主机的IP，如果有多台拨号VPS，也统一发送到远程主机，这样我们只需要从远程主机取下代理就好了，保准是实时可用，稳定高效的。 整体思路大体是这样子，当然为了更完善一下，我们要做到如下功能： 远程主机：</p>
                  <ul>
                    <li>监听主机请求，获取动态VPS主机IP</li>
                    <li>将VPS主机IP记录下来存入数据库，支持多个客户端</li>
                    <li>检测当前接收到的IP可用情况，如果不可用则删除</li>
                    <li>提供API接口，通过API接口可获取当前可用代理IP</li>
                  </ul>
                  <p>拨号VPS：</p>
                  <ul>
                    <li>定时执行拨号脚本换IP</li>
                    <li>换IP后立即请求远程主机</li>
                    <li>拨号后检测是否拨号成功，如果失败立即重新拨号</li>
                  </ul>
                  <h3 id="远程主机实现"><a href="#远程主机实现" class="headerlink" title="远程主机实现"></a>远程主机实现</h3>
                  <p>说了这么多，那么我们就梳理一下具体的实现吧，整个项目我们用Python3实现。</p>
                  <h4 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h4>
                  <p>远程主机作为一台服务器，动态拨号VPS会定时请求远程主机，远程主机接收到请求后将IP记录下来存入数据库。 因为IP是一直在变化的，IP更新了之后，原来的IP就不能用了，所以对于一个主机来说我们可能需要多次更新一条数据。另外我们不能仅限于维护一台拨号VPS主机，当然是需要支持多台维护的。在这里我们直接选用Key-Value形式的非关系型数据库存储更加方便，所以在此选用Redis数据库。 既然是Key-Value，Key是什么?Value是什么?首先我们能确定Value就是代理的值，比如112.84.119.67:8888，那么Key是什么？我们知道，这个IP是针对一台动态拨号VPS的，而且这个值会不断地变，所以我们需要有一个不变量Key来唯一标识这台主机，所以在这里我们可以把Key当做主机名称。名称怎么来？自己取就好了，只要每台主机的名字不重复，我们就可以区分出是哪台主机了，这个名字可以在拨号主机那边指定，然后传给远程主机就好了。 所以，在这里数据库我们选用Redis，Key就是拨号主机的名称，可以自己指定，Value就是代理的值。 所以可以写一个操作Redis数据库的类，参考如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisClient</span>(<span class="title">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, host=REDIS_HOST, port=REDIS_PORT)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.db = redis.Redis(host=host, port=port, password=REDIS_PASSWORD)</span><br><span class="line">        <span class="keyword">self</span>.proxy_key = PROXY_KEY</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">key</span><span class="params">(<span class="keyword">self</span>, name)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'&#123;key&#125;:&#123;name&#125;'</span>.format(key=<span class="keyword">self</span>.proxy_key, name=name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set</span><span class="params">(<span class="keyword">self</span>, name, proxy)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.db.set(<span class="keyword">self</span>.key(name), proxy)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(<span class="keyword">self</span>, name)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.db.get(<span class="keyword">self</span>.key(name)).decode(<span class="string">'utf-8'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先初始化Redis连接，我们可以将Key设计成<code>adsl:vm1</code>这种形式，冒号前面是总的key，冒号后面是主机名称name，这样显得结构更加清晰。 然后指定set()和get()方法，用来存储代理和获取代理。</p>
                  <h4 id="请求处理"><a href="#请求处理" class="headerlink" title="请求处理"></a>请求处理</h4>
                  <p>拨号主机会一直向远程主机发送请求，远程主机当然可以获取拨号主机的IP，但是代理端口是无法获得的，我们在拨号主机上设置了TinyProxy或者Squid，但是服务器不知道是在哪个端口开的，所以端口也是需要客户端传给远程主机的。远程主机接收到请求后，将解析得到的IP和端口合并就可以作为完整的代理保存了。 所以现在我们知道拨号主机需要传送给远程主机的信息已经有两个了，一是拨号主机本身的名称，二是代理的端口。</p>
                  <h4 id="通信秘钥"><a href="#通信秘钥" class="headerlink" title="通信秘钥"></a>通信秘钥</h4>
                  <p>为了保证远程主机不被恶意的请求干扰，可以设置一个传输秘钥，最简单的方式可以二者共同规定一个秘钥字符串，拨号主机在传送这个字符串，远程主机匹配一下，如果能正确匹配，那就进行下一步的处理，如果不能匹配，那么可能是恶意请求，就忽略这个请求。 当然肯定有更好的加密传输方式，但为了方便起见可以用如上来做。 所以客户机还需要传送一个数据，那就是通信秘钥，一共需要传送三个数据。 所以我们需要架设一个服务器，一直监听客户端的请求，在这里我们用tornado实现。 tornado的安装也非常简单，利用pip安装即可：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> tornado</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>定义一个处理拨号主机请求的方法，在这里我们使用post请求，参考如下。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def post(self):</span><br><span class="line">        token = self.get_body_argument(<span class="string">'token'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">       <span class="built_in"> port </span>= self.get_body_argument(<span class="string">'port'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">        name = self.get_body_argument(<span class="string">'name'</span>, <span class="attribute">default</span>=None, <span class="attribute">strip</span>=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> token == TOKEN <span class="keyword">and</span> port:</span><br><span class="line">           <span class="built_in"> ip </span>= self.request.remote_ip</span><br><span class="line">           <span class="built_in"> proxy </span>=<span class="built_in"> ip </span>+ <span class="string">':'</span> + port</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">'Receive proxy'</span>, proxy)</span><br><span class="line">            self.redis.<span class="builtin-name">set</span>(name, proxy)</span><br><span class="line">            self.test_proxies()</span><br><span class="line">        elif token != TOKEN:</span><br><span class="line">            self.write(<span class="string">'Wrong Token'</span>)</span><br><span class="line">        elif <span class="keyword">not</span> port:</span><br><span class="line">            self.write(<span class="string">'No Client Port'</span>)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>远程主机获取请求的token，也就是上面我们所说的通信密钥，保证安全。port是拨号机的代理端口，name是拨号主机的名称。然后我们再获取请求的remote_ip，也就是拨号主机的IP。然后将IP和端口拼合就可以得到拨号主机的完整代理信息了，将其存入数据库即可。</p>
                  <h4 id="代理检测"><a href="#代理检测" class="headerlink" title="代理检测"></a>代理检测</h4>
                  <p>在远程主机端我们需要做一下代理检测，如果某个代理不可用了，会及时将其去除，以免出现获取到代理后不可用的情况。</p>
                  <blockquote>
                    <p>注意：在这里在拨号主机端验证是不够的，因为可能突然遇到某个拨号主机宕机的情况，这样拨号主机就不会再向远程主机发送请求，而最后一次得到的代理还会存在于数据库中，所以在远程主机端统一验证比较科学。</p>
                  </blockquote>
                  <p>验证方式可以定时检测，也可以每收到一次请求检测一次，用获取到的代理来请求某个网站，检测一下是否能访问即可。如果不能，将其从数据库中删除。</p>
                  <h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4>
                  <p>远程主机已经将拨号主机的IP和端口保存下来了，那也就是说，所有的可用的代理已经在远程主机保存了，我们需要提供一个接口来将代理获取下来。 比如我们可以提供这么几个方法，获取所有代理，获取最新代理，获取随机代理等等。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">all</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    keys = <span class="keyword">self</span>.keys()</span><br><span class="line">    proxies = [&#123;<span class="string">'name'</span>: key, <span class="string">'proxy'</span>: <span class="keyword">self</span>.get(key)&#125; <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">    <span class="keyword">return</span> proxies</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    items = <span class="keyword">self</span>.all()</span><br><span class="line">    <span class="keyword">return</span> random.choice(items).get(<span class="string">'proxy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">list</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    keys = <span class="keyword">self</span>.keys()</span><br><span class="line">    proxies = [<span class="keyword">self</span>.get(key) <span class="keyword">for</span> key <span class="keyword">in</span> keys]</span><br><span class="line">    <span class="keyword">return</span> proxies</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">first</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">self</span>.get(<span class="keyword">self</span>.keys()[<span class="number">0</span>])</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后用tornado搭建API服务，如果可以的话还可以绑定一个域名，更加便捷，举例如下： 获取随机代理： <img src="https://blog-10039692.file.myqcloud.com/1495176234257_8333_1495176237128.jpg" alt=""> 获取最新代理： <img src="https://blog-10039692.file.myqcloud.com/1495176256328_2908_1495176259312.jpg" alt=""> 获取所有代理： <img src="https://blog-10039692.file.myqcloud.com/1495176279029_802_1495176279909.jpg" alt=""> 请求接口获取可用代理即可，比如获取一个随机代理：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_proxy</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 远程主机的服务地址</span></span><br><span class="line">        url = <span class="string">'http://xxx.xxx.xxx.xxx:8000/random'</span></span><br><span class="line">        <span class="keyword">return</span> requests.get(url).text</span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.ConnectionError:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们拿到的IP都是稳定可用的，而且过段时间重新请求取到的IP就会变化，是一直动态变化的高可用代理。</p>
                  <h3 id="拨号VPS实现"><a href="#拨号VPS实现" class="headerlink" title="拨号VPS实现"></a>拨号VPS实现</h3>
                  <h4 id="定时拨号"><a href="#定时拨号" class="headerlink" title="定时拨号"></a>定时拨号</h4>
                  <p>拨号VPS需要每隔一段时间就拨号一次，我们可以直接执行命令行来拨号，那在Python里我们只需要调用一下这个拨号命令就好了。利用subprocess模块调用脚本即可，在这里定义一个变量ADSL_BASH为<code>adsl-stop;adsl-start</code>，这就是拨号的脚本。</p>
                  <figure class="highlight cpp">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line">(status, output) = subprocess.getstatusoutput(ADSL_BASH)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>通过getstatusoutput方法可以获取脚本的执行状态和输出结果，如果status为0，则证明拨号成功，然后检测一下拨号接口是否获取了IP地址。 执行<code>ifconfig</code>命令可以获取当前的IP，我这台主机接口名称叫做ppp0，当然网卡名称可以自己指定，所以将ppp0接口的IP提取出来即可。</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def get_ip(self, <span class="attribute">ifname</span>=ADSL_IFNAME):</span><br><span class="line">    (status, output) = subprocess.getstatusoutput(<span class="string">'ifconfig'</span>)</span><br><span class="line">    <span class="keyword">if</span> status == 0:</span><br><span class="line">        pattern = re.compile(ifname + <span class="string">'.*?inet.*?(\d+\.\d+\.\d+\.\d+).*?netmask'</span>, re.S)</span><br><span class="line">        result = re.search(pattern, output)</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">           <span class="built_in"> ip </span>= result.group(1)</span><br><span class="line">            return ip</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>如果方法正常返回IP，则证明IP存在，拨号成功，接下来向远程主机发送请求即可，然后sleep一段时间重新再次拨号。 如果方法返回的值为空，那证明IP不存在，我们需要重新拨号。</p>
                  <h4 id="请求远程主机"><a href="#请求远程主机" class="headerlink" title="请求远程主机"></a>请求远程主机</h4>
                  <p>发送的时候需要携带这么几个信息，一个是通信秘钥，一个是代理端口，另一个是主机的标识符，用requests发送即可。</p>
                  <figure class="highlight haskell">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="title">requests</span>.post(<span class="type">SERVER_URL</span>, <span class="class"><span class="keyword">data</span>=&#123;'<span class="title">token'</span>: <span class="type">TOKEN</span>, '<span class="title">port'</span>: <span class="type">PROXY_PORT</span>, '<span class="title">name'</span>: <span class="type">CLIENT_NAME</span>&#125;)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>所以整体的思路实现可以写成这样子：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def adsl(self):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="builtin-name">print</span>(<span class="string">'ADSL Start, Please wait'</span>)</span><br><span class="line">            (status, output) = subprocess.getstatusoutput(ADSL_BASH)</span><br><span class="line">            <span class="keyword">if</span> status == 0:</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">'ADSL Successfully'</span>)</span><br><span class="line">               <span class="built_in"> ip </span>= self.get_ip()</span><br><span class="line">                <span class="keyword">if</span> ip:</span><br><span class="line">                    <span class="builtin-name">print</span>(<span class="string">'New IP'</span>, ip)</span><br><span class="line">                    try:</span><br><span class="line">                        requests.post(SERVER_URL, data=&#123;<span class="string">'token'</span>: TOKEN, <span class="string">'port'</span>: PROXY_PORT, <span class="string">'name'</span>: CLIENT_NAME&#125;)</span><br><span class="line">                        <span class="builtin-name">print</span>(<span class="string">'Successfully Sent to Server'</span>, SERVER_URL)</span><br><span class="line">                    except ConnectionError:</span><br><span class="line">                        <span class="builtin-name">print</span>(<span class="string">'Failed to Connect Server'</span>, SERVER_URL)</span><br><span class="line">                    time.sleep(ADSL_CYCLE)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="builtin-name">print</span>(<span class="string">'Get IP Failed'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="builtin-name">print</span>(<span class="string">'ADSL Failed, Please Check'</span>)</span><br><span class="line">            time.sleep(1)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就可以做到定时拨号并向远程主机发送请求了。</p>
                  <h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2>
                  <p>Talk is cheap, show me the code! 在这里提供一份完整代码实现，其中client模块是在动态VPS主机运行，server模块在远程主机运行，具体的操作使用可以参考README。 <a href="https://github.com/Germey/ADSLProxyPool" target="_blank" rel="noopener">ADSLProxyPool</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-19 14:50:15" itemprop="dateCreated datePublished" datetime="2017-05-19T14:50:15+08:00">2017-05-19</time>
                </span>
                <span id="/4596.html" class="post-meta-item leancloud_visitors" data-flag-title="使用Tornado+Redis维护ADSL拨号服务器代理池" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>7.8k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>7 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4534.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4534.html" class="post-title-link" itemprop="url">Scrapyd日志输出优化</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>现在维护着一个新浪微博爬虫，爬取量已经5亿+，使用了Scrapyd部署分布式。 Scrapyd运行时会输出日志到本地，导致日志文件会越来越大，这个其实就是Scrapy控制台的输出。但是这个日志其实有用的部分也就是最后那几百行而已，如果出错，去日志查看下出错信息就好了。 所以现在可以写一个脚本，来定时更新日志文件，将最后的100行保存下来就好了。 Scrapyd默认的日志目录是在用户文件夹下的logs目录。 所以在这里我们指定dir=~/logs 新建bash脚本，内容如下：</p>
                  <figure class="highlight bash">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">clean</span></span>() &#123;</span><br><span class="line">  <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$1</span>/*</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ -d <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">      clean <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="variable">$file</span></span><br><span class="line">      temp=$(tail -100 <span class="variable">$file</span>)</span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"<span class="variable">$temp</span>"</span> &gt; <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dir=~/logs</span><br><span class="line">clean <span class="variable">$dir</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>新建这样的一个脚本，然后命名为 clean.sh，我的直接放在了用户文件夹下。 然后crontab创建定时任务。 执行</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">crontab -e</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们想要一分钟清理一次日志文件。 输入</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">*<span class="string">/1</span> * * * * <span class="string">/bin/sh</span> ~<span class="string">/clean.sh</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后退出之后，crontab就可以每隔一分钟执行一次clean.sh，清理日志了。 这样我们就不怕日志文件大量占用主机空间啦~</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-17 14:49:03" itemprop="dateCreated datePublished" datetime="2017-05-17T14:49:03+08:00">2017-05-17</time>
                </span>
                <span id="/4534.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapyd日志输出优化" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>579</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4465.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4465.html" class="post-title-link" itemprop="url">免登录新浪微博爬虫系列之第一篇 单博主微博及评论数据</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <blockquote>
                    <p>我的GITHUB地址：<a href="https://github.com/xiaosimao/weibo_spider" target="_blank" rel="noopener">https://github.com/xiaosimao/weibo_spider</a> 2017.05.04 更新： 感谢哥本哈根小树对于获取containnerid的指教，多谢。</p>
                    <pre><code>_**大家好，我是新人四毛，大家可以叫我小四毛，至于为什么，在家排行老四，农村人，就是那么任性。**_
</code></pre>
                  </blockquote>
                  <pre><code>好，自我介绍完毕，开始今天的学（zhuang）习（bi）之路。
</code></pre>
                  <blockquote>
                    <p><strong>说明：本文针对的是有一些爬虫基础的同学，所以看不太懂的同学先补一下基础。</strong></p>
                    <p><strong>本文的全部代码并没有上传到GITHUB中，而且本文的code部分给出的代码也是指导性的，大部分还是要靠大家自己动手完成。待后几篇博客出来以后，代码会放到上面。</strong></p>
                    <p><strong>大家如果有问题交流的话，欢迎在下面进行评论，或者可以加我QQ:549411552(加的话麻烦注明来自静觅)，欢迎大佬拍砖指错，大家共同进步。</strong></p>
                  </blockquote>
                  <pre><code>前几天，大才发布了一个视频，主要讲的是通过维护一个新浪微博 Cookies池，抓取新浪微博的相关数据，爬取的站点是weibo.cn。相关的代码在大才的Github里【大才的视频教程真的很用心，视频高清无码，希望大家可以支持大才，毕竟写了那么多精彩的教程真心不易】。

然而，如果你只是想简单的搞点数据，对技术一点兴趣都没有，又或者某宝搜来搜去都没有买到账号，又或者装个模拟登陆需要的模块都想跳楼，有没有除此之外其他的办法呢？你有没有想过在免登陆的情况下就可以获得你想要的数据呢？如果你这么想过而又没有做出来，那么接下来，让我们一起搞（qi）事（fei）吧。
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a></p>
                  <p>本文重点提供解决问题的思路，会把最关键的点标示出来，代码基本没有。有什么不对或不足之处，还望大家指出，共同进步。</p>
                  <h3 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1.前期准备"></a>1.前期准备</h3>
                  <pre><code> 代理IP。虽说本文介绍的方法不需要Cookies，但是代理IP还是需要的，要不然也是被新浪分分钟的403（我测试的时候会出现）。如果你连403都不知道是什么，那么还是去看看大才的爬虫基础课程，或者不想看文字的话直接来报大才的视频课程课，哈哈（大才，今晚得加两个菜啊，我这吆喝的）。
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/兔子.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/兔子.gif" alt=""></a></p>
                  <h3 id="2-思路分析"><a href="#2-思路分析" class="headerlink" title="2.思路分析"></a>2.思路分析</h3>
                  <pre><code>一般做爬虫爬取网站，首选的都是m站，其次是wap站，最后考虑PC站。当然，这不是绝对的，有的时候PC站的信息最全，而你又恰好需要全部的信息，那么PC站是你的首选。一般m站都以m开头后接域名，试一下 就好了，实在找不到，上网搜。

所以本文开搞的网址就是 m.weibo.cn。但是当你在浏览器中输入这个网址时，你得到的应该是下面这个页面，如果不是，说明你的浏览器保留了你最近登录微博的cookie，这个时候，清空浏览器保存的数据，再次打开这个网页，就应该也是这个界面了：
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/login-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/login-1.jpg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/login.jpg" target="_blank" rel="noopener"></a> 我滴天，是的，你没看错，就是这个登录界面。你不是说不需要登录吗？怎么TM的还是这个万恶的界面？怎么破？WTF?</p>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/表情2.jpg" alt=""></a></p>
                  <pre><code>哈哈，其实一开始我也不知道，后来经人指点，才发现只要在后面加入一些东西之后就不会看到这个界面了。那么是什么呢？
</code></pre>
                  <p><em><strong>当当当当！！！！！！！！！！</strong></em></p>
                  <blockquote>
                    <p><strong><a href="http://m.weibo.cn/u/1713926427" target="_blank" rel="noopener">http://m.weibo.cn/u/1713926427</a></strong></p>
                  </blockquote>
                  <p> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/表情1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/表情1-300x300.jpg" alt=""></a></p>
                  <pre><code>当你看到这个网址的时候，憋说话，一定要用心去感受，这个时候说话你的嘴都是咧着的，别问我为什么知道，我就是知道。

**用心去感受，真的。**

对了，上面网址最后的数字是博主的数字ID，在weibo.com的源码里可以找到，这里不做说明了。

打开上述网址， 界面变成这个样子，是不是很厉害的样子（大手勿喷），拨云见日，对于老手来说，下面的他们就可以不看了，可以去抓包写代码了，但是对于一头雾水的小伙伴请接着往下看：
</code></pre>
                  <p> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_page-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_page-1.jpg" alt=""></a></p>
                  <pre><code>这就是本文爬虫的入口，没错，就说牛逼的榜姐，入口选一些质量高的，比如你想爬新闻方面信息，那么你就去找澎湃新闻，新浪新闻之类的。

通过该入口，我们可以抓取该博主的所有微博及评论信息，以及该博主关注的人的微博及评论信息，依次往后，循环不断。

在这里谈一点经验：
</code></pre>
                  <p> <strong>其实做爬虫，最基础的当然是写代码的能力，抓包什么的都不是什么困难的事，抓包很简单很简单。我觉得最难的是找到入口，找到一个最适合的入口。怎么定义这个最适合呢？就是要去尝试，依照一般的顺序，先找找M站，再找找wap站，最后再去看PC站，找到一个合适的入口，往往会事半功倍。前几天抓取途牛网的相关游记信息，爬PC站分分钟的302，但是爬M站，全是接口，全程无阻。</strong></p>
                  <pre><code>因大多数人都是采集微博信息以及评论信息，所以下面将以这两方面为主。

剧透一下，在这里可以抓到的信息：

(1) **博主信息 （没发现有价值的信息，下面抓包过程不讲）**

(2) **博主微博信息（下文抓包讲解）**

(3) **微博评论信息（下文抓包讲解）**

(4) **热门微博信息（小时榜，日榜，周榜，月榜）（下文抓包未讲解，大家可以摸索一下）**

       。。。。。。还有很多我没有细看，等待各位细细研究吧。
</code></pre>
                  <h3 id="3-抓包分析"><a href="#3-抓包分析" class="headerlink" title="3. 抓包分析"></a>3. 抓包分析</h3>
                  <pre><code>首先，得会抓包，一般的浏览器的Network够用了。
</code></pre>
                  <p> <strong>(1) 微博正文抓包</strong></p>
                  <pre><code>点击 上图中的微博然后往下拉，抓包出现下图：
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1.jpg" target="_blank" rel="noopener"></a><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/post_content_zhuabao-1-1.jpg" alt=""></a></p>
                  <p><strong>分析：</strong></p>
                  <blockquote>
                    <pre><code>可以看到，服务器返回的数据为json格式，这个是做爬虫的最喜欢的了。返回的数据包括很多的字段，图中也以及做了标示，相信大家都能看的懂，看不懂那也没办法了。
</code></pre>
                  </blockquote>
                  <pre><code>最后放上抓包的数据：
</code></pre>
                  <blockquote>
                    <ol>
                      <li>
                        <p><strong>Request URL</strong>:</p>
                        <p><a href="http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=1713926427&amp;containerid=1076031713926427&amp;page=2" target="_blank" rel="noopener">http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=1713926427&amp;containerid=1076031713926427&amp;page=2</a></p>
                      </li>
                      <li>
                        <p><strong>Request Method</strong>:</p>
                        <p>GET</p>
                      </li>
                      <li>
                        <p><strong>Query String Parameters</strong></p>
                        <p>type: uid</p>
                        <p>value: 1713926427</p>
                        <p>containerid: 1076031713926427</p>
                        <p>page: 2</p>
                      </li>
                    </ol>
                  </blockquote>
                  <pre><code>**(2) 微博评论抓包**

单击微博内容，就可以抓包成功，如下图：
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao.jpg" target="_blank" rel="noopener"></a><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao-1.jpg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/comment_zhuabao.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <pre><code>从上面可以看出，这里的数据依然还是很好获取的。
</code></pre>
                  </blockquote>
                  <pre><code>最后放上抓包的数据：
</code></pre>
                  <blockquote>
                    <ol>
                      <li>
                        <p><strong>Request URL</strong>:</p>
                        <p><a href="http://m.weibo.cn/api/comments/show?id=4103388327019042&amp;page=1" target="_blank" rel="noopener">http://m.weibo.cn/api/comments/show?id=4103388327019042&amp;page=1</a></p>
                      </li>
                      <li>
                        <p><strong>Request Method</strong>:</p>
                        <p>GET</p>
                      </li>
                      <li>
                        <p><strong>Query String Parameters</strong></p>
                        <p>id: 4103388327019042</p>
                        <p>page: 1</p>
                      </li>
                    </ol>
                  </blockquote>
                  <p> <strong>再次分析：</strong></p>
                  <blockquote>
                    <pre><code>通过抓包的数据可以发现，获取微博评论必须首先获得这条微博的ID。所以，目前还是要对微博正文的抓包过程进行分析。
</code></pre>
                  </blockquote>
                  <h3 id="4-思路解析"><a href="#4-思路解析" class="headerlink" title="4. 思路解析"></a>4. 思路解析</h3>
                  <pre><code>在上面的微博正文中发现需要提交以下数据：
</code></pre>
                  <blockquote>
                    <p>type: uid</p>
                    <p>value: 1713926427</p>
                    <p>containerid: 1076031713926427</p>
                    <p>page: 2</p>
                  </blockquote>
                  <pre><code>其中：**type**(固定值)、**value**(博主微博ID)、**containerid**(意义不明确，但是带了个id在里面，应该代表的是一个唯一性的一个标识)、**page**(页码)。页码在返回的数据中可以获得。

那么分析到这里，containerid就是我们要找的最重要的信息。这个字段信息是不会凭空出现的，肯定产生于某一个请求之中，所以这时候，我们再回到开头，回到我们的初始。刷新入口网址，抓包发现了下面3个网址，见下图：
</code></pre>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao.jpg" target="_blank" rel="noopener"></a><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao-1.jpg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/home_zhuabao.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <pre><code>这3个网址的格式一模一样，所以点进去看一下里面到底什么情况。
</code></pre>
                  </blockquote>
                  <p> 下面的先点开<strong>网址1</strong>看看：</p>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg.jpg" target="_blank" rel="noopener"></a><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg-1.jpg" alt=""></a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/user_infojpg.jpg" target="_blank" rel="noopener"></a> <strong> 分析：</strong></p>
                  <blockquote>
                    <pre><code>从返回的数据中，可以看到第1个网址的主要内容为 user_Info，即博主的个人信息，相关的字段在图中已经标示出来。最令人惊喜的是查找我们需要的containerid时，发现数据竟然就在其中，那么可以肯定我们需要的containerid就是在这个请求的返回值中，那么问题再次出现，这个请求的网址中又出现了一个containerid，我们似乎又回到了原点，而且在用户的首页抓包中，在这个请求之前，也没有什么有意义的请求了，到这里是不是就进入死胡同了呢？其实不然，在这里我们就要进行多方面的尝试了，当我们将第一个网址中的containerid删掉以后，重新请求一次，发现返回的依然是这些数据，具体见下图：
</code></pre>
                  </blockquote>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/no_containid-1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/05/no_containid-1.jpg" alt=""></a></p>
                  <p> <strong>分析：</strong></p>
                  <blockquote>
                    <pre><code>而当我将第三个网址，也就是微博正文的网址中的containerid去掉后，返回的数据就是博主的个人信息了，而不是我们需要的微博正文，所以可以肯定第一个网址中的containerid并不是必须的，而对于网址3，这个字段则是必须的。
</code></pre>
                  </blockquote>
                  <pre><code>为了让这个爬虫可以顺着一个初始用户爬取到其他用户的相关信息，甚至全网的信息，那么我们就需要让爬虫自己去添加待爬任务。本文选择的初始用户有3000多万的粉丝数，就是人们常说的微博大V。在做这一类的信息爬取时，我们往往关注的是数据的质量，所以我们选择初始用户的关注用户作为下一级的用户。在下一级中，这些用户将被作为初始用户。这样周而复始，最理想的情况当然就是可以把微博全站的质量还不错的博主的微博以及下面的评论都抓取了。但是在实际的操作过程中会发现微博的用户质量真的是参差不齐，所以我们在筛选后面的用户时，可以加一些限制条件，如用户的粉丝数等等。在这里找寻初始用户关注用户信息的这一过程就省略了，留给大家探索一下，很简单。
</code></pre>
                  <p>所以到这里，我们的整个流程就理清了（单个博主，如需循环，则只需要找到下一级用户的ID即可，相信这对于聪明的大家肯定不难的）：</p>
                  <blockquote>
                    <p>请求用户主页网址—&gt;得到containerid，请求微博正文网址—&gt;保存博文相关信息，取出博文ID，请求评论网址—&gt;得到评论信息</p>
                  </blockquote>
                  <h3 id="5-CODE-TIME"><a href="#5-CODE-TIME" class="headerlink" title="5. CODE TIME"></a>5. CODE TIME</h3>
                  <pre><code>思路已经理清了，那么下面就是CODE TIME了，毕竟:
</code></pre>
                  <blockquote>
                    <p>TALK IS CHEAP,SHOW ME YOUR CODE</p>
                  </blockquote>
                  <pre><code>本文采用scrapy编写，重写个proxy中间件，即可实现每一个request带一个随机IP，减少被封禁的概率，同时尽量把重试的次数设置大一些。

想要保存哪些信息，根据自身的业务需求而定，具体的信息，能找到的都可以在每一个请求返回的内容中找到，都是json格式的，所以这里的代码只是将上面讲的流程实现了一遍，其他的都没有实现。
</code></pre>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">class SinaSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">"sina"</span></span><br><span class="line">    allowed_domains = [<span class="string">"m.weibo.cn"</span>]</span><br><span class="line">    # root id</span><br><span class="line">    first_id = <span class="string">'1713926427'</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        # <span class="keyword">to</span> <span class="builtin-name">get</span> containerid</span><br><span class="line">        url = <span class="string">'http://m.weibo.cn/api/container/getIndex?type=uid&amp;value=&#123;&#125;'</span>.format(self.first_id)</span><br><span class="line">        yield scrapy.Request(<span class="attribute">url</span>=url, <span class="attribute">callback</span>=self.get_containerid)</span><br><span class="line"></span><br><span class="line">    def get_containerid(self,response):</span><br><span class="line">        content = json.loads(response.body)</span><br><span class="line">        # here, we can <span class="builtin-name">get</span> containerid</span><br><span class="line">        containerid = None</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span>  content.<span class="builtin-name">get</span>(<span class="string">'tabsInfo'</span>).<span class="builtin-name">get</span>(<span class="string">'tabs'</span>):</span><br><span class="line">            <span class="keyword">if</span> data.<span class="builtin-name">get</span>(<span class="string">'tab_type'</span>) == <span class="string">'weibo'</span>:</span><br><span class="line">                containerid = data.<span class="builtin-name">get</span>(<span class="string">'containerid'</span>)</span><br><span class="line">                <span class="builtin-name">print</span> <span class="string">'weibo request url containerid is %s'</span> % containerid</span><br><span class="line"></span><br><span class="line">        # construct the wei bo request url</span><br><span class="line">        <span class="keyword">if</span> containerid:</span><br><span class="line">            weibo_url = response.url + <span class="string">'&amp;containerid=%s'</span>%containerid</span><br><span class="line">            yield scrapy.Request(<span class="attribute">url</span>=weibo_url, <span class="attribute">callback</span>=self.get_weibo_id)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="builtin-name">print</span> <span class="string">'sorry, do not get containerid'</span></span><br><span class="line"></span><br><span class="line">    def get_weibo_id(self, response):</span><br><span class="line">        content = json.loads(response.body)</span><br><span class="line">        # <span class="builtin-name">get</span> weibo id ,you can also save some other data <span class="keyword">if</span> you need</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> content.<span class="builtin-name">get</span>(<span class="string">'cards'</span>):</span><br><span class="line">            <span class="keyword">if</span> data.<span class="builtin-name">get</span>(<span class="string">'card_type'</span>) == 9:</span><br><span class="line">                single_weibo_id = data.<span class="builtin-name">get</span>(<span class="string">'mblog'</span>).<span class="builtin-name">get</span>(<span class="string">'id'</span>)</span><br><span class="line">                <span class="builtin-name">print</span> single_weibo_id</span><br><span class="line">                # here ,<span class="keyword">if</span> you want <span class="keyword">to</span> <span class="builtin-name">get</span> comment <span class="builtin-name">info</span> ,you can construct the comment url just the same as wei bo url</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h3>
                  <pre><code>本文写到这里就算结束了，我一直信奉授人以鱼不如授人以渔，在这篇文章中，我并没有把全部的代码展示出来，而是通过分析的过程来让大家知道怎么去处理这类问题，在文中也留了好几个可以让大家发挥的地方，如用户关注用户怎么获取？按照关键词搜索的信息怎么抓取？等等。我相信大家通过一步步的抓包以及分析一定可以解决这些问题的。这些问题，在以后的博客中我也会继续更新的。

第一次写这样的博客，感觉还是驾驭不了，还是得多多练习。写博客真的很累，向大才致敬，感谢他无私的为我们奉献了这么多精彩的教程。
</code></pre>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/四毛" class="author" itemprop="url" rel="index">四毛</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-05-04 12:56:51" itemprop="dateCreated datePublished" datetime="2017-05-04T12:56:51+08:00">2017-05-04</time>
                </span>
                <span id="/4465.html" class="post-meta-item leancloud_visitors" data-flag-title="免登录新浪微博爬虫系列之第一篇  单博主微博及评论数据" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>5.4k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>5 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4421.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4421.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第四篇（图片下载管道篇）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><strong>PS： 爬虫不进入img_url函数的小伙伴儿 请尝试将将代码复制到你新建的py文件中。</strong> 2017/8/30 更新解决了网站防盗链导致下载图片失败的问题 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt=""></a> 这几天一直有小伙伴而给我吐槽说，由于妹子图站长把www.mzitu.com/all这个地址取消了。导致原来的那个采集爬虫不能用啦。 正好也有小伙伴儿问Scrapy中的图片下载管道是怎么用的。 就凑合在一起把mzitu.com给重新写了一下。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/9555112.jpg" alt=""></a> 首先确保你的Python环境已安装 Scrapy!!!!!!!! 命令行下进入你需要存放项目的目录并创建项目： 比如我放在了D:\PycharmProjects</p>
                  <figure class="highlight properties">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">D</span>:<span class="string"></span></span><br><span class="line"><span class="attr">cd</span> <span class="string">PycharmProjects</span></span><br><span class="line"><span class="attr">scrapy</span> <span class="string">startproject mzitu_scrapy</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我是Windows！其余系统的伙伴儿自己看着办哈。 这都不会的小伙伴儿，快去洗洗睡吧。养足了精神从头看一遍教程哈！ 在PyCharm中打开我们的项目目录。 在mzitu_scrapy目录创建run.py。写入以下内容：</p>
                  <figure class="highlight smali">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">from scrapy.cmdline import execute</span><br><span class="line">execute(['scrapy', 'crawl', 'mzitu'])</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>其中的 mzitu 就为待会儿spider.py文件中的name属性。这点请务必记住哦！不然是跑不起来的。 在mzitu_scrapy\spider目录中创建spider.py。文件作为爬虫文件。 好了！现在我们来想想，怎么来抓mzitu.com了。 首先我们的目标是当然是全站的妹子图片！！！ 但是问题来了，站长把之前那个mzitu.com\all 这个URL地址给取消了，我们没办法弄到全部的套图地址了！ 我们可以去仔细观察一下站点所有套图的地址都是：<a href="http://www.mzitu.com/几位数字结尾的。" target="_blank" rel="noopener">http://www.mzitu.com/几位数字结尾的。</a> 这种格式地址。 有木有小伙伴儿想到了啥？ <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161022193315.gif" alt=""></a> CrawlSpider ！！！就是这玩儿！！ 有了它我们就能追踪“<a href="http://www.mzitu.com/几位数字结尾的”这种格式的URL了。" target="_blank" rel="noopener">http://www.mzitu.com/几位数字结尾的”这种格式的URL了。</a> Go Go Go Go！开始搞事。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt=""></a> 首先在item.py中新建我们需要的字段。我们需要啥？我们需要套图的名字和图片地址！！ 那我们新建三个字段：</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import <span class="keyword">scrapy</span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword"></span></span><br><span class="line"><span class="keyword">class </span>MzituScrapyItem(<span class="keyword">scrapy.Item):</span></span><br><span class="line"><span class="keyword"> </span>   <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    name = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   image_urls = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   url = <span class="keyword">scrapy.Field()</span></span><br><span class="line"><span class="keyword"> </span>   pass</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 第一步完成啦！开始写spider.py啦！ 首先导入我们需要的包：</p>
                  <figure class="highlight pgsql">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, <span class="keyword">Rule</span></span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>都是干啥的我不说了哈！不知道的小伙伴儿自己去翻翻官方文档。 接下来是：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">class Spider(CrawlSpider):</span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), <span class="attribute">callback</span>=<span class="string">'parse_item'</span>, <span class="attribute">follow</span>=<span class="literal">True</span>),</span><br><span class="line">    )</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第五行的img_urls=[] 这个列表是我们之后用来存储每个套图的全部图片的URL地址的。 rules中的语句是：匹配<a href="http://www.mzitu.com/1至6位数的的URL（\\d：数字；{1,6}匹配1至6次。就能匹配出1到6位数）" target="_blank" rel="noopener">http://www.mzitu.com/1至6位数的的URL（\\d：数字；{1,6}匹配1至6次。就能匹配出1到6位数）</a> 但是我们会发现网页中除了<a href="http://www.mzitu.com/XXXXXXX" target="_blank" rel="noopener">http://www.mzitu.com/XXXXXXX</a> 这种格式的URL之外；还有 <a href="http://www.mzitu.com/XXXX/XXXX" target="_blank" rel="noopener">http://www.mzitu.com/XXXX/XXXX</a> 这个格式的URL。所以我们需要设置 deny来不匹配<a href="http://www.mzitu.com/XXXX/XXXX这种格式的URL。" target="_blank" rel="noopener">http://www.mzitu.com/XXXX/XXXX这种格式的URL。</a> 然后将匹配到的网页交给parse_item来处理。并且持续追踪 <strong>看这儿敲黑板！！划重点！！：：：</strong></p>
                  <h2 id="重点说明！！！！不能parse函数！！这是CrawlSpider进行匹配调用的函数，你要是使用了！rules就没法进行匹配啦！！！"><a href="#重点说明！！！！不能parse函数！！这是CrawlSpider进行匹配调用的函数，你要是使用了！rules就没法进行匹配啦！！！" class="headerlink" title="重点说明！！！！不能parse函数！！这是CrawlSpider进行匹配调用的函数，你要是使用了！rules就没法进行匹配啦！！！"></a><strong>重点说明！！！！不能parse函数！！这是CrawlSpider进行匹配调用的函数，你要是使用了！rules就没法进行匹配啦！！！</strong></h2>
                  <p>现在spider.py是这样的：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>来跑一下试试 别忘了怎么测试的哈！！上面新建的那个run.py！ <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu01.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu01.png" alt=""></a> Good！！真棒！全是我们想要的！！！ 现在干啥？啥？你不知道？EXM你没逗我吧！ <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/e6a6e85d131a484b8034606c0f6a504a_th.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/e6a6e85d131a484b8034606c0f6a504a_th.gif" alt=""></a> 当然是解析我们拿到的response了！从里面找我们要的套图名称和所有的图片地址了！ 我们随便打开一个URL。 首先用xpath取套图名称： 啥？你不知道怎么用xpath？？少年少女 你走吧。出去别说看过我的博文。 ./*//div[@class=’main’]/div[1]/h2/text() 这段xpath就是套图名称的xpath了！看不懂的少年少女赶快去<a href="http://www.w3school.com.cn/看看xpath的教程！" target="_blank" rel="noopener">http://www.w3school.com.cn/看看xpath的教程！</a> 当然你直接用Chrome拷贝出来的那个xpath也行。（有一定的概率不能使） 现在来找图片地址了，怎么找我在 小白爬虫第一弹中已经写过了哈！这就不详细赘述了！ 首先找到每套图有多少张图片： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu02.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu02.png" alt=""></a> 就是红框中的那个东东。 Xpath这样写：</p>
                  <figure class="highlight delphi">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">descendant::<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'main'</span>]/<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'content'</span>]/<span class="keyword">div</span>[@<span class="keyword">class</span>=<span class="string">'pagenavi'</span>]/a[last()-<span class="number">1</span>]/span/text()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 意思是选取根节点下面所有后代标签，在其中选取出 div[@class=’main’]下面的div[@class=’content’]下面的/div[@class=’pagenavi’]下面的倒数第二个a标签 下面的span标签中的文本。（有点长哈哈哈哈哈！其实还可以短一些，我懒就不改了） 然后循环拼接处每张图片的的网页地址，现在spider.py是这样：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param response: 下载器返回的response</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = MzituScrapyItem()</span><br><span class="line">        <span class="comment"># max_num为页面最后一张图片的位置</span></span><br><span class="line">        max_num = response.xpath(<span class="string">"descendant::div[@class='main']/div[@class='content']/div[@class='pagenavi']/a[last()-1]/span/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'name'</span>] = response.xpath(<span class="string">"./*//div[@class='main']/div[1]/h2/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>, int(max_num)):</span><br><span class="line">            <span class="comment"># page_url 为每张图片所在的页面地址</span></span><br><span class="line">            page_url = response.url + <span class="string">'/'</span> + str(num)</span><br><span class="line">            <span class="keyword">yield</span> Request(page_url, callback=self.img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>extract_first(default=”N/A”)的意思是：取xpath返回值的第一个元素。如果xpath没有取到值，则返回N/A 然后调用函数img_url来提取每个网页中的图片地址。img_url长这样：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_url</span><span class="params">(self, response,)</span>:</span></span><br><span class="line">    <span class="string">"""取出图片URL 并添加进self.img_urls列表中</span></span><br><span class="line"><span class="string">    :param response:</span></span><br><span class="line"><span class="string">    :param img_url 为每张图片的真实地址</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    img_urls = response.xpath(<span class="string">"descendant::div[@class='main-image']/descendant::img/@src"</span>).extract()</span><br><span class="line">    <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">        self.img_urls.append(img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> descendant::div[@class=’main-image’]/descendant::img/@src这段xpath取出div[@class=’main-image’]下面所有的img标签的src属性（有的套图一个页面有好几张图） .extract()不跟上[0]返回的是列表 完整的spider.py如下：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> mzitu_scrapy.items <span class="keyword">import</span> MzituScrapyItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'mzitu'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mzitu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mzitu.com/'</span>]</span><br><span class="line">    img_urls = []</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;'</span>,), deny=(<span class="string">'http://www.mzitu.com/\d&#123;1,6&#125;/\d&#123;1,6&#125;'</span>)), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param response: 下载器返回的response</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = MzituScrapyItem()</span><br><span class="line">        <span class="comment"># max_num为页面最后一张图片的位置</span></span><br><span class="line">        max_num = response.xpath(<span class="string">"descendant::div[@class='main']/div[@class='content']/div[@class='pagenavi']/a[last()-1]/span/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'name'</span>] = response.xpath(<span class="string">"./*//div[@class='main']/div[1]/h2/text()"</span>).extract_first(default=<span class="string">"N/A"</span>)</span><br><span class="line">        item[<span class="string">'url'</span>] = response.url</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>, int(max_num)):</span><br><span class="line">            <span class="comment"># page_url 为每张图片所在的页面地址</span></span><br><span class="line">            page_url = response.url + <span class="string">'/'</span> + str(num)</span><br><span class="line">            <span class="keyword">yield</span> Request(page_url, callback=self.img_url)</span><br><span class="line">        item[<span class="string">'image_urls'</span>] = self.img_urls</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">img_url</span><span class="params">(self, response,)</span>:</span></span><br><span class="line">        <span class="string">"""取出图片URL 并添加进self.img_urls列表中</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param img_url 为每张图片的真实地址</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        img_urls = response.xpath(<span class="string">"descendant::div[@class='main-image']/descendant::img/@src"</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">            self.img_urls.append(img_url)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 下面开始把图片弄回本地啦！！ 开写我们的pipelines.py 首先根据官方文档说明我们如果需要使用图片管道 则需要使用ImagesPipeline： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu03.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu03.png" alt=""></a> 我们可以依葫芦画瓢写一个。但是这样有一个很麻烦的问题就是，这样下载下来的图片没有分类，很是难看啊！ 所以 我们需要重写一下ImagesPipeline中的file_path方法！ 具体如下：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MzituScrapyPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param request: 每一个图片下载管道请求</span></span><br><span class="line"><span class="string">        :param response:</span></span><br><span class="line"><span class="string">        :param info:</span></span><br><span class="line"><span class="string">        :param strip :清洗Windows系统的文件夹非法字符，避免无法创建目录</span></span><br><span class="line"><span class="string">        :return: 每套图的分类目录</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        folder = item[<span class="string">'name'</span>]</span><br><span class="line">        folder_strip = strip(folder)</span><br><span class="line">        image_guid = request.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        filename = <span class="string">u'full/&#123;0&#125;/&#123;1&#125;'</span>.format(folder_strip, image_guid)</span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param item: spider.py中返回的item</span></span><br><span class="line"><span class="string">        :param info:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> item[<span class="string">'image_urls'</span>]:</span><br><span class="line">            referer = item[<span class="string">'url'</span>]</span><br><span class="line">            <span class="keyword">yield</span> Request(img_url, meta=&#123;<span class="string">'item'</span>: item,</span><br><span class="line">                                         <span class="string">'referer'</span>: referer&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Item contains no images"</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def process_item(self, item, spider):</span></span><br><span class="line">    <span class="comment">#     return item</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strip</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param path: 需要清洗的文件夹名字</span></span><br><span class="line"><span class="string">    :return: 清洗掉Windows系统非法文件夹名字的字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    path = re.sub(<span class="string">r'[？\*|“&lt;&gt;:/]'</span>, <span class="string">''</span>, str(path))</span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    a = <span class="string">'我是一个？*|“&lt;&gt;:/错误的字符串'</span></span><br><span class="line">    print(strip(a))</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 写一个中间件来处理图片下载的防盗链：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeiZiTu</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="string">'''设置headers和切换请求头</span></span><br><span class="line"><span class="string">        :param request: 请求体</span></span><br><span class="line"><span class="string">        :param spider: spider对象</span></span><br><span class="line"><span class="string">        :return: None</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        referer = request.meta.get(<span class="string">'referer'</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> referer:</span><br><span class="line">            request.headers[<span class="string">'referer'</span>] = referer</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 最后一步设置ImagesPipeline的存储目录！ 在settings.py中写入：</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">IMAGES_STORE</span> = <span class="string">'F:\mzitu\\'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>则ImagesPipeline将所有下载的图片放置在此目录下！ 设置图片实效性： 图像管道避免下载最近已经下载的图片。使用 <a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/media-pipeline.html#std:setting-FILES_EXPIRES" target="_blank" rel="noopener"><code>FILES_EXPIRES</code></a> (或 <a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/media-pipeline.html#std:setting-IMAGES_EXPIRES" target="_blank" rel="noopener"><code>IMAGES_EXPIRES</code></a>) 设置可以调整失效期限，可以用天数来指定: 在settings.py中写入以下配置。</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># 30 days of delay for images expiration</span></span><br><span class="line"><span class="attr">IMAGES_EXPIRES</span> = <span class="number">30</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> settings.py中开启item_pipelines:</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">ITEM_PIPELINES</span> = &#123;</span><br><span class="line">   <span class="string">'mzitu_scrapy.pipelines.MzituScrapyPipeline'</span>: 300,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>settings.py中开启DOWNLOADER_MIDDLEWARES</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">DOWNLOADER_MIDDLEWARES</span> = &#123;</span><br><span class="line">   <span class="string">'mzitu_scrapy.middlewares.MeiZiTu'</span>: 543,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 如果你需要缩略图之类的请参考官方文档： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu05.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu05.png" alt=""></a> 将其写入settings.py文件中。 至此完毕！！！ 来看看效果： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu04.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/mzitu04.png" alt=""></a> 下载速度简直飞起！！友情提示：请务必配置代理哦！ 可以参考大才哥的<a href="http://cuiqingcai.com/3443.html做一个代理，就不需要重写Scrapy中间件啦！更能避免费代理总是不能用的坑爹行为。">http://cuiqingcai.com/3443.html做一个代理，就不需要重写Scrapy中间件啦！更能避免费代理总是不能用的坑爹行为。</a> 总之省事省时又省心啊！ github地址：<a href="https://github.com/thsheep/mzitu_scrapy" target="_blank" rel="noopener">https://github.com/thsheep/mzitu_scrapy</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-24 00:37:29" itemprop="dateCreated datePublished" datetime="2017-04-24T00:37:29+08:00">2017-04-24</time>
                </span>
                <span id="/4421.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第四篇（图片下载管道篇）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>8.5k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>8 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4380.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4380.html" class="post-title-link" itemprop="url">利用Scrapy爬取知乎用户详细信息并存至MongoDB</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>本节分享一下爬取知乎用户信息的Scrapy爬虫实战。</p>
                  <h2 id="本节目标"><a href="#本节目标" class="headerlink" title="本节目标"></a>本节目标</h2>
                  <p>本节要实现的内容有：</p>
                  <ul>
                    <li>从一个大V用户开始，通过递归抓取粉丝列表和关注列表，实现知乎所有用户的详细信息的抓取。</li>
                    <li>将抓取到的结果存储到MongoDB，并进行去重操作。</li>
                  </ul>
                  <h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2>
                  <p>我们都知道每个人都有关注列表和粉丝列表，尤其对于大V来说，粉丝和关注尤其更多。 如果我们从一个大V开始，首先可以获取他的个人信息，然后我们获取他的粉丝列表和关注列表，然后遍历列表中的每一个用户，进一步抓取每一个用户的信息还有他们各自的粉丝列表和关注列表，然后再进一步遍历获取到的列表中的每一个用户，进一步抓取他们的信息和关注粉丝列表，循环往复，不断递归，这样就可以做到一爬百，百爬万，万爬百万，通过社交关系自然形成了一个爬取网，这样就可以爬到所有的用户信息了。当然零粉丝零关注的用户就忽略他们吧～ 爬取的信息怎样来获得呢？不用担心，通过分析知乎的请求就可以得到相关接口，通过请求接口就可以拿到用户详细信息和粉丝、关注列表了。 接下来我们开始实战爬取。</p>
                  <h2 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h2>
                  <h3 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h3>
                  <p>本项目使用的Python版本是Python3，项目开始之前请确保你已经安装了Python3。</p>
                  <h3 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h3>
                  <p>Scrapy是一个强大的爬虫框架，安装方式如下：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> scrapy</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h3>
                  <p>非关系型数据库，项目开始之前请先安装好MongoDB并启动服务。</p>
                  <h3 id="PyMongo"><a href="#PyMongo" class="headerlink" title="PyMongo"></a>PyMongo</h3>
                  <p>Python的MongoDB连接库，安装方式如下：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">pip3 <span class="keyword">install</span> pymongo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2>
                  <p>安装好以上环境之后，我们便可以开始我们的项目了。 在项目开始之首先我们用命令行创建一个项目：</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy startproject zhihuuser</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h2>
                  <p>接下来我们需要创建一个spider，同样利用命令行，不过这次命令行需要进入到项目里运行。</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">cd</span> <span class="selector-tag">zhihuuser</span></span><br><span class="line"><span class="selector-tag">scrapy</span> <span class="selector-tag">genspider</span> <span class="selector-tag">zhihu</span> <span class="selector-tag">www</span><span class="selector-class">.zhihu</span><span class="selector-class">.com</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h2 id="禁止ROBOTSTXT-OBEY"><a href="#禁止ROBOTSTXT-OBEY" class="headerlink" title="禁止ROBOTSTXT_OBEY"></a>禁止ROBOTSTXT_OBEY</h2>
                  <p>接下来你需要打开settings.py文件，将ROBOTSTXT_OBEY修改为False。</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">ROBOTSTXT_OBEY</span> = <span class="literal">False</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>它默认为True，就是要遵守robots.txt 的规则，那么 robots.txt 是个什么东西呢？ 通俗来说， robots.txt 是遵循 Robot 协议的一个文件，它保存在网站的服务器中，它的作用是，告诉搜索引擎爬虫，本网站哪些目录下的网页 不希望 你进行爬取收录。在Scrapy启动后，会在第一时间访问网站的 robots.txt 文件，然后决定该网站的爬取范围。 当然，我们并不是在做搜索引擎，而且在某些情况下我们想要获取的内容恰恰是被 robots.txt 所禁止访问的。所以，某些时候，我们就要将此配置项设置为 False ，拒绝遵守 Robot协议 ！ 所以在这里设置为False。当然可能本次爬取不一定会被它限制，但是我们一般来说会首先选择禁止它。</p>
                  <h2 id="尝试最初的爬取"><a href="#尝试最初的爬取" class="headerlink" title="尝试最初的爬取"></a>尝试最初的爬取</h2>
                  <p>接下来我们什么代码也不修改，执行爬取，运行如下命令：</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>你会发现爬取结果会出现这样的一个错误：</p>
                  <figure class="highlight basic">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">500 </span>Internal Server <span class="keyword">Error</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>访问知乎得到的状态码是500，这说明爬取并没有成功，其实这是因为我们没有加入请求头，知乎识别User-Agent发现不是浏览器，就返回错误的响应了。 所以接下来的一步我们需要加入请求headers信息，你可以在Request的参数里加，也可以在spider里面的custom_settings里面加，当然最简单的方法莫过于在全局settings里面加了。 我们打开settings.py文件，取消DEFAULT_REQUEST_HEADERS的注释，加入如下的内容：</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.<span class="number">2924.87</span> Safari/537.36'</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个是为你的请求添加请求头，如果你没有设置headers的话，它就会使用这个请求头请求，添加了User-Agent信息，所以这样我们的爬虫就可以伪装浏览器了。 接下来重新运行爬虫。</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这时你就会发现得到的返回状态码就正常了。 解决了这个问题，我们接下来就可以分析页面逻辑来正式实现爬虫了。</p>
                  <h2 id="爬取流程"><a href="#爬取流程" class="headerlink" title="爬取流程"></a>爬取流程</h2>
                  <p>接下来我们需要先探寻获取用户详细信息和获取关注列表的接口。 回到网页，打开浏览器的控制台，切换到Network监听模式。 我们首先要做的是寻找一个大V，以轮子哥为例吧，它的个人信息页面网址是：<a href="https://www.zhihu.com/people/excited-vczh" target="_blank" rel="noopener">https://www.zhihu.com/people/excited-vczh</a> 首先打开轮子哥的首页 <img src="https://ww4.sinaimg.cn/large/006tKfTcly1femrd0w9qwj31kw145n1v.jpg" alt=""> 我们可以看到这里就是他的一些基本信息，我们需要抓取的就是这些，比如名字、签名、职业、关注数、赞同数等等。 接下来我们需要探索一下关注列表接口在哪里，我们点击关注选项卡，然后下拉，点击翻页，我们会在下面的请求中发现出现了 followees开头的Ajax请求。这个就是获取关注列表的接口。 <img src="https://ww1.sinaimg.cn/large/006tKfTcly1femrhdtpkoj31kw0y7jw5.jpg" alt=""> 我们观察一下这个请求结构 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrk47kt9j31ho0sejwx.jpg" alt=""> 首先它是一个Get类型的请求，请求的URL是<a href="https://www.zhihu.com/api/v4/members/excited-vczh/followees" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/excited-vczh/followees</a>，后面跟了三个参数，一个是include，一个是offset，一个是limit。 观察后可以发现，include是一些获取关注的人的基本信息的查询参数，包括回答数、文章数等等。 offset是偏移量，我们现在分析的是第3页的关注列表内容，offset当前为40。 limit为每一页的数量，这里是20，所以结合上面的offset可以推断，当offset为0时，获取到的是第一页关注列表，当offset为20时，获取到的是第二页关注列表，依次类推。 然后接下来看下返回结果： <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrpgchhpj31ec0ss0wb.jpg" alt=""> 可以看到有data和paging两个字段，data就是数据，包含20个内容，这些就是用户的基本信息，也就是关注列表的用户信息。 paging里面又有几个字段，is_end表示当前翻页是否结束，next是下一页的链接，所以在判读分页的时候，我们可以先利用is_end判断翻页是否结束，然后再获取next链接，请求下一页。 这样我们的关注列表就可以通过接口获取到了。 接下来我们再看下用户详情接口在哪里，我们将鼠标放到关注列表任意一个头像上面，观察下网络请求，可以发现又会出现一个Ajax请求。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femrumazrij31kw0zjk1e.jpg" alt=""> 可以看到这次的请求链接为<a href="https://www.zhihu.com/api/v4/members/lu-jun-ya-1" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/lu-jun-ya-1</a> 后面又一个参数include，include是一些查询参数，与刚才的接口类似，不过这次参数非常全，几乎可以把所有详情获取下来，另外接口的最后是加了用户的用户名，这个其实是url_token，上面的那个接口其实也是，在返回数据中是可以获得的。 <img src="https://ww4.sinaimg.cn/large/006tKfTcly1femrxhb8ptj313w0qy76m.jpg" alt=""> 所以综上所述：</p>
                  <ul>
                    <li>要获取用户的关注列表，我们需要请求类似 <a href="https://www.zhihu.com/api/v4/members/%7Buser%7D/followees?include={include}&amp;offset={offset}&amp;limit={limit}" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/{user}/followees?include={include}&amp;offset={offset}&amp;limit={limit}</a> 这样的接口，其中user就是该用户的url_token，include是固定的查询参数，offset是分页偏移量，limit是一页取多少个。</li>
                    <li>要获取用户的详细信息，我们需要请求类似 <a href="https://www.zhihu.com/api/v4/members/%7Buser%7D?include={include}" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/members/{user}?include={include}</a> 这样的接口，其中user就是该用户的url_token，include是查询参数。</li>
                  </ul>
                  <p>理清了如上接口逻辑后，我们就可以开始构造请求了。</p>
                  <h2 id="生成第一步请求"><a href="#生成第一步请求" class="headerlink" title="生成第一步请求"></a>生成第一步请求</h2>
                  <p>接下来我们要做的第一步当然是请求轮子哥的基本信息，然后获取轮子哥的关注列表了，我们首先构造一个格式化的url，将一些可变参数提取出来，然后需要重写start_requests方法，生成第一步的请求，接下来我们还需要根据获取到到关注列表做进一步的分析。</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import json</span><br><span class="line">from scrapy import Spider, Request</span><br><span class="line">from zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="constructor">ZhihuSpider(Spider)</span>:</span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = <span class="literal">["<span class="identifier">www</span>.<span class="identifier">zhihu</span>.<span class="identifier">com</span>"]</span></span><br><span class="line">    user_url = 'https:<span class="comment">//www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = 'https:<span class="comment">//www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;amp;offset=&#123;offset&#125;&amp;amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = 'excited-vczh'</span><br><span class="line">    user_query = 'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge<span class="literal">[?(<span class="identifier">type</span>=<span class="identifier">best_answerer</span>)]</span>.topics'</span><br><span class="line">    follows_query = 'data<span class="literal">[<span class="operator">*</span>]</span>.answer_count,articles_count,gender,follower_count,is_followed,is_following,badge<span class="literal">[?(<span class="identifier">type</span>=<span class="identifier">best_answerer</span>)]</span>.topics'</span><br><span class="line"></span><br><span class="line">    def start<span class="constructor">_requests(<span class="params">self</span>)</span>:</span><br><span class="line">        yield <span class="constructor">Request(<span class="params">self</span>.<span class="params">user_url</span>.<span class="params">format</span>(<span class="params">user</span>=<span class="params">self</span>.<span class="params">start_user</span>, <span class="params">include</span>=<span class="params">self</span>.<span class="params">user_query</span>)</span>, self.parse_user)</span><br><span class="line">        yield <span class="constructor">Request(<span class="params">self</span>.<span class="params">follows_url</span>.<span class="params">format</span>(<span class="params">user</span>=<span class="params">self</span>.<span class="params">start_user</span>, <span class="params">include</span>=<span class="params">self</span>.<span class="params">follows_query</span>, <span class="params">limit</span>=20, <span class="params">offset</span>=0)</span>,</span><br><span class="line">                      self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后我们实现一下两个解析方法parse_user和parse_follows。</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_user</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    print(response.text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_follows</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">    print(response.text)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>最简单的实现他们的结果输出即可，然后运行观察结果。</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这时你会发现出现了</p>
                  <figure class="highlight basic">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">401 </span>HTTP status code is <span class="keyword">not</span> handled <span class="keyword">or</span> <span class="keyword">not</span> allowed</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>访问被禁止了，这时我们观察下浏览器请求，发现它相比之前的请求多了一个OAuth请求头。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femsckhmbxj30zy0qsaem.jpg" alt=""></p>
                  <h2 id="OAuth"><a href="#OAuth" class="headerlink" title="OAuth"></a>OAuth</h2>
                  <p>它是Open Authorization的缩写。 OAUTH_token:OAUTH进行到最后一步得到的一个“令牌”，通过此“令牌”请求，就可以去拥有资源的网站抓取任意有权限可以被抓取的资源。 在这里我知乎并没有登陆，这里的OAuth值是</p>
                  <figure class="highlight llvm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">oauth <span class="keyword">c</span><span class="number">3</span>cef<span class="number">7</span><span class="keyword">c</span><span class="number">66</span>a<span class="number">1843</span>f<span class="number">8</span>b<span class="number">3</span>a<span class="number">9e6</span>a<span class="number">1e3160</span>e<span class="number">20</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>经过我长久的观察，这个一直不会改变，所以可以长久使用，我们将它配置到DEFAULT_REQUEST_HEADERS里，这样它就变成了：</p>
                  <figure class="highlight 1c">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.<span class="number">2924.87</span> Safari/537.36',</span><br><span class="line">    'authorization': 'oauth c3cef7c66a<span class="number">1843</span>f8b3a9e6a1e<span class="number">3160</span>e20',</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>接下来如果我们重新运行爬虫，就可以发现可以正常爬取了。</p>
                  <h2 id="parse-user"><a href="#parse-user" class="headerlink" title="parse_user"></a>parse_user</h2>
                  <p>接下来我们处理一下用户基本信息，首先我们查看一下接口信息会返回一些什么数据。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femsgc32lzj31900r241a.jpg" alt=""> 可以看到返回的结果非常全，在这里我们直接声明一个Item全保存下就好了。 在items里新声明一个UserItem</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Item, Field</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="symbol">UserItem</span>(<span class="symbol">Item</span>):</span><br><span class="line">    # <span class="symbol">define</span> <span class="symbol">the</span> <span class="symbol">fields</span> <span class="symbol">for</span> <span class="symbol">your</span> <span class="symbol">item</span> <span class="symbol">here</span> <span class="symbol">like:</span></span><br><span class="line">    <span class="symbol">id</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">name</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">avatar_url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">headline</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">description</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">url_token</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">gender</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">cover_url</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">type</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">badge</span> = <span class="symbol">Field</span>()</span><br><span class="line"></span><br><span class="line">    <span class="symbol">answer_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">articles_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">commercial_question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">favorite_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">favorited_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">follower_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_columns_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">pins_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thank_from_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thank_to_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">thanked_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">vote_from_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">vote_to_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">voteup_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_favlists_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_question_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">following_topic_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">marked_answers_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">mutual_followees_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">hosted_live_count</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">participated_live_count</span> = <span class="symbol">Field</span>()</span><br><span class="line"></span><br><span class="line">    <span class="symbol">locations</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">educations</span> = <span class="symbol">Field</span>()</span><br><span class="line">    <span class="symbol">employments</span> = <span class="symbol">Field</span>()</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>所以在解析方法里面我们解析得到的response内容，然后转为json对象，然后依次判断字段是否存在，赋值就好了。</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="built_in">result</span> = json.loads(response.<span class="keyword">text</span>)</span><br><span class="line"><span class="keyword">item</span> = UserItem()</span><br><span class="line"><span class="keyword">for</span> field <span class="keyword">in</span> <span class="keyword">item</span>.fields:</span><br><span class="line">    <span class="keyword">if</span> field <span class="keyword">in</span> <span class="built_in">result</span>.<span class="built_in">keys</span>():</span><br><span class="line">        <span class="keyword">item</span>[field] = <span class="built_in">result</span>.<span class="built_in">get</span>(field)</span><br><span class="line">yield <span class="keyword">item</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>得到item后通过yield返回就好了。 这样保存用户基本信息就完成了。 接下来我们还需要在这里获取这个用户的关注列表，所以我们需要再重新发起一个获取关注列表的request 在parse_user后面再添加如下代码：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yield Request(</span><br><span class="line">            self.follows_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们又生成了获取该用户关注列表的请求。</p>
                  <h2 id="parse-follows"><a href="#parse-follows" class="headerlink" title="parse_follows"></a>parse_follows</h2>
                  <p>接下来我们处理一下关注列表，首先也是解析response的文本，然后要做两件事：</p>
                  <ul>
                    <li>通过关注列表的每一个用户，对每一个用户发起请求，获取其详细信息。</li>
                    <li>处理分页，判断paging内容，获取下一页关注列表。</li>
                  </ul>
                  <p>所以在这里将parse_follows改写如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">        yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                      self.parse_user)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">    next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">    yield Request(next_page,</span><br><span class="line">                  self.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样，整体代码如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">from scrapy import Spider, Request</span><br><span class="line">from zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhihuSpider</span>(<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = [<span class="string">"www.zhihu.com"</span>]</span><br><span class="line">    user_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;amp;offset=&#123;offset&#125;&amp;amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = <span class="string">'excited-vczh'</span></span><br><span class="line">    user_query = <span class="string">'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    follows_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">yield</span> Request(<span class="keyword">self</span>.user_url.format(user=<span class="keyword">self</span>.start_user, <span class="keyword">include</span>=<span class="keyword">self</span>.user_query), <span class="keyword">self</span>.parse_user)</span><br><span class="line">        <span class="keyword">yield</span> Request(<span class="keyword">self</span>.follows_url.format(user=<span class="keyword">self</span>.start_user, <span class="keyword">include</span>=<span class="keyword">self</span>.follows_query, limit=<span class="number">20</span>, offset=<span class="number">0</span>),</span><br><span class="line">                      <span class="keyword">self</span>.parse_follows)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_user</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        result = json.loads(response.text)</span><br><span class="line">        item = UserItem()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> field <span class="keyword">in</span> item.<span class="symbol">fields:</span></span><br><span class="line">            <span class="keyword">if</span> field <span class="keyword">in</span> result.keys()<span class="symbol">:</span></span><br><span class="line">                item[field] = result.get(field)</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> Request(</span><br><span class="line">            <span class="keyword">self</span>.follows_url.format(user=result.get(<span class="string">'url_token'</span>), <span class="keyword">include</span>=<span class="keyword">self</span>.follows_query, limit=<span class="number">20</span>, offset=<span class="number">0</span>),</span><br><span class="line">            <span class="keyword">self</span>.parse_follows)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_follows</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys()<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.get(<span class="string">'data'</span>)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">yield</span> Request(<span class="keyword">self</span>.user_url.format(user=result.get(<span class="string">'url_token'</span>), <span class="keyword">include</span>=<span class="keyword">self</span>.user_query),</span><br><span class="line">                              <span class="keyword">self</span>.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.get(<span class="string">'paging'</span>).get(<span class="string">'is_end'</span>) == <span class="symbol">False:</span></span><br><span class="line">            next_page = results.get(<span class="string">'paging'</span>).get(<span class="string">'next'</span>)</span><br><span class="line">            <span class="keyword">yield</span> Request(next_page,</span><br><span class="line">                          <span class="keyword">self</span>.parse_follows)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样我们就完成了获取用户基本信息，然后递归获取关注列表进一步请求了。 重新运行爬虫，可以发现当前已经可以实现循环递归爬取了。</p>
                  <h2 id="followers"><a href="#followers" class="headerlink" title="followers"></a>followers</h2>
                  <p>上面我们实现了通过获取关注列表实现爬取循环，那这里少不了的还有粉丝列表，经过分析后发现粉丝列表的api也类似，只不过把followee换成了follower，其他的完全相同，所以我们按照同样的逻辑添加followers相关信息， 最终spider代码如下：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy import Spider, Request</span><br><span class="line"><span class="keyword">from</span> zhihuuser.items import UserItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ZhihuSpider(Spider):</span><br><span class="line">    name = <span class="string">"zhihu"</span></span><br><span class="line">    allowed_domains = [<span class="string">"www.zhihu.com"</span>]</span><br><span class="line">    user_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;?include=&#123;include&#125;'</span></span><br><span class="line">    follows_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followees?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    followers_url = <span class="string">'https://www.zhihu.com/api/v4/members/&#123;user&#125;/followers?include=&#123;include&#125;&amp;offset=&#123;offset&#125;&amp;limit=&#123;limit&#125;'</span></span><br><span class="line">    start_user = <span class="string">'tianshansoft'</span></span><br><span class="line">    user_query = <span class="string">'locations,employments,gender,educations,business,voteup_count,thanked_Count,follower_count,following_count,cover_url,following_topic_count,following_question_count,following_favlists_count,following_columns_count,answer_count,articles_count,pins_count,question_count,commercial_question_count,favorite_count,favorited_count,logs_count,marked_answers_count,marked_answers_text,message_thread_token,account_status,is_active,is_force_renamed,is_bind_sina,sina_weibo_url,sina_weibo_name,show_sina_weibo,is_blocking,is_blocked,is_following,is_followed,mutual_followees_count,vote_to_count,vote_from_count,thank_to_count,thank_from_count,thanked_count,description,hosted_live_count,participated_live_count,allow_message,industry_category,org_name,org_homepage,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    follows_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line">    followers_query = <span class="string">'data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics'</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        yield Request(self.user_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.user_query), self.parse_user)</span><br><span class="line">        yield Request(self.follows_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">                      self.parse_follows)</span><br><span class="line">        yield Request(self.followers_url.format(<span class="attribute">user</span>=self.start_user, <span class="attribute">include</span>=self.followers_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">                      self.parse_followers)</span><br><span class="line"></span><br><span class="line">    def parse_user(self, response):</span><br><span class="line">        result = json.loads(response.text)</span><br><span class="line">        item = UserItem()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> field <span class="keyword">in</span> item.fields:</span><br><span class="line">            <span class="keyword">if</span> field <span class="keyword">in</span> result.keys():</span><br><span class="line">                item[field] = result.<span class="builtin-name">get</span>(field)</span><br><span class="line">        yield item</span><br><span class="line"></span><br><span class="line">        yield Request(</span><br><span class="line">            self.follows_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.follows_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_follows)</span><br><span class="line"></span><br><span class="line">        yield Request(</span><br><span class="line">            self.followers_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.followers_query, <span class="attribute">limit</span>=20, <span class="attribute">offset</span>=0),</span><br><span class="line">            self.parse_followers)</span><br><span class="line"></span><br><span class="line">    def parse_follows(self, response):</span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">                yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                              self.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">            next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">            yield Request(next_page,</span><br><span class="line">                          self.parse_follows)</span><br><span class="line"></span><br><span class="line">    def parse_followers(self, response):</span><br><span class="line">        results = json.loads(response.text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'data'</span> <span class="keyword">in</span> results.keys():</span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results.<span class="builtin-name">get</span>(<span class="string">'data'</span>):</span><br><span class="line">                yield Request(self.user_url.format(<span class="attribute">user</span>=result.get('url_token'), <span class="attribute">include</span>=self.user_query),</span><br><span class="line">                              self.parse_user)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'paging'</span> <span class="keyword">in</span> results.keys() <span class="keyword">and</span> results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'is_end'</span>) == <span class="literal">False</span>:</span><br><span class="line">            next_page = results.<span class="builtin-name">get</span>(<span class="string">'paging'</span>).<span class="builtin-name">get</span>(<span class="string">'next'</span>)</span><br><span class="line">            yield Request(next_page,</span><br><span class="line">                          self.parse_followers)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要改变的位置有</p>
                  <ul>
                    <li>start_requests里面添加yield followers信息</li>
                    <li>parse_user里面里面添加yield followers信息</li>
                    <li>parse_followers做相应的的抓取详情请求和翻页。</li>
                  </ul>
                  <p>如此一来，spider就完成了，这样我们就可以实现通过社交网络递归的爬取，把用户详情都爬下来。</p>
                  <h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>
                  <p>通过以上的spider，我们实现了如上逻辑：</p>
                  <ul>
                    <li>start_requests方法，实现了第一个大V用户的详细信息请求还有他的粉丝和关注列表请求。</li>
                    <li>parse_user方法，实现了详细信息的提取和粉丝关注列表的获取。</li>
                    <li>paese_follows，实现了通过关注列表重新请求用户并进行翻页的功能。</li>
                    <li>paese_followers，实现了通过粉丝列表重新请求用户并进行翻页的功能。</li>
                  </ul>
                  <h2 id="加入pipeline"><a href="#加入pipeline" class="headerlink" title="加入pipeline"></a>加入pipeline</h2>
                  <p>在这里数据库存储使用MongoDB，所以在这里我们需要借助于Item Pipeline，实现如下：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span>(<span class="title">object</span>):</span></span><br><span class="line">    collection_name = <span class="string">'users'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, mongo_uri, mongo_db)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.mongo_uri = mongo_uri</span><br><span class="line">        <span class="keyword">self</span>.mongo_db = mongo_db</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(<span class="string">'MONGO_URI'</span>),</span><br><span class="line">            mongo_db=crawler.settings.get(<span class="string">'MONGO_DATABASE'</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.client = pymongo.MongoClient(<span class="keyword">self</span>.mongo_uri)</span><br><span class="line">        <span class="keyword">self</span>.db = <span class="keyword">self</span>.client[<span class="keyword">self</span>.mongo_db]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(<span class="keyword">self</span>, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.client.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(<span class="keyword">self</span>, item, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.db[<span class="keyword">self</span>.collection_name].update(&#123;<span class="string">'url_token'</span>: item[<span class="string">'url_token'</span>]&#125;, &#123;<span class="string">'$set'</span>: dict(item)&#125;, True)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>比较重要的一点就在于process_item，在这里使用了update方法，第一个参数传入查询条件，这里使用的是url_token，第二个参数传入字典类型的对象，就是我们的item，第三个参数传入True，这样就可以保证，如果查询数据存在的话就更新，不存在的话就插入。这样就可以保证去重了。 另外记得开启一下Item Pileline</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">ITEM_PIPELINES</span> = &#123;</span><br><span class="line">    <span class="string">'zhihuuser.pipelines.MongoPipeline'</span>: 300,</span><br><span class="line">&#125;</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后重新运行爬虫</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">scrapy crawl zhihu</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这样就可以发现正常的输出了，会一直不停地运行，用户也一个个被保存到数据库。 <img src="https://ww3.sinaimg.cn/large/006tKfTcly1femt2bisibj31kw0qa7fr.jpg" alt=""> 看下MongoDB，里面我们爬取的用户详情结果。 <img src="https://ww4.sinaimg.cn/large/006tKfTcgy1femtnv605cj31kw134guj.jpg" alt=""> 到现在为止，整个爬虫就基本完结了，我们主要通过递归的方式实现了这个逻辑。存储结果也通过适当的方法实现了去重。</p>
                  <h2 id="更高效率"><a href="#更高效率" class="headerlink" title="更高效率"></a>更高效率</h2>
                  <p>当然我们现在运行的是单机爬虫，只在一台电脑上运行速度是有限的，所以后面我们要想提高抓取效率，需要用到分布式爬虫，在这里需要用到Redis来维护一个公共的爬取队列。 更多的分布式爬虫的实现可以查看<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-15 03:36:48" itemprop="dateCreated datePublished" datetime="2017-04-15T03:36:48+08:00">2017-04-15</time>
                </span>
                <span id="/4380.html" class="post-meta-item leancloud_visitors" data-flag-title="利用Scrapy爬取知乎用户详细信息并存至MongoDB" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>15k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>14 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4352.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4352.html" class="post-title-link" itemprop="url">小白学爬虫系列教程</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 听大才哥说好像我的文章挺难找的，这整理一下。</p>
                  <h2 id="基础知识篇："><a href="#基础知识篇：" class="headerlink" title="基础知识篇："></a>基础知识篇：</h2>
                  <p>这玩意儿我没写，各位参考大才哥的： <a href="http://cuiqingcai.com/1052.html">Python爬虫学习系列教程</a> <a href="http://cuiqingcai.com/4320.html">Python3爬虫学习视频教程</a></p>
                  <h2 id="小白系列教程"><a href="#小白系列教程" class="headerlink" title="小白系列教程"></a>小白系列教程</h2>
                  <p><a href="http://cuiqingcai.com/3179.html">小白爬虫第一弹之抓取妹子图</a> <a href="http://cuiqingcai.com/3256.html">小白爬虫第二弹之健壮的小爬虫</a> <a href="http://cuiqingcai.com/3314.html">小白爬虫第三弹之去重去重</a> <a href="http://cuiqingcai.com/3363.html">小白爬虫第四弹之爬虫快跑（多进程+多线程）</a> <a href="http://cuiqingcai.com/3472.html">小白进阶之Scrapy第一篇</a> <a href="http://cuiqingcai.com/3952.html">小白进阶之Scrapy第二篇（登录篇）</a> <a href="http://cuiqingcai.com/4048.html">小白进阶之</a><a href="http://cuiqingcai.com/4020.html">Scrapy分布式的前篇—让redis和MongoDB安全点</a> <a href="http://cuiqingcai.com/4048.html">小白进阶之Scrapy第三篇（基于Scrapy-Redis的分布式以及cookies池）</a> <a href="http://cuiqingcai.com/4421.html">小白进阶之Scrapy第四篇（图片下载管道篇）</a> <a href="http://cuiqingcai.com/4725.html">小白进阶之Scrapy第五篇（Scrapy-Splash配合CrawlSpider；瞎几把整的）</a> <a href="http://cuiqingcai.com/4652.html">利用新接口抓取微信公众号的所有文章</a> <a href="https://cuiqingcai.com/6058.html">小白进阶之</a><a href="http://cuiqingcai.com/4725.html">Scrapy第六篇</a><a href="https://cuiqingcai.com/6058.html">Scrapy-Redis详解</a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 暂时就这些了、最近工作刚入职。上了个新项目，没时间更新文章了（主要是我懒、挤点时间都用来打LOL了···············尴尬脸） 等项目第一期结束了，我会把以前许诺的 ：JS异步加载 | 动态爬虫 更新出来。 感谢大才哥的平台（有兴趣的小伙伴一起来更新文章啊！ 才不会告诉你们：我扯着大才哥的大旗找了个不错的工作。手动笑哭······） <strong>如果以上网站有更改无法正常采集，请PM我一下，我尽量保证demo的可用性</strong></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 20:31:03" itemprop="dateCreated datePublished" datetime="2017-04-11T20:31:03+08:00">2017-04-11</time>
                </span>
                <span id="/4352.html" class="post-meta-item leancloud_visitors" data-flag-title="小白学爬虫系列教程" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>569</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4347.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Other <i class="label-arrow"></i>
                  </a>
                  <a href="/4347.html" class="post-title-link" itemprop="url">本站投稿功能已关闭</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="公告"><a href="#公告" class="headerlink" title="公告"></a>公告</h2>
                  <p>大家好，本站于今日（2017.4.11）关闭投稿功能。</p>
                  <h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2>
                  <p>由于之前本站开放了投稿注册接口，该接口现在被人利用，每天都会发送垃圾邮件，经常导致邮箱发信过多而被冻结，而WordPress本身没有提供验证码验证，所以自己也不想再去修改，当然最主要的是能发优质文章的又是少之又少，经常会出现一些垃圾草稿，所以博主决定直接将投稿功能关闭，希望大家可以理解。</p>
                  <h2 id="投稿"><a href="#投稿" class="headerlink" title="投稿"></a>投稿</h2>
                  <p>如果您有在本站投稿意向，请直接联系我邮件cqc@cuiqingcai.com，我为您注册账号并开通写作权限。</p>
                  <h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2>
                  <p>非常感谢在本站投稿的童鞋，尤其是卧槽哥，发表了很多篇高质量爬虫文章。另外还有戴笠兄也是，不过后来戴笠兄的文章因为开车过猛而下架了哈哈，不过还是非常感谢。另外也非常感谢其他在本站投稿的小伙伴，在这不一一点名啦！</p>
                  <h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2>
                  <p>最后希望大家可以理解，也非常感谢大家的支持！前一段时间忙着在录制爬虫视频，今天刚刚收尾，现在已经更新完毕，后面我将学习一些数据分析、自然语言处理、Web安全方面的知识分享给大家，希望大家多多支持！感谢！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 20:03:03" itemprop="dateCreated datePublished" datetime="2017-04-11T20:03:03+08:00">2017-04-11</time>
                </span>
                <span id="/4347.html" class="post-meta-item leancloud_visitors" data-flag-title="本站投稿功能已关闭" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>440</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4320.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4320.html" class="post-title-link" itemprop="url">Python3爬虫视频学习教程</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <h2 id="课程链接"><a href="#课程链接" class="headerlink" title="课程链接"></a>课程链接</h2>
                  <p><strong>天善智能：<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></strong> <strong>网易云课堂：<a href="http://study.163.com/course/courseMain.htm?courseId=1003827039&amp;utm_campaign=commission&amp;utm_source=cp-1018878377&amp;utm_medium=share" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></strong></p>
                  <h2 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h2>
                  <p>大家好哈，现在呢静觅博客已经两年多啦，可能大家过来更多看到的是爬虫方面的博文，首先非常感谢大家的支持，希望我的博文对大家有帮助！ 之前我写了一些Python爬虫方面的文章，<a href="http://cuiqingcai.com/1052.html">Python爬虫学习系列教程</a>，涉及到了基础和进阶的一些内容，当时更多用到的是Urllib还有正则，后来又陆续增加了一些文章，在学习过程中慢慢积累慢慢成型了一套算不上教程的教程，后来有越来越多的小伙伴学习和支持我感到非常开心，再次感谢大家！ 不过其实这些教程总的来说有一些问题：</p>
                  <ol>
                    <li>当时用的Python2写的，刚写的时候Scrapy这个框架也没有支持Python3，一些Python3爬虫库也不怎么成熟，所以当时选择了Python2。但到现在，Python3发展迅速，爬虫库也越来越成熟，而且Python2在不久的将来就会停止维护了，所以慢慢地，我的语言重心也慢慢转向了Python3，我也相信Python3会成为主流。所以说之前的一套课程算是有点过时了，相信大家肯定还在寻找Python3的一些教程。</li>
                    <li>当时学习的时候主要用的urllib，正则，所以这些文章的较大篇幅也都是urllib和正则的一些东西，后来的一些高级库都是在后面慢慢加的，而且一些高级的框架用法也没有做深入讲解，所以感觉整个内容有点头重脚轻，安排不合理。而且现在分布式越来越火，那么分布式爬虫的应用相必也是越来越广泛，之前的课程也没有做系统讲解。</li>
                    <li>在介绍一些操作的时候可能介绍不全面，环境的配置也没有兼顾各个平台，所以可能有些小伙伴摸不着头脑，可能卡在某一步不知道接下来是怎么做的了。</li>
                  </ol>
                  <p>那么综合上面的问题呢，最近我花了前前后后将近一个月的时间录制了一套新的Pyhthon3爬虫视频教程，将我之前做爬虫的一些经验重新梳理和整合，利用Python3编写，从环境配置、基础库讲解到案例实战、框架使用，最后再到分布式爬虫进行了比较系统的讲解。 课程内容是这个样子的：</p>
                  <h3 id="一、环境篇"><a href="#一、环境篇" class="headerlink" title="一、环境篇"></a><strong>一、环境篇</strong></h3>
                  <ul>
                    <li>Python3+Pip环境配置</li>
                    <li>MongoDB环境配置</li>
                    <li>Redis环境配置</li>
                    <li>MySQL环境配置</li>
                    <li>Python多版本共存配置</li>
                    <li>Python爬虫常用库的安装</li>
                  </ul>
                  <h3 id="二、基础篇"><a href="#二、基础篇" class="headerlink" title="二、基础篇"></a><strong>二、基础篇</strong></h3>
                  <ul>
                    <li>爬虫基本原理</li>
                    <li>Urllib库基本使用</li>
                    <li>Requests库基本使用</li>
                    <li>正则表达式基础</li>
                    <li>BeautifulSoup详解</li>
                    <li>PyQuery详解</li>
                    <li>Selenium详解</li>
                  </ul>
                  <h3 id="三、实战篇"><a href="#三、实战篇" class="headerlink" title="三、实战篇"></a><strong>三、实战篇</strong></h3>
                  <ul>
                    <li>使用Requests+正则表达式爬取猫眼电影</li>
                    <li>分析Ajax请求并抓取今日头条街拍美图</li>
                    <li>使用Selenium模拟浏览器抓取淘宝商品美食信息</li>
                    <li>使用Redis+Flask维护动态代理池</li>
                    <li>使用代理处理反爬抓取微信文章</li>
                    <li>使用Redis+Flask维护动态Cookies池</li>
                  </ul>
                  <h3 id="四、框架篇"><a href="#四、框架篇" class="headerlink" title="四、框架篇"></a><strong>四、框架篇</strong></h3>
                  <ul>
                    <li>PySpider框架基本使用及抓取TripAdvisor实战</li>
                    <li>PySpider架构概述及用法详解</li>
                    <li>Scrapy框架的安装</li>
                    <li>Scrapy框架基本使用</li>
                    <li>Scrapy命令行详解</li>
                    <li>Scrapy中选择器的用法</li>
                    <li>Scrapy中Spiders的用法</li>
                    <li>Scrapy中Item Pipeline的用法</li>
                    <li>Scrapy中Download Middleware的用法</li>
                    <li>Scrapy爬取知乎用户信息实战</li>
                    <li>Scrapy+Cookies池抓取新浪微博</li>
                    <li>Scrapy+Tushare爬取微博股票数据</li>
                  </ul>
                  <h3 id="五、分布式篇"><a href="#五、分布式篇" class="headerlink" title="五、分布式篇"></a><strong>五、分布式篇</strong></h3>
                  <ul>
                    <li>Scrapy分布式原理及Scrapy-Redis源码解析</li>
                    <li>Scrapy分布式架构搭建抓取知乎</li>
                    <li>Scrapy分布式的部署详解</li>
                  </ul>
                  <p>整个课程是从小白起点的，从环境配置和基础开始讲起，环境安装部分三大平台都有介绍，实战的部分我是一边写一边讲解，还有一些分布式爬虫的搭建流程也做了介绍。 不过这个课程是收费的，其实里面也包含了我学习爬虫以来的经验和汗水，我在做讲解的时候也会把我学习爬虫的一些思路和想法讲解出来，避免大家走一些弯路，希望大家可以支持一下！ 不过在这里有免费的视频，是属于整个课程的一部分，大家可以直接观看 <strong><a href="https://edu.hellobi.com/course/156" target="_blank" rel="noopener">Python3爬虫三大案例实战分享</a></strong> 整套视频课程放在天善智能这边了，大家如果感兴趣的话可以直接在这里购买，499元。 课程链接如下： <strong>天善智能：<a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></strong> <strong>网易云课堂：<a href="http://study.163.com/course/courseMain.htm?courseId=1003827039&amp;utm_campaign=commission&amp;utm_source=cp-1018878377&amp;utm_medium=share" target="_blank" rel="noopener">自己动手，丰衣足食！Python3网络爬虫实战案例</a></strong> <a href="https://edu.hellobi.com/course/157" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/04/WechatIMG257-1.jpeg" alt=""></a> 最后的最后希望大家可以多多支持！非常感谢！知识就是力量！也希望我的课程能为您创造更大的财富！</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-04-11 00:38:31" itemprop="dateCreated datePublished" datetime="2017-04-11T00:38:31+08:00">2017-04-11</time>
                </span>
                <span id="/4320.html" class="post-meta-item leancloud_visitors" data-flag-title="Python3爬虫视频学习教程" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>1.8k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4244.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4244.html" class="post-title-link" itemprop="url">Scrapy小技巧-MySQL存储</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p><a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/吃惊表情1.jpg" alt="吃惊表情1"></a> 这两天上班接手，别人留下来的爬虫发现一个很好玩的 SQL脚本拼接。 只要你的Scrapy Field字段名字和 数据库字段的名字 一样。那么恭喜你你就可以拷贝这段SQL拼接脚本。进行MySQL入库处理。 具体拼接代码如下：</p>
                  <figure class="highlight livecodeserver">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def process_item(self, <span class="keyword">item</span>, spider):</span><br><span class="line">    <span class="keyword">if</span> isinstance(<span class="keyword">item</span>, WhoscoredNewItem):</span><br><span class="line">        table_name = <span class="keyword">item</span>.pop(<span class="string">'table_name'</span>)</span><br><span class="line">        col_str = <span class="string">''</span></span><br><span class="line">        row_str = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> <span class="keyword">item</span>.<span class="built_in">keys</span>():</span><br><span class="line">            col_str = col_str + <span class="string">" "</span> + key + <span class="string">","</span></span><br><span class="line">            row_str = <span class="string">"&#123;&#125;'&#123;&#125;',"</span>.<span class="built_in">format</span>(row_str, <span class="keyword">item</span>[key] <span class="keyword">if</span> <span class="string">"'"</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">item</span>[key] <span class="keyword">else</span> <span class="keyword">item</span>[key].<span class="built_in">replace</span>(<span class="string">"'"</span>, <span class="string">"\\'"</span>))</span><br><span class="line">            sql = <span class="string">"insert INTO &#123;&#125; (&#123;&#125;) VALUES (&#123;&#125;) ON DUPLICATE KEY UPDATE "</span>.<span class="built_in">format</span>(table_name, col_str[<span class="number">1</span>:<span class="number">-1</span>], row_str[:<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">for</span> (key, <span class="built_in">value</span>) <span class="keyword">in</span> <span class="literal">six</span>.iteritems(<span class="keyword">item</span>):</span><br><span class="line">            sql += <span class="string">"&#123;&#125; = '&#123;&#125;', "</span>.<span class="built_in">format</span>(key, <span class="built_in">value</span> <span class="keyword">if</span> <span class="string">"'"</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">value</span> <span class="keyword">else</span> <span class="built_in">value</span>.<span class="built_in">replace</span>(<span class="string">"'"</span>, <span class="string">"\\'"</span>))</span><br><span class="line">        sql = sql[:<span class="number">-2</span>]</span><br><span class="line">        self.cursor.execute(sql) <span class="comment">#执行SQL</span></span><br><span class="line">        self.cnx.commit()<span class="comment"># 写入操作</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个SQL拼接实现了，如果数据库存在相同数据则 更新，不存在则插入 的SQL语句 具体实现就是第一个for循环，获取key作为MySQL字段名字、VALUES做为SQL的VALUES（拼接成一个插入的SQL语句） 第二个for循环，实现了 字段名 = VALUES的拼接。 和第一个for循环的中的sql就组成了 insert into XXXXX on duplicate key update 这个。存在则更新 不存在则插入的SQL语句。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ图片20161021225948.jpg" alt="QQ图片20161021225948"></a> 我只能所 6666666666 写这个拼接的小哥儿有想法。还挺通用。 不知道你们有没有想到这种方法 反正我是没想到。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-03-19 17:05:09" itemprop="dateCreated datePublished" datetime="2017-03-19T17:05:09+08:00">2017-03-19</time>
                </span>
                <span id="/4244.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapy小技巧-MySQL存储" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>989</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4197.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/4197.html" class="post-title-link" itemprop="url">WordPress 远程附件上传插件 For 又拍云【升级版】</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>今天给大家介绍 WordPress Plugin for UPYUN 插件，专为<a href="https://www.upyun.com/index.html" target="_blank" rel="noopener">又拍云</a>和 WordPress 用户准备，主要功能如下：</p>
                  <ol>
                    <li>可以与 WordPress 无缝结合，通过 WordPress 上传图片和文件到又拍云, 支持大文件上传（需要开启表单 API) 和防盗链功能</li>
                    <li>支持同步删除（在 WordPress 后台媒体管理 “删除” 附件后，又拍云服务器中的文件也随之删除)</li>
                    <li>增加图片编辑功能</li>
                    <li>优化防盗链功能</li>
                    <li>增加与水印插件的兼容性，使上传到远程服务器的图片同样可以加上水印等</li>
                  </ol>
                  <p>PS：修复了很多之前版本存在的 bug，具体可访问：<a href="https://github.com/ihacklog/hacklog-remote-attachment-upyun" target="_blank" rel="noopener">github</a> 又拍云是以 CDN 为核心业务，另外提供云存储、云处理、云安全、流量营销等的云服务商，有开放且可扩展的API，以及开放的SDK和第三方插件，还针对开发者启动了 <a href="https://www.upyun.com/league.html" target="_blank" rel="noopener">又拍云联盟</a> 活动，可以每月获取免费空间和流量。更多介绍，请访问<a href="https://www.upyun.com/index.html" target="_blank" rel="noopener">又拍云</a>。 <strong>安装插件：</strong> 进入到你的 WordPress 的 wp-content/plugins 目录下</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # <span class="keyword">pwd</span>/home/wwwroot/blog.v5linux.<span class="keyword">com</span>/<span class="keyword">wp</span>-content/plugins`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>克隆插件</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # git clone https:<span class="comment">//github.com/ihacklog/hacklog-remote-attachment-upyun.</span></span><br><span class="line">gitInitialized empty Git repository <span class="keyword">in</span> /home/wwwroot/blog.v5linux.com/wp-</span><br><span class="line">content/plugins/hacklog-remote-attachment-upyun/.git/remote: Counting </span><br><span class="line">objects: <span class="number">387</span>, done.remote: Compressing objects: <span class="number">100</span>% (<span class="number">31</span>/<span class="number">31</span>), done.</span><br><span class="line">remote: Total <span class="number">387</span> (delta <span class="number">16</span>), reused <span class="number">0</span> (delta <span class="number">0</span>), pack-reused <span class="number">356</span>Receiving </span><br><span class="line">objects: <span class="number">100</span>% (<span class="number">387</span>/<span class="number">387</span>), <span class="number">399.17</span> KiB | <span class="number">106</span> KiB/s, done.Resolving deltas:</span><br><span class="line"> <span class="number">100</span>% (<span class="number">223</span>/<span class="number">223</span>), done.`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>设置权限</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">` # ll总用量 <span class="number">16</span>drwxr-xr-x <span class="number">4</span> www  www  <span class="number">4096</span> <span class="number">1</span>月  <span class="number">12</span> <span class="number">13</span>:<span class="number">20</span> akismetdrwxr-xr-x </span><br><span class="line"><span class="number">8</span> root root <span class="number">4096</span> <span class="number">1</span>月  <span class="number">16</span> <span class="number">11</span>:<span class="number">34</span> hacklog-remote-attachment-upyun-rw-r--r-- <span class="number">1</span> </span><br><span class="line">www  www  <span class="number">2255</span> <span class="number">5</span>月  <span class="number">23</span> <span class="number">2013</span> hello.php-rw-r--r-- <span class="number">1</span> www  www    <span class="number">28</span> <span class="number">6</span>月   </span><br><span class="line"><span class="number">5</span> <span class="number">2014</span> index.php# chown -R www:www hacklog-remote-attachment-upyun/`</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>注意，如果你是虚拟主机，请下载后打包成 zip 文件上传到 plugins 目录下插件配置 <strong>插件设置</strong></p>
                  <p><a href="https://img.wpdaxue.com/2017/03/screenshot-1.png" target="_blank" rel="noopener"><img src="https://static.oschina.net/uploads/img/201703/06153426_bm5y.png" alt=""></a> 主要配置 空间名：后台创建的存储类型服务的名称 操作员和操作员密码：后台获取 表单密钥：<a href="https://console.upyun.com/login/" target="_blank" rel="noopener">又拍云控制台</a> 找到对应的服务 — 高级选项 - 开启表单密钥远程基本 URL：填写你的绑定域名或默认域名（强烈建议使用绑定域名） REST 远程路径和 HTTP 路径：根据需求填写 插件启用和配置详情，请参考：<a href="http://support.upyun.com/hc/kb/article/1025121/" target="_blank" rel="noopener">WordPress 远程附件上传插件</a></p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/yvette_" class="author" itemprop="url" rel="index">yvette_</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-03-12 08:46:01" itemprop="dateCreated datePublished" datetime="2017-03-12T08:46:01+08:00">2017-03-12</time>
                </span>
                <span id="/4197.html" class="post-meta-item leancloud_visitors" data-flag-title="WordPress 远程附件上传插件 For 又拍云【升级版】" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>1.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>1 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4048.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> Python <i class="label-arrow"></i>
                  </a>
                  <a href="/4048.html" class="post-title-link" itemprop="url">小白进阶之Scrapy第三篇（基于Scrapy-Redis的分布式以及cookies池）</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>啥话都不说了、进入正题。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ图片20170205084843.jpg" alt="QQ图片20170205084843"></a> 首先我们更新一下scrapy版本。最新版为1.3 再说一遍Windows的小伙伴儿 pip是装不上Scrapy的。推荐使用anaconda 、不然还是老老实实用Linux吧</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">conda install <span class="attribute">scrapy</span>==1.3</span><br><span class="line">或者</span><br><span class="line">pip install <span class="attribute">scrapy</span>==1.3</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装Scrapy-Redis</p>
                  <figure class="highlight mipsasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">conda <span class="keyword">install </span><span class="keyword">scrapy-redis</span></span><br><span class="line"><span class="keyword">或者</span></span><br><span class="line"><span class="keyword">pip </span><span class="keyword">install </span><span class="keyword">scrapy-redis</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>需要注意： Python 版本为 2.7，3.4 或者3.5 。个人使用3.6版本也没有问题 Redis&gt;=2.8 Scrapy&gt;=1.0 Redis-py&gt;=2.1 。 3.X版本的Python 都是自带Redis-py 其余小伙伴如果没有的话、自己 pip 安装一下。 开始搞事！ 开始之前我们得知道scrapy-redis的一些配置：PS 这些配置是写在Scrapy项目的settings.py中的！</p>
                  <figure class="highlight vala">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="meta">#启用Redis调度存储请求队列</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#确保所有的爬虫通过Redis去重</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#默认请求序列化使用的是pickle 但是我们可以更改为其他类似的。PS：这玩意儿2.X的可以用。3.X的不能用</span></span><br><span class="line"><span class="meta">#SCHEDULER_SERIALIZER = "scrapy_redis.picklecompat"</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#不清除Redis队列、这样可以暂停/恢复 爬取</span></span><br><span class="line"><span class="meta">#SCHEDULER_PERSIST = True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#使用优先级调度请求队列 （默认使用）</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'</span></span><br><span class="line"><span class="meta">#可选用的其它队列</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'</span></span><br><span class="line"><span class="meta">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#最大空闲时间防止分布式爬虫因为等待而关闭</span></span><br><span class="line"><span class="meta">#这只有当上面设置的队列类是SpiderQueue或SpiderStack时才有效</span></span><br><span class="line"><span class="meta">#并且当您的蜘蛛首次启动时，也可能会阻止同一时间启动（由于队列为空）</span></span><br><span class="line"><span class="meta">#SCHEDULER_IDLE_BEFORE_CLOSE = 10</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#将清除的项目在redis进行处理</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#序列化项目管道作为redis Key存储</span></span><br><span class="line"><span class="meta">#REDIS_ITEMS_KEY = '%(spider)s:items'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#默认使用ScrapyJSONEncoder进行项目序列化</span></span><br><span class="line"><span class="meta">#You can use any importable path to a callable object.</span></span><br><span class="line"><span class="meta">#REDIS_ITEMS_SERIALIZER = 'json.dumps'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#指定连接到redis时使用的端口和地址（可选）</span></span><br><span class="line"><span class="meta">#REDIS_HOST = 'localhost'</span></span><br><span class="line"><span class="meta">#REDIS_PORT = 6379</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#指定用于连接redis的URL（可选）</span></span><br><span class="line"><span class="meta">#如果设置此项，则此项优先级高于设置的REDIS_HOST 和 REDIS_PORT</span></span><br><span class="line"><span class="meta">#REDIS_URL = 'redis://user:pass@hostname:9001'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#自定义的redis参数（连接超时之类的）</span></span><br><span class="line"><span class="meta">#REDIS_PARAMS  = &#123;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#自定义redis客户端类</span></span><br><span class="line"><span class="meta">#REDIS_PARAMS['redis_cls'] = 'myproject.RedisClient'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#如果为True，则使用redis的'spop'进行操作。</span></span><br><span class="line"><span class="meta">#如果需要避免起始网址列表出现重复，这个选项非常有用。开启此选项urls必须通过sadd添加，否则会出现类型错误。</span></span><br><span class="line"><span class="meta">#REDIS_START_URLS_AS_SET = False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#RedisSpider和RedisCrawlSpider默认 start_usls 键</span></span><br><span class="line"><span class="meta">#REDIS_START_URLS_KEY = '%(name)s:start_urls'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#设置redis使用utf-8之外的编码</span></span><br><span class="line"><span class="meta">#REDIS_ENCODING = 'latin1'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>请各位小伙伴儿自行挑选需要的配置写到项目的settings.py文件中 英语渣靠Google、看不下去的小伙伴儿看这儿：<a href="http://scrapy-redis.readthedocs.io/en/stable/readme.html" target="_blank" rel="noopener">http://scrapy-redis.readthedocs.io/en/stable/readme.html</a> 继续在我们上一篇博文中的爬虫程序修改： 首先把我们需要的redis配置文件写入settings.py中： 如果你的redis数据库按照前一片博文配置过则需要以下至少三项</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attr">SCHEDULER</span> = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DUPEFILTER_CLASS</span> = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">REDIS_URL</span> = <span class="string">'redis://root:密码@主机ＩＰ:端口'</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第三项请按照你的实际情况配置。 Nice配置文件写到这儿。我们来做一些基本的反爬虫设置 最基本的一个切换UserAgent！ 首先在项目文件中新建一个useragent.py用来写一堆 User-Agent（可以去网上找更多，也可以用下面这些现成的）</p>
                  <figure class="highlight smalltalk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">agents = [</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/2.02E (Win95; U)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/3.01Gold (Win95; I)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/4.8 [en] (Windows NT 5.1; U)"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)"</span>,</span><br><span class="line">    <span class="comment">"HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">    <span class="comment">"Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1"</span>,</span><br><span class="line">]</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>现在我们来重写一下Scrapy的下载中间件（哇靠！！重写中间件 好高端啊！！会不会好难!!!放心！！！So Easy！！跟我做！包教包会，毕竟不会你也不能顺着网线来打我啊）： 关于重写中间件的详细情况 请参考 官方文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.DownloaderMiddleware" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.DownloaderMiddleware</a> 在项目中新建一个middlewares.py的文件（如果你使用的新版本的Scrapy，在新建的时候会有这么一个文件，直接用就好了） 首先导入UserAgentMiddleware毕竟我们要重写它啊！</p>
                  <figure class="highlight clean">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">import</span> json ##处理json的包</span><br><span class="line"><span class="keyword">import</span> redis #Python操作redis的包</span><br><span class="line"><span class="keyword">import</span> random #随机选择</span><br><span class="line"><span class="keyword">from</span> .useragent <span class="keyword">import</span> agents #导入前面的</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware #UserAegent中间件</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware #重试中间件</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p> 开写：</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserAgentmiddleware</span>(<span class="title">UserAgentMiddleware</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(<span class="keyword">self</span>, request, spider)</span></span><span class="symbol">:</span></span><br><span class="line">        agent = random.choice(agents)</span><br><span class="line">        request.headers[<span class="string">"User-Agent"</span>] = agent</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第一行：定义了一个类UserAgentmiddleware继承自UserAgentMiddleware 第二行：定义了函数<code>process_request</code>(<em>request</em>, <em>spider</em>)为什么定义这个函数，因为Scrapy每一个request通过中间 件都会调用这个方法。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170206-223156.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170206-223156.png" alt="QQ20170206-223156"></a> 第三行：随机选择一个User-Agent 第四行：设置request的User-Agent为我们随机的User-Agent ^_^Y(^o^)Y一个中间件写完了！哈哈 是不是So easy！ 下面就需要登陆了。这次我们不用上一篇博文的FromRequest来实现登陆了。我们来使用Cookie登陆。这样的话我们需要重写Cookie中间件！分布式爬虫啊！你不能手动的给每个Spider写一个Cookie吧。而且你还不会知道这个Cookie到底有没有失效。所以我们需要维护一个Cookie池(这个cookie池用redis)。 好！来理一理思路，维护一个Cookie池最基本需要具备些什么功能呢？</p>
                  <ol>
                    <li>获取Cookie</li>
                    <li>更新Cookie</li>
                    <li>删除Cookie</li>
                    <li>判断Cookie是否可用进行相对应的操作（比如重试）</li>
                  </ol>
                  <p>好，我们先做前三个对Cookie进行操作。 首先我们在项目中新建一个cookies.py的文件用来写我们需要对Cookie进行的操作。 haoduofuli/haoduofuli/cookies.py: 首先日常导入我们需要的文件：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import redis</span><br><span class="line">import logging</span><br><span class="line"><span class="keyword">from</span> .settings import REDIS_URL ##获取settings.py中的REDIS_URL</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>首先我们把登陆用的账号密码 以Key:value的形式存入redis数据库。不推荐使用db0（这是Scrapy-redis默认使用的，账号密码单独使用一个db进行存储。） <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-221128@2x.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-221128@2x.png" alt="QQ20170207-221128@2x"></a> 就像这个样子。 解决第一个问题：获取Cookie：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import redis</span><br><span class="line">import logging</span><br><span class="line"><span class="keyword">from</span> .settings import REDIS_URL</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"><span class="comment">##使用REDIS_URL链接Redis数据库, deconde_responses=True这个参数必须要，数据会变成byte形式 完全没法用</span></span><br><span class="line">reds = redis.Redis.from_url(REDIS_URL, <span class="attribute">db</span>=2, <span class="attribute">decode_responses</span>=<span class="literal">True</span>)</span><br><span class="line">login_url = <span class="string">'http://haoduofuli.pw/wp-login.php'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##获取Cookie</span></span><br><span class="line">def get_cookie(account, password):</span><br><span class="line">    s = requests.Session()</span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">'log'</span>: account,</span><br><span class="line">        <span class="string">'pwd'</span>: password,</span><br><span class="line">        <span class="string">'rememberme'</span>: <span class="string">"forever"</span>,</span><br><span class="line">        <span class="string">'wp-submit'</span>: <span class="string">"登录"</span>,</span><br><span class="line">        <span class="string">'redirect_to'</span>: <span class="string">"http://http://www.haoduofuli.pw/wp-admin/"</span>,</span><br><span class="line">        <span class="string">'testcookie'</span>: <span class="string">"1"</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = s.post(login_url, <span class="attribute">data</span>=payload)</span><br><span class="line">    cookies = response.cookies.get_dict()</span><br><span class="line">    logger.<span class="builtin-name">warning</span>(<span class="string">"获取Cookie成功！（账号为:%s）"</span> % account)</span><br><span class="line">    return json.dumps(cookies)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这段很好懂吧。 使用requests模块提交表单登陆获得Cookie，返回一个通过Json序列化后的Cookie（如果不序列化，存入Redis后会变成Plain Text格式的，后面取出来Cookie就没法用啦。） 第二个问题：将Cookie写入Redis数据库（分布式呀，当然得要其它其它Spider也能使用这个Cookie了）</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">def init_cookie(red, spidername):</span><br><span class="line">    redkeys = reds.keys()</span><br><span class="line">    <span class="keyword">for</span><span class="built_in"> user </span><span class="keyword">in</span> redkeys:</span><br><span class="line">        password = reds.<span class="builtin-name">get</span>(user)</span><br><span class="line">        <span class="keyword">if</span> red.<span class="builtin-name">get</span>(<span class="string">"%s:Cookies:%s--%s"</span> % (spidername, user, password)) is None:</span><br><span class="line">            cookie = get_cookie(user, password)</span><br><span class="line">            red.<span class="builtin-name">set</span>(<span class="string">"%s:Cookies:%s--%s"</span>% (spidername, user, password), cookie)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>使用我们上面建立的redis链接获取redis db2中的所有Key(我们设置为账号的哦！)，再从redis中获取所有的Value(我设成了密码哦！) 判断这个spider和账号的Cookie是否存在，不存在 则调用get_cookie函数传入从redis中获取到的账号密码的cookie； 保存进redis，Key为spider名字和账号密码，value为cookie。 这儿操作redis的不是上面建立的那个reds链接哦！而是red;后面会传进来的(因为要操作两个不同的db,我在文档中没有看到切换db的方法，只好这么用了，知道的小伙伴儿留言一下)。 spidername获取方式后面也会说的。 还有剩余的更新Cookie 删除无法使用的账号等，大家伙可以自己试着写写（写不出来也没关系 不影响正常使用） 好啦！搞定！简直So Easy!!!! 现在开始大业了！重写cookie中间件；估摸着吧！聪明的小伙儿看了上面重写User-Agent的方法，十之八九也知道怎么重写Cookie中间件了。 好啦，现在继续写middlewares.py啦！</p>
                  <figure class="highlight reasonml">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">class</span> <span class="constructor">CookieMiddleware(RetryMiddleware)</span>:</span><br><span class="line"></span><br><span class="line">    def <span class="constructor">__init__(<span class="params">self</span>, <span class="params">settings</span>, <span class="params">crawler</span>)</span>:</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">RetryMiddleware</span>.</span><span class="module"><span class="identifier">__init__</span>(</span></span>self, settings)</span><br><span class="line">        self.rconn = redis.from<span class="constructor">_url(<span class="params">settings</span>['REDIS_URL'], <span class="params">db</span>=1, <span class="params">decode_responses</span>=True)</span>##decode_responses设置取出的编码为str</span><br><span class="line">        init<span class="constructor">_cookie(<span class="params">self</span>.<span class="params">rconn</span>, <span class="params">crawler</span>.<span class="params">spider</span>.<span class="params">name</span>)</span></span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def from<span class="constructor">_crawler(<span class="params">cls</span>, <span class="params">crawler</span>)</span>:</span><br><span class="line">        return cls(crawler.settings, crawler)</span><br><span class="line"></span><br><span class="line">    def process<span class="constructor">_request(<span class="params">self</span>, <span class="params">request</span>, <span class="params">spider</span>)</span>:</span><br><span class="line">        redisKeys = self.rconn.keys<span class="literal">()</span></span><br><span class="line">        <span class="keyword">while</span> len(redisKeys) &gt; <span class="number">0</span>:</span><br><span class="line">            elem = random.choice(redisKeys)</span><br><span class="line">            <span class="keyword">if</span> spider.name + ':Cookies' <span class="keyword">in</span> elem:</span><br><span class="line">                cookie = json.loads(self.rconn.get(elem))</span><br><span class="line">                request.cookies = cookie</span><br><span class="line">                request.meta<span class="literal">["<span class="identifier">accountText</span>"]</span> = elem.split(<span class="string">"Cookies:"</span>)<span class="literal">[-<span class="number">1</span>]</span></span><br><span class="line">                break</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>第一行：不说 第二行第三行得说一下 这玩意儿叫重载（我想了大半天都没想起来叫啥，还是问了大才。尴尬）有啥用呢： 也不扯啥子高深问题了，小伙伴儿可能发现，当你继承父类之后；子类是不能用 def <strong>init</strong>()方法的，不过重载父类之后就能用啦！ 第四行：settings[‘REDIS_URL’]是个什么鬼？这是访问scrapy的settings。怎么访问的？下面说 第五行：往redis中添加cookie。第二个参数就是spidername的获取方法（其实就是字典啦！）</p>
                  <figure class="highlight ruby">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">@classmethod</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> cls(crawler.settings, crawler)</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>这个貌似不好理解，作用看下面： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/D9DF3655-F28A-482C-8B02-C53B152958A0.jpg" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/D9DF3655-F28A-482C-8B02-C53B152958A0.jpg" alt="D9DF3655-F28A-482C-8B02-C53B152958A0"></a> 这样是不是一下就知道了？? 至于访问settings的方法官方文档给出了详细的方法： <a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#how-to-access-settings" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#how-to-access-settings</a> <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-233701@2x.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170207-233701@2x.png" alt="QQ20170207-233701@2x"></a> 下面就是完整的middlewares.py文件：</p>
                  <figure class="highlight python">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your spider middleware</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># http://doc.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> .useragent <span class="keyword">import</span> agents</span><br><span class="line"><span class="keyword">from</span> .cookies <span class="keyword">import</span> init_cookie, remove_cookie, update_cookie</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserAgentmiddleware</span><span class="params">(UserAgentMiddleware)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        agent = random.choice(agents)</span><br><span class="line">        request.headers[<span class="string">"User-Agent"</span>] = agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CookieMiddleware</span><span class="params">(RetryMiddleware)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, settings, crawler)</span>:</span></span><br><span class="line">        RetryMiddleware.__init__(self, settings)</span><br><span class="line">        self.rconn = redis.from_url(settings[<span class="string">'REDIS_URL'</span>], db=<span class="number">1</span>, decode_responses=<span class="literal">True</span>)<span class="comment">##decode_responses设置取出的编码为str</span></span><br><span class="line">        init_cookie(self.rconn, crawler.spider.name)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(crawler.settings, crawler)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        redisKeys = self.rconn.keys()</span><br><span class="line">        <span class="keyword">while</span> len(redisKeys) &gt; <span class="number">0</span>:</span><br><span class="line">            elem = random.choice(redisKeys)</span><br><span class="line">            <span class="keyword">if</span> spider.name + <span class="string">':Cookies'</span> <span class="keyword">in</span> elem:</span><br><span class="line">                cookie = json.loads(self.rconn.get(elem))</span><br><span class="line">                request.cookies = cookie</span><br><span class="line">                request.meta[<span class="string">"accountText"</span>] = elem.split(<span class="string">"Cookies:"</span>)[<span class="number">-1</span>]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment">#else:</span></span><br><span class="line">                <span class="comment">#redisKeys.remove(elem)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#def process_response(self, request, response, spider):</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#"""</span></span><br><span class="line">         <span class="comment">#下面的我删了，各位小伙伴可以尝试以下完成后面的工作</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#你需要在这个位置判断cookie是否失效</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#然后进行相应的操作，比如更新cookie  删除不能用的账号</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#写不出也没关系，不影响程序正常使用，</span></span><br><span class="line"></span><br><span class="line">         <span class="comment">#"""</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>存储我也不写啦！就是这么简单一个分布式的scrapy就这么完成啦！！！ 我试了下 三台机器 两个小时 就把整个站点全部爬完了。 弄好你的存储 放在不同的机器上就可以跑啦！ 完整的代码在GitHub上： GitHub：<a href="https://github.com/thsheep/haoduofuli" target="_blank" rel="noopener">https://github.com/thsheep/haoduofuli</a> Y(^o^)Y完工 下篇博文来对付爬虫的大敌：Ajax 以后的教程用微博做靶子，那些数据比较有用，可以玩玩分析什么的。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-02-07 23:53:44" itemprop="dateCreated datePublished" datetime="2017-02-07T23:53:44+08:00">2017-02-07</time>
                </span>
                <span id="/4048.html" class="post-meta-item leancloud_visitors" data-flag-title="小白进阶之Scrapy第三篇（基于Scrapy-Redis的分布式以及cookies池）" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>15k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>14 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/4020.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> 技术杂谈 <i class="label-arrow"></i>
                  </a>
                  <a href="/4020.html" class="post-title-link" itemprop="url">Scrapy分布式的前篇--让redis和MongoDB安全点</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>各位小伙伴 大家好啊！年假结束了··· 也该开始继续我的装逼之旅了。 年前博文的结尾说了 还有一个基于Scrapy的分布式版本、 今天这博文就先给大家做些前期工作，其实吧、最主要的是防止你的服务器因为这篇博文被轮········· 博文开始之前 我们先来看篇文章： <a href="http://www.youxia.org/daily-news-attack-extortion-does-not-delay-a-week-had-27000-mongodb-database.html" target="_blank" rel="noopener">http://www.youxia.org/daily-news-attack-extortion-does-not-delay-a-week-had-27000-mongodb-database.html</a> 关于年前MongoDB由于<strong>默认可匿名访问</strong> 而导致了一大堆的管理员掉坑里 预估中国有十万数据库被坑。 这是继Redis之后又一个小白式的错误······（Redis也是默认匿名访问） 所以在下一篇博文开始之前，先给一些新手小伙伴做一些准备工作。 因为篇幅较少 先写写Redis的一些安全设置： 安装Redis: 请参考这儿;<a href="https://redis.io/download" target="_blank" rel="noopener">https://redis.io/download</a></p>
                  <figure class="highlight gams">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="symbol">$</span> wget http:<span class="comment">//download.redis.io/releases/redis-3.2.7.tar.gz</span></span><br><span class="line"><span class="symbol">$</span> tar xzf redis<span class="number">-3.2</span><span class="number">.7</span>.tar.gz</span><br><span class="line"><span class="symbol">$</span> cd redis<span class="number">-3.2</span><span class="number">.7</span></span><br><span class="line"><span class="symbol">$</span> make</span><br><span class="line"></span><br><span class="line"><span class="symbol">$</span> src/redis-server</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>ps :如果以上有报错，可能是你的服务器没有安装依赖： CentOS7：</p>
                  <figure class="highlight brainfuck">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="comment">yum</span> <span class="comment">install</span> <span class="literal">-</span><span class="comment">y</span> <span class="comment">gcc</span><span class="literal">-</span><span class="comment">c</span>++ <span class="comment">tcl</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <pre><code>只写关于Linux的、Windows的很简单，配置文件通用： 安装完成后 在目录 redis-3.2.7中有一个redis.conf的配置文件，按照默认习惯我们将其复制到/etc目录下：
</code></pre>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# cp redis<span class="number">-3.2</span><span class="number">.7</span>/redis.conf /etc</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>PS：请使用复制（cp）而不要使用移动（mv）；毕竟你要弄错了还可以再拷贝一份儿过去用不是？ 使用vim编辑刚刚拷贝的redis.conf</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">vim</span> /etc/redis.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>PS:使用vim需要先安装： CentOS7：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">yum  <span class="keyword">install</span> vim</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>我们需要注意以下几项： 1、注释掉47行的bind 127.0.0.1（这个意思是限制为只能 127.0.0.1 也就是本机登录）PS：个人更建议 将你需要连接Redis数据库的IP地址填写在此处，而不是注释掉。这样做会比直接注释掉更加安全。 2、更改第84行port 6379 为你需要的端口号（这是Redis的默认监听端口）PS：个人建议务必更改 3、更改第128行 daemonize no 为 daemonize yes（这是让Redis后台运行） PS:个人建议更改 4、取消第 480 # requirepass foobared 的#注释符（这是redis的访问密码） 并更改foobared为你需要的密码 比如 我需们需要密码为123456 则改为 requirepass 123456。PS：密码不可过长否则Python的redis客户端无法连接 以上配置文件更改完毕，需要在防火墙放行：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">firewall-cmd <span class="attribute">--zone</span>=public <span class="attribute">--add-port</span>=xxxx/tcp --permanent</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>请将xxxx更改为你自己的redis端口。 重启防火墙生效：</p>
                  <figure class="highlight css">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="selector-tag">systemctl</span> <span class="selector-tag">restart</span> <span class="selector-tag">firewalld</span><span class="selector-class">.service</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>指定配置文件启动redis:</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# redis<span class="number">-3.2</span><span class="number">.7</span>/src/redis-server /etc/redis.conf</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>加入到开机启动:</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">echo</span> <span class="string">"/root/redis-3.2.6/src/redis-server /etc/redis.conf"</span> &gt;&gt; <span class="string">/etc/rc.local</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>一个较为安全的redis配置完毕。 redis的桌面客户端我推荐：RedisDesktopManager 去下面这个地址下载就不需要捐助啦！ <a href="https://github.com/uglide/RedisDesktopManager/releases" target="_blank" rel="noopener">https://github.com/uglide/RedisDesktopManager/releases</a> 当然还有一些其他配置、我们用不到也就不写啦！ <strong>MongoDB：</strong> 这次MongoDB挺惨啊！由于默认匿名访问、下面给MongoDB配置一点安全措施： 安装MongoDB： 以CentOS7为例其余发行版请参考官方文档：<a href="https://docs.mongodb.com/manual/administration/install-on-linux/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/administration/install-on-linux/</a> 1、建一个yum源：</p>
                  <figure class="highlight angelscript">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[<span class="symbol">root@</span>MyCloudServer ~]# vim /etc/yum.repos.d/mongodb-org<span class="number">-3.4</span>.repo</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>写入以下内容：</p>
                  <figure class="highlight ini">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="section">[mongodb-org-3.4]</span></span><br><span class="line"><span class="attr">name</span>=MongoDB Repository</span><br><span class="line"><span class="attr">baseurl</span>=https://repo.mongodb.org/yum/redhat/<span class="variable">$releasever</span>/mongodb-org/<span class="number">3.4</span>/x<span class="number">86_64</span>/</span><br><span class="line"><span class="attr">gpgcheck</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">enabled</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">gpgkey</span>=https://www.mongodb.org/static/pgp/server-<span class="number">3.4</span>.asc</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>2、安装mongoDB以及相关工具：</p>
                  <figure class="highlight cmake">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo yum <span class="keyword">install</span> -y mongodb-org</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>3、启动MongoDB：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>mongod start</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>ＰＳ：如果你的服务器在使用SELinux的话，你需要配置SElinux允许MongoDB启动，当然更简单的方法是关掉SElinux。 关闭SElinux:</p>
                  <figure class="highlight autoit">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[root<span class="symbol">@MyCloudServer</span> ~]<span class="meta"># vim /etc/selinux/config</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>将第7行设置为：SELINUX=disabled 4、停止MongoDB：</p>
                  <figure class="highlight routeros">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">sudo<span class="built_in"> service </span>mongod stop</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面安装完按成了MongoDB下面要步入正题了： 1、备份和更改配置文件：</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">[root@MyCloudServer ~]# <span class="keyword">cp</span> /etc/mongod.<span class="keyword">conf</span>  /etc/mongod_backup.<span class="keyword">conf</span></span><br><span class="line">[root@MyCloudServer ~]# <span class="keyword">vim</span> /etc/mongod.<span class="keyword">conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>更改第28行 prot 2701为你需要更改的端口（这是MongoDB默认的监听端口） 更改第29行 bindIp: 127.0.0.1为0.0.0.0（MongoDB默认只能本地访问）ＰＳ：个人建议此处添加你需要连接MongoDB服务器的IP地址、而不是改成0.0.0.0。这样做会更安全 启动MongoDB：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">mongod <span class="params">--config</span> <span class="string">/etc/mongod.conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>意思是：指定/etc/mongod.conf为配置文件启动MongoDB 好了、配置文件更改完毕，现在可以外网访问我们的MongoDB了！不需要用户名！匿名的！现在我们进行下一步设置。 因为MongoDB默认是匿名访问的、我们需要开启用户认证。 我估摸着很多哥们儿和我一样没补全 啥都不会干、所以直接在服务器上改就不太现实了，需要借助于第三方客户端。我个人推荐：mongobooster 官方地址：<a href="https://mongobooster.com/" target="_blank" rel="noopener">https://mongobooster.com/</a> 收费版免费版功能一样 不用在意： 首先我们需要连上MongoDB服务器（别忘了防火墙放行你使用的端口啊！！！） <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/170203.gif" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/170203.gif" alt="170203"></a> 连上之后大慨是这个样子： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/17020301.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/17020301.png" alt="17020301"></a> 按下Ctrl+T 打开shell界面输入一下内容：</p>
                  <figure class="highlight gherkin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">use admin</span><br><span class="line">db.createUser(</span><br><span class="line">   &#123;</span><br><span class="line">     user: <span class="string">"你的用户名"</span>,</span><br><span class="line">     pwd: <span class="string">"你的密码"</span>,</span><br><span class="line">     roles: [ &#123;role:<span class="string">"userAdminAnyDatabase"</span>, db:<span class="string">"admin"</span>&#125; ]</span><br><span class="line">    /<span class="symbol">*</span> All build-in Roles </span><br><span class="line">    Database User Roles: read|<span class="string">readWrite</span></span><br><span class="line"><span class="string">    数据库用户角色：读</span>|<span class="string">读写</span></span><br><span class="line"><span class="string">    Database Admion Roles: dbAdmin</span>|<span class="string">dbOwner</span>|userAdmin</span><br><span class="line">    数据库管理角色：数据库管理员|<span class="string">数据库所有者</span>|<span class="string">用户管理</span></span><br><span class="line"><span class="string">    Cluster Admin Roles: clusterAdmin</span>|<span class="string">clusterManager</span>|<span class="string">clusterMonitor</span>|hostManager</span><br><span class="line">    集群管理角色：</span><br><span class="line">    Backup and Restoration Roles: backup|<span class="string">restore</span></span><br><span class="line"><span class="string">    All-Database Roles: readAnyDatabase</span>|<span class="string">readWriteAnyDatabase</span>|<span class="string">userAdminAnyDatabase</span>|dbAdminAnyDatabase</span><br><span class="line">    所有数据库角色：读所有数据库|<span class="string">读写所有数据库</span>|<span class="string">所有数据库的用户管理员</span>|<span class="string">所有数据库的管理员</span></span><br><span class="line"><span class="string">    Superuser Roles: root */</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string">)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>再点击run运行即可 会在信息栏中提示True 现在断开数据库连接、再打开会发现多出一个admin的数据库。 <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ截图20170204001502.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ截图20170204001502.png" alt="QQ截图20170204001502"></a> 上面的都做了些什么呢？ 首先我们新建了一个admin的数据库（MongoDB的原则哦、有则切换没有就创建） 然后在admin数据中创建了一个用户 和 密码 赋予了这个用户管理admin数据库 所有数据库用户的权限。 至于有那些权限 在注释中都有写哦！常用的我估摸着写了个对应意思········· OK！搞定这一部分 就可以开启MongoDB的用户认证了！ 怎么开启呢？首先关闭正在运行的MongoDB：</p>
                  <figure class="highlight vim">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">ps</span> -<span class="keyword">e</span> | <span class="keyword">grep</span> mongod</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>上面的命令会找出MongoDB的进程号、然后运行kill 进程号即可！ 开启MongoDB：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">mongod <span class="params">--auth</span> <span class="params">--config</span> <span class="string">/etc/mongod.conf</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>意思是：以认证模式 指定/etc/mongod.conf启动 MongoDB。 加入开机启动：</p>
                  <figure class="highlight jboss-cli">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">echo</span> <span class="string">"mongod --auth --config /etc/mongod.conf"</span> &gt;&gt; <span class="string">/etc/rc.local</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>好了！现在MongoDB也配置完成 啦！ 现在如果你需要新建一个用户让其使用数据库 你该怎么做呢？ 像下面这样；首先你需要连接到admin数据库！ 在选项Basic中照常配置： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004332@2x.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004332@2x.png" alt="QQ20170204-004332@2x"></a> 需要额外设置的是Authentication选项： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004627@2x.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004627@2x.png" alt="QQ20170204-004627@2x"></a> 连接成功后大概是这个样子： <a href="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004930@2x.png" target="_blank" rel="noopener"><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2017/02/QQ20170204-004930@2x.png" alt="QQ20170204-004930@2x"></a> 需要注意的一点是：这个用户只能看到所有的数据库和用户、并不能看到数据！因为我们创建的时候只给了所有数据库用户管理的权限哦！ 然后打开shell界面按照创建admin的模板执行即可：</p>
                  <figure class="highlight gherkin">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">use 想要创建的数据库</span><br><span class="line">db.createUser(</span><br><span class="line">   &#123;</span><br><span class="line">     user: <span class="string">"想要使用的用户名"</span>,</span><br><span class="line">     pwd: <span class="string">"想要使用的密码"</span>,</span><br><span class="line">     roles: [ &#123;role:<span class="string">"赋予什么样的权限"</span>, db:<span class="string">"创建的数据库"</span>&#125; ]</span><br><span class="line">    /<span class="symbol">*</span> All build-in Roles </span><br><span class="line">    Database User Roles: read|<span class="string">readWrite</span></span><br><span class="line"><span class="string">    数据库用户角色：读</span>|<span class="string">读写</span></span><br><span class="line"><span class="string">    Database Admion Roles: dbAdmin</span>|<span class="string">dbOwner</span>|userAdmin</span><br><span class="line">    数据库管理角色：数据库管理员|<span class="string">数据库所有者</span>|<span class="string">用户管理</span></span><br><span class="line"><span class="string">    Cluster Admin Roles: clusterAdmin</span>|<span class="string">clusterManager</span>|<span class="string">clusterMonitor</span>|hostManager</span><br><span class="line">    集群管理角色：</span><br><span class="line">    Backup and Restoration Roles: backup|<span class="string">restore</span></span><br><span class="line"><span class="string">    All-Database Roles: readAnyDatabase</span>|<span class="string">readWriteAnyDatabase</span>|<span class="string">userAdminAnyDatabase</span>|dbAdminAnyDatabase</span><br><span class="line">    所有数据库角色：读所有数据库|<span class="string">读写所有数据库</span>|<span class="string">所有数据库的用户管理员</span>|<span class="string">所有数据库的管理员</span></span><br><span class="line"><span class="string">    Superuser Roles: root */</span></span><br><span class="line"><span class="string">   &#125;</span></span><br><span class="line"><span class="string">)</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>创建完成后、就可以用创建好的用户名和密码去链接有权限的数据库啦！！是不是So Easy！！！ 其实吧 还是 bindIp安全 哈哈哈！ 以上完毕！！ 下一篇就是基于Scrapy-Redis的分布式了、真的超级简单！简单得不要不要的</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/哎哟卧槽" class="author" itemprop="url" rel="index">哎哟卧槽</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-02-04 00:59:05" itemprop="dateCreated datePublished" datetime="2017-02-04T00:59:05+08:00">2017-02-04</time>
                </span>
                <span id="/4020.html" class="post-meta-item leancloud_visitors" data-flag-title="Scrapy分布式的前篇--让redis和MongoDB安全点" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>4.8k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>4 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3998.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> 个人日记 <i class="label-arrow"></i>
                  </a>
                  <a href="/3998.html" class="post-title-link" itemprop="url">回首我的二零一六</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>没有选择那个二零一六年尾，而是选择了这个二零一六年尾来总结。</p>
                  <p>毕竟元旦那时候真的被一堆考试烦透，说到考试，可以说我是极其反对这种形式，在我看来，因为有了考试，学一门课反倒成了任务，而不是真正踏实地去学，有了考试，学习的目的不再是单纯学习，而是为了最后的应考。所以很多科目，经验之谈，一旦它成了我的课程，我反倒没有那么多耐心去学它。而又有很多考试，理解性的东西真的不考察理解，你背过，就高分了，背不过，那就没分。做到原题了，就有分了，做不到原题，那就不一定有分。到头来，一门课程的结束伴随着你仅仅在短时间内记忆了一些概念和题目去应考。考试结束，抛掉了，你还记得什么？何况，某些课，你可能这辈子都用不到了。 然而就是这样，或许真的没有比这更合适的考察方式了吧。 果然一扯就停不下来，后面简单点扯。 嗯，就是这样，我来北航读研了，2016级的新生，刚刚渡过了研究生第一个学期。这个学期，基本上把研究生所有的课都上完。我能体会到自己还是偏重于实践性的东西而非理论，一个想法，纯理论都是空谈，实现出来才是最终目标。作为一名程序猿，平时我喜欢瞎捣腾些东西，逛GitHub，搜开源项目，找到有趣的组件来实现自己想要的功能。 二零一六年上半年，毕设的一段时间吧，由于自己对爬虫比较感兴趣，正好毕设也有个选题是关于爬虫的，所以干脆毕设就实现了一个分布式爬虫框架，虽然也是开源项目组合起来的，Scrapy，Redis，Mongo，Splash，Django等等吧，不过这个过程的探索也是受益匪浅。哦对了，也是上半年这个时候吧，换上了自己的第一台Mac，联想也终于寿终正寝了，我也算是真正踏上了程序员的行列。一年下来，不得不说，开发真的太便捷。 那时候正好是大四，也没多少事，期间也接着大大小小的外包，赚点外快，后来又入手了单反，然而到现在我发现自己没有那么狂爱摄影。 每年都有毕业季，今年轮到我们了。毕业行去了云南，还有些意犹未尽的感觉，也感谢一路同行的小伙伴给我拍的绝世美照哈哈。后来忙着毕业照啦，穿上学士服，辗转各大校区，各种奇怪的姿势拍拍拍。现在真的挺想念山大的，那里的人儿，那里的事儿。嗯，毕业快乐。 暑假，我又回到北京。一件重要的事那就是女朋友保研，虽然中间出了点小叉子，不过还是恭喜她能被中科院录取，随后在北京呆了近整个暑假。 随之而来的，便是北航研究生的新学期了。嗯，从山大到了北航。开学时我并没有那么欣喜，或许是已经过来太多次了习惯了。上学期课满满当当，然而你以为我会乖乖听课？我可不是那种学霸。我总是有着自己的学习和项目计划，学习一些我觉得有用的东西，比如Andrew Ng的机器学习、Web相关知识还有在做自己在忙的一些项目。前面说了我不喜欢上课，不喜欢考试，因为我觉得这些时间，可以去做更有意义的事情。最后几个星期突击一下就好了。其实我的大学就是这么过来的，上课都在学习别的和撸代码去了，成绩也还说得过去，不过感觉这样还是挺充实的。然而考前突击的时候是难了点儿，因为大部分我得预习。还好，这学期过去了，后面的时间我终于可以尽情做我想做的事情了，喜欢无拘无束自己探索的感觉。 期间其实还在和同学创业，演艺行业平台，自己负责技术这方面，好玩表演（hwby.com），一年来了吧，网站实现后投入运营，前期还是非常艰难，不过近期也还是有了起色，继续加油。写的过程中也抽离出了自己的一套CMS，以便后期开发应用的时候更加便捷，现在还不成熟，暂未公开。 说一件值得骄傲的事情吧，每天坚持记有道，把每天完成的事情，成功的事情，失败的事情每天做一下总结，这种感觉似乎是记录了自己路途的脚印，自己能感觉出自己走了多远，收获了多少，有一种自我激励的感觉。从14年开始记录到到今天了，希望自己能坚持下去。 哦又想到一个，之前博客上会有很多人加我，后来我想，干脆建一个交流群多好，于是乎在九月份左右，进击的Coder诞生了，三个多月的时间吧，几乎每天都有人加，刚才看了下已经788人啦，在群里跟大家探讨经验，交流技术，没事吐吐槽，扯扯淡，真的很愉快，爱你们。 然而现在还是觉得自己有时候懒癌发作之后就什么也不想干，执行力差，定了一些计划，今天拖明天，明天拖后天，最后就那么不了了之了。半年前定的学习鬼步舞呢，到现在跳的依然那么差。说好的练好腹肌呢，现在似乎没多大效果。 总结了这么多，似乎也没有多么值得骄傲的一件事，算是瞎忙了一整年吧哈哈。 新年计划： 1.写一本爬虫的书并出版，出套算不上教程的经验分享 2.完善好我的CMS，长期维护下去 3.学习数据挖掘和Web安全，向大牛进发 4.懒癌，不敢说改掉，但也能稍微缓解下吧 5.好玩表演，燥起来。 太多太多…. 觉得自己不会的还是太多，想学的也太多，好好提高自己的执行力和自制力吧，新的一年成为更好的自己。 凌晨三点了，安。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-01-27 02:49:20" itemprop="dateCreated datePublished" datetime="2017-01-27T02:49:20+08:00">2017-01-27</time>
                </span>
                <span id="/3998.html" class="post-meta-item leancloud_visitors" data-flag-title="回首我的二零一六" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <article itemscope itemtype="http://schema.org/Article" class="post-block index" lang="zh-CN">
              <link itemprop="mainEntityOfPage" href="https://cuiqingcai.com/3992.html">
              <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                <meta itemprop="image" content="/images/avatar.png">
                <meta itemprop="name" content="崔庆才">
                <meta itemprop="description" content="崔庆才的个人站点，记录生活的瞬间，分享学习的心得。">
              </span>
              <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                <meta itemprop="name" content="静觅">
              </span>
              <header class="post-header">
                <h2 class="post-title" itemprop="name headline">
                  <a class="label"> PHP <i class="label-arrow"></i>
                  </a>
                  <a href="/3992.html" class="post-title-link" itemprop="url">Mac下升级PHP版本至7.1</a>
                </h2>
              </header>
              <div class="post-body" itemprop="articleBody">
                <div class="thumb">
                  <img itemprop="contentUrl" class="random">
                </div>
                <div class="excerpt">
                  <p>
                  <p>博主在搞Web开发主要采用的是Laravel，然而发现其对PHP版本的要求是越来越高，PHP5.6已经越来受到限制，Laravel 5.5将正式弃用PHP5.6，所以博主决定直接升级到7.1版本。</p>
                  <h2 id="移除旧版本"><a href="#移除旧版本" class="headerlink" title="移除旧版本"></a>移除旧版本</h2>
                  <p>由于系统本身已经装了PHP5.6，所以需要先将其移除。 在这里列出目录以及移除需要的命令。</p>
                  <figure class="highlight groovy">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/private/</span>etc/               sudo rm -rf php-fpm.conf.<span class="keyword">default</span> php.ini php.ini.<span class="keyword">default</span></span><br><span class="line"><span class="regexp">/usr/</span>bin/               sudo rm -rf php php-config phpdoc phpize</span><br><span class="line"><span class="regexp">/usr/</span>include                sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>lib                sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>sbin               sudo rm -rf php-fpm</span><br><span class="line"><span class="regexp">/usr/</span>share              sudo rm -rf php</span><br><span class="line"><span class="regexp">/usr/</span>share<span class="regexp">/man/</span>man1         sudo rm -rf php-config<span class="number">.1</span> php<span class="number">.1</span> phpize<span class="number">.1</span></span><br><span class="line"><span class="regexp">/usr/</span>share<span class="regexp">/man/</span>man8         sudo rm -rf php-fpm<span class="number">.8</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>顺次手动删除它们即可。</p>
                  <h2 id="搞清关系"><a href="#搞清关系" class="headerlink" title="搞清关系"></a>搞清关系</h2>
                  <p>在卸载过程中你会发现有PHP、FastCGI、php-fpm、spawn-fcgi等等的概念，所以在这里先梳理一下。</p>
                  <h3 id="CGI"><a href="#CGI" class="headerlink" title="CGI"></a>CGI</h3>
                  <p>CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。 web server（比如说nginx）只是内容的分发者。比如，如果请求<code>/index.html</code>，那么web server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。好了，如果现在请求的是<code>/index.php</code>，根据配置文件，nginx知道这个不是静态文件，需要去找PHP解析器来处理，那么他会把这个请求简单处理后交给PHP解析器。Nginx会传哪些数据给PHP解析器呢？url要有吧，查询字符串也得有吧，POST数据也要有，HTTP header不能少吧，好的，CGI就是规定要传哪些数据、以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 当web server收到<code>/index.php</code>这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。</p>
                  <h3 id="FastCGI"><a href="#FastCGI" class="headerlink" title="FastCGI"></a>FastCGI</h3>
                  <p>Fastcgi是用来提高CGI程序性能的。 那么CGI程序的性能问题在哪呢？”PHP解析器会解析php.ini文件，初始化执行环境”，就是这里了。标准的CGI对每个请求都会执行这些步骤（不闲累啊！启动进程很累的说！），所以处理每个时间的时间会比较长。这明显不合理嘛！那么Fastcgi是怎么做的呢？首先，Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。</p>
                  <h3 id="PHP-FPM"><a href="#PHP-FPM" class="headerlink" title="PHP-FPM"></a>PHP-FPM</h3>
                  <p>是一个实现了Fastcgi的程序，被PHP官方收了。 大家都知道，PHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。好了PHP-FPM也是这么个东东，在长时间的发展后，逐渐得到了大家的认可（要知道，前几年大家可是抱怨PHP-FPM稳定性太差的），也越来越流行。 php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，因为前面说了fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。 有的说，php-fpm是php内核的一个补丁 以前是对的。因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用<code>\--enalbe-fpm</code>这个编译参数即可。</p>
                  <h2 id="安装PHP7-1"><a href="#安装PHP7-1" class="headerlink" title="安装PHP7.1"></a>安装PHP7.1</h2>
                  <p>用brew进行安装。</p>
                  <figure class="highlight armasm">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br><span class="line">2</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="keyword">brew </span>install homebrew/php/php71</span><br><span class="line"><span class="keyword">brew </span>install homebrew/php/php71-mcrypt</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>安装完了之后它会自带PHP-FPM，在 启动PHP-FPM</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo php-fpm</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <h3 id="配置文件目录"><a href="#配置文件目录" class="headerlink" title="配置文件目录"></a>配置文件目录</h3>
                  <p>php.ini</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="regexp">/7.1/</span>php.ini</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>php-fpm.conf</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="regexp">/7.1/</span>php-fpm.conf</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>php-fpm</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/opt/</span>php71<span class="regexp">/sbin/</span>php-fpm</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>但是执行<code>php-fpm</code>发现没有反应，所以这里需要加一个symlink</p>
                  <figure class="highlight awk">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line">ln -s <span class="regexp">/usr/</span>local<span class="regexp">/opt/</span>php71<span class="regexp">/sbin/</span>php-fpm <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span>php-fpm</span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>然后运行php-fpm</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo php-fpm</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>启动nginx</p>
                  <figure class="highlight ebnf">
                    <table>
                      <tr>
                        <td class="gutter">
                          <pre><span class="line">1</span><br></pre>
                        </td>
                        <td class="code">
                          <pre><span class="line"><span class="attribute">sudo nginx</span></span><br></pre>
                        </td>
                      </tr>
                    </table>
                  </figure>
                  <p>关于MySQL和其他的安装在这就不再赘述。 以上便完成了PHP的升级。</p>
                  </p>
                </div>
              </div>
              <div class="post-meta">
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-user"></i>
                  </span>
                  <span class="post-meta-item-text">作者</span>
                  <span><a href="/authors/崔庆才" class="author" itemprop="url" rel="index">崔庆才</a></span>
                </span>
                <span class="post-meta-item">
                  <span class="post-meta-item-icon">
                    <i class="far fa-calendar"></i>
                  </span>
                  <span class="post-meta-item-text">发表于</span>
                  <time title="创建时间：2017-01-26 22:05:48" itemprop="dateCreated datePublished" datetime="2017-01-26T22:05:48+08:00">2017-01-26</time>
                </span>
                <span id="/3992.html" class="post-meta-item leancloud_visitors" data-flag-title="Mac下升级PHP版本至7.1" title="阅读次数">
                  <span class="post-meta-item-icon">
                    <i class="fa fa-eye"></i>
                  </span>
                  <span class="post-meta-item-text">阅读次数：</span>
                  <span class="leancloud-visitors-count"></span>
                </span>
                <span class="post-meta-item" title="本文字数">
                  <span class="post-meta-item-icon">
                    <i class="far fa-file-word"></i>
                  </span>
                  <span class="post-meta-item-text">本文字数：</span>
                  <span>2.3k</span>
                </span>
                <span class="post-meta-item" title="阅读时长">
                  <span class="post-meta-item-icon">
                    <i class="far fa-clock"></i>
                  </span>
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                  <span>2 分钟</span>
                </span>
              </div>
            </article>
            <script>
              document.querySelectorAll('.random').forEach(item => item.src = "https://picsum.photos/id/" + Math.floor(Math.random() * Math.floor(300)) + "/200/133")

            </script>
            <nav class="pagination">
              <a class="extend prev" rel="prev" href="/page/16/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/18/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
            </nav>
          </div>
          <script>
            window.addEventListener('tabs:register', () =>
            {
              let
              {
                activeClass
              } = CONFIG.comments;
              if (CONFIG.comments.storage)
              {
                activeClass = localStorage.getItem('comments_active') || activeClass;
              }
              if (activeClass)
              {
                let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
                if (activeTab)
                {
                  activeTab.click();
                }
              }
            });
            if (CONFIG.comments.storage)
            {
              window.addEventListener('tabs:click', event =>
              {
                if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
                let commentClass = event.target.classList[1];
                localStorage.setItem('comments_active', commentClass);
              });
            }

          </script>
        </div>
        <div class="toggle sidebar-toggle">
          <span class="toggle-line toggle-line-first"></span>
          <span class="toggle-line toggle-line-middle"></span>
          <span class="toggle-line toggle-line-last"></span>
        </div>
        <aside class="sidebar">
          <div class="sidebar-inner">
            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc"> 文章目录 </li>
              <li class="sidebar-nav-overview"> 站点概览 </li>
            </ul>
            <!--noindex-->
            <div class="post-toc-wrap sidebar-panel">
            </div>
            <!--/noindex-->
            <div class="site-overview-wrap sidebar-panel">
              <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
                <img class="site-author-image" itemprop="image" alt="崔庆才" src="/images/avatar.png">
                <p class="site-author-name" itemprop="name">崔庆才</p>
                <div class="site-description" itemprop="description">崔庆才的个人站点，记录生活的瞬间，分享学习的心得。</div>
              </div>
              <div class="site-state-wrap motion-element">
                <nav class="site-state">
                  <div class="site-state-item site-state-posts">
                    <a href="/archives/">
                      <span class="site-state-item-count">518</span>
                      <span class="site-state-item-name">日志</span>
                    </a>
                  </div>
                  <div class="site-state-item site-state-categories">
                    <a href="/categories/">
                      <span class="site-state-item-count">21</span>
                      <span class="site-state-item-name">分类</span></a>
                  </div>
                  <div class="site-state-item site-state-tags">
                    <a href="/tags/">
                      <span class="site-state-item-count">121</span>
                      <span class="site-state-item-name">标签</span></a>
                  </div>
                </nav>
              </div>
              <div class="links-of-author motion-element">
                <span class="links-of-author-item">
                  <a href="https://github.com/Germey" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Germey" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
                </span>
                <span class="links-of-author-item">
                  <a href="mailto:cqc@cuiqingcai.com.com" title="邮件 → mailto:cqc@cuiqingcai.com.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>邮件</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://weibo.com/cuiqingcai" title="微博 → https:&#x2F;&#x2F;weibo.com&#x2F;cuiqingcai" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>微博</a>
                </span>
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/Germey" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;Germey" rel="noopener" target="_blank"><i class="fa fa-magic fa-fw"></i>知乎</a>
                </span>
              </div>
            </div>
            <div style=" width: 100%;" class="sidebar-panel sidebar-panel-image sidebar-panel-active">
              <a href="https://www.abuyun.com/http-proxy/introduce.html" target="_blank" rel="noopener">
                <img src="https://qiniu.cuiqingcai.com/88au8.jpg" style=" width: 100%;">
              </a>
            </div>
            <div style=" width: 100%;" class="sidebar-panel sidebar-panel-image sidebar-panel-active">
              <a href="https://tutorial.lengyue.video/?coupon=12ef4b1a-a3db-11ea-bb37-0242ac130002_cqx_850" target="_blank" rel="noopener">
                <img src="https://qiniu.cuiqingcai.com/bco2a.png" style=" width: 100%;">
              </a>
            </div>
            <div style=" width: 100%;" class="sidebar-panel sidebar-panel-image sidebar-panel-active">
              <a href="https://luminati-china.io/?affiliate=ref_5fbbaaa9647883f5c6f77095" target="_blank" rel="noopener">
                <img src="https://qiniu.cuiqingcai.com/ikkq9.jpg" style=" width: 100%;">
              </a>
            </div>
            <div class="sidebar-panel sidebar-panel-tags sidebar-panel-active">
              <h4 class="name"> 标签云 </h4>
              <div class="content">
                <a href="/tags/2048/" style="font-size: 10px;">2048</a> <a href="/tags/599/" style="font-size: 10px;">599</a> <a href="/tags/Bootstrap/" style="font-size: 11.25px;">Bootstrap</a> <a href="/tags/CDN/" style="font-size: 10px;">CDN</a> <a href="/tags/CQC/" style="font-size: 10px;">CQC</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/CSS-%E5%8F%8D%E7%88%AC%E8%99%AB/" style="font-size: 10px;">CSS 反爬虫</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Eclipse/" style="font-size: 11.25px;">Eclipse</a> <a href="/tags/FTP/" style="font-size: 10px;">FTP</a> <a href="/tags/GitHub/" style="font-size: 11.25px;">GitHub</a> <a href="/tags/HTML5/" style="font-size: 10px;">HTML5</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/IT/" style="font-size: 10px;">IT</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/K8s/" style="font-size: 10px;">K8s</a> <a href="/tags/LOGO/" style="font-size: 10px;">LOGO</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MIUI/" style="font-size: 10px;">MIUI</a> <a href="/tags/MongoDB/" style="font-size: 10px;">MongoDB</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/PHP/" style="font-size: 11.25px;">PHP</a> <a href="/tags/PS/" style="font-size: 10px;">PS</a> <a href="/tags/Pathlib/" style="font-size: 10px;">Pathlib</a> <a href="/tags/PhantomJS/" style="font-size: 10px;">PhantomJS</a> <a href="/tags/PySpider/" style="font-size: 10px;">PySpider</a> <a href="/tags/Python/" style="font-size: 16.25px;">Python</a> <a href="/tags/Python3/" style="font-size: 12.5px;">Python3</a> <a href="/tags/Pythonic/" style="font-size: 10px;">Pythonic</a> <a href="/tags/QQ/" style="font-size: 10px;">QQ</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/SAE/" style="font-size: 10px;">SAE</a> <a href="/tags/SSH/" style="font-size: 10px;">SSH</a> <a href="/tags/SVG/" style="font-size: 10px;">SVG</a> <a href="/tags/Scrapy/" style="font-size: 10px;">Scrapy</a> <a href="/tags/Scrapy-redis/" style="font-size: 10px;">Scrapy-redis</a> <a href="/tags/Scrapy%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 10px;">Scrapy分布式</a> <a href="/tags/Selenium/" style="font-size: 10px;">Selenium</a> <a href="/tags/TKE/" style="font-size: 10px;">TKE</a> <a href="/tags/Ubuntu/" style="font-size: 11.25px;">Ubuntu</a> <a href="/tags/Vue/" style="font-size: 11.25px;">Vue</a> <a href="/tags/Webpack/" style="font-size: 10px;">Webpack</a> <a href="/tags/Windows/" style="font-size: 10px;">Windows</a> <a href="/tags/Winpcap/" style="font-size: 10px;">Winpcap</a> <a href="/tags/WordPress/" style="font-size: 13.75px;">WordPress</a> <a href="/tags/object-Object/" style="font-size: 10px;">[object Object]</a> <a href="/tags/android/" style="font-size: 10px;">android</a> <a href="/tags/ansible/" style="font-size: 10px;">ansible</a> <a href="/tags/cocos2d-x/" style="font-size: 10px;">cocos2d-x</a> <a href="/tags/e6/" style="font-size: 10px;">e6</a> <a href="/tags/fitvids/" style="font-size: 10px;">fitvids</a> <a href="/tags/git/" style="font-size: 11.25px;">git</a> <a href="/tags/json/" style="font-size: 10px;">json</a> <a href="/tags/js%E9%80%86%E5%90%91/" style="font-size: 10px;">js逆向</a> <a href="/tags/kubernetes/" style="font-size: 10px;">kubernetes</a> <a href="/tags/log/" style="font-size: 10px;">log</a> <a href="/tags/logging/" style="font-size: 10px;">logging</a> <a href="/tags/matlab/" style="font-size: 11.25px;">matlab</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/pywin32/" style="font-size: 10px;">pywin32</a> <a href="/tags/style/" style="font-size: 10px;">style</a> <a href="/tags/tomcat/" style="font-size: 10px;">tomcat</a> <a href="/tags/ubuntu/" style="font-size: 10px;">ubuntu</a> <a href="/tags/uwsgi/" style="font-size: 10px;">uwsgi</a> <a href="/tags/validate-cert/" style="font-size: 10px;">validate_cert</a> <a href="/tags/vsftpd/" style="font-size: 10px;">vsftpd</a> <a href="/tags/wamp/" style="font-size: 10px;">wamp</a> <a href="/tags/wineQQ/" style="font-size: 10px;">wineQQ</a> <a href="/tags/%E4%B8%83%E7%89%9B/" style="font-size: 11.25px;">七牛</a> <a href="/tags/%E4%B8%8A%E6%B5%B7/" style="font-size: 10px;">上海</a> <a href="/tags/%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/" style="font-size: 10px;">个人网站</a> <a href="/tags/%E4%B8%BB%E9%A2%98/" style="font-size: 10px;">主题</a> <a href="/tags/%E4%BA%91%E5%AD%98%E5%82%A8/" style="font-size: 10px;">云存储</a> <a href="/tags/%E4%BA%AC%E4%B8%9C%E4%BA%91/" style="font-size: 10px;">京东云</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 10px;">人工智能</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 10px;">代理</a> <a href="/tags/%E4%BB%A3%E7%A0%81/" style="font-size: 10px;">代码</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 10px;">优化</a> <a href="/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/" style="font-size: 10px;">位运算</a> <a href="/tags/%E5%88%86%E4%BA%AB/" style="font-size: 10px;">分享</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 10px;">分布式</a> <a href="/tags/%E5%88%9B%E4%B8%9A/" style="font-size: 10px;">创业</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 11.25px;">前端</a> <a href="/tags/%E5%8E%9F%E7%94%9FAPP/" style="font-size: 10px;">原生APP</a> <a href="/tags/%E5%8F%8D%E7%88%AC%E8%99%AB/" style="font-size: 12.5px;">反爬虫</a> <a href="/tags/%E5%91%BD%E4%BB%A4/" style="font-size: 10px;">命令</a> <a href="/tags/%E5%93%8D%E5%BA%94%E5%BC%8F%E5%B8%83%E5%B1%80/" style="font-size: 10px;">响应式布局</a> <a href="/tags/%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A/" style="font-size: 10px;">域名绑定</a> <a href="/tags/%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84/" style="font-size: 10px;">大众点评</a> <a href="/tags/%E5%AD%97%E4%BD%93%E5%8F%8D%E7%88%AC%E8%99%AB/" style="font-size: 10px;">字体反爬虫</a> <a href="/tags/%E5%AE%9E%E7%94%A8/" style="font-size: 10px;">实用</a> <a href="/tags/%E5%B4%94%E5%BA%86%E6%89%8D/" style="font-size: 18.75px;">崔庆才</a> <a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 10px;">工具</a> <a href="/tags/%E6%89%8B%E6%9C%BA%E8%AE%BF%E9%97%AE/" style="font-size: 10px;">手机访问</a> <a href="/tags/%E6%95%99%E7%A8%8B/" style="font-size: 10px;">教程</a> <a href="/tags/%E6%97%85%E6%B8%B8/" style="font-size: 10px;">旅游</a> <a href="/tags/%E6%97%A5%E5%BF%97/" style="font-size: 10px;">日志</a> <a href="/tags/%E6%9D%9C%E5%85%B0%E7%89%B9/" style="font-size: 10px;">杜兰特</a> <a href="/tags/%E6%A1%8C%E9%9D%A2/" style="font-size: 10px;">桌面</a> <a href="/tags/%E6%B1%9F%E5%8D%97/" style="font-size: 10px;">江南</a> <a href="/tags/%E6%B8%B8%E6%88%8F/" style="font-size: 10px;">游戏</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/" style="font-size: 10px;">环境变量</a> <a href="/tags/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">生活笔记</a> <a href="/tags/%E7%99%BB%E5%BD%95/" style="font-size: 10px;">登录</a> <a href="/tags/%E7%9F%A5%E4%B9%8E/" style="font-size: 10px;">知乎</a> <a href="/tags/%E7%9F%AD%E4%BF%A1/" style="font-size: 10px;">短信</a> <a href="/tags/%E7%BA%B8%E5%BC%A0/" style="font-size: 10px;">纸张</a> <a href="/tags/%E7%BD%91%E7%AB%99/" style="font-size: 10px;">网站</a> <a href="/tags/%E8%82%89%E5%A4%B9%E9%A6%8D/" style="font-size: 10px;">肉夹馍</a> <a href="/tags/%E8%A5%BF%E5%B0%91%E7%88%B7/" style="font-size: 10px;">西少爷</a> <a href="/tags/%E8%A7%86%E9%A2%91/" style="font-size: 10px;">视频</a> <a href="/tags/%E8%BF%9C%E7%A8%8B/" style="font-size: 10px;">远程</a> <a href="/tags/%E9%80%86%E5%90%91/" style="font-size: 10px;">逆向</a> <a href="/tags/%E9%85%8D%E7%BD%AE/" style="font-size: 10px;">配置</a> <a href="/tags/%E9%87%8D%E8%A3%85/" style="font-size: 10px;">重装</a> <a href="/tags/%E9%9D%99%E8%A7%85/" style="font-size: 17.5px;">静觅</a> <a href="/tags/%E9%A2%A0%E8%A6%86/" style="font-size: 10px;">颠覆</a> <a href="/tags/%E9%A3%9E%E4%BF%A1/" style="font-size: 10px;">飞信</a>
              </div>
              <script>
                const tagsColors = ['#00a67c', '#5cb85c', '#d9534f', '#567e95', '#b37333', '#f4843d', '#15a287']
                const tagsElements = document.querySelectorAll('.sidebar-panel-tags .content a')
                tagsElements.forEach((item) =>
                {
                  item.style.backgroundColor = tagsColors[Math.floor(Math.random() * tagsColors.length)]
                })

              </script>
            </div>
            <div class="sidebar-panel sidebar-panel-categories sidebar-panel-active">
              <h4 class="name"> 分类 </h4>
              <div class="content">
                <ul class="category-list">
                  <li class="category-list-item"><a class="category-list-link" href="/categories/C-C/">C/C++</a><span class="category-list-count">23</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a><span class="category-list-count">13</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">5</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">26</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">15</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Net/">Net</a><span class="category-list-count">4</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Other/">Other</a><span class="category-list-count">38</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a><span class="category-list-count">27</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">256</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/TypeScript/">TypeScript</a><span class="category-list-count">2</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E5%B1%95%E7%A4%BA/">个人展示</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E6%97%A5%E8%AE%B0/">个人日记</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E9%9A%8F%E7%AC%94/">个人随笔</a><span class="category-list-count">10</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/">技术杂谈</a><span class="category-list-count">74</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/">未分类</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/">生活笔记</a><span class="category-list-count">1</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A6%8F%E5%88%A9%E4%B8%93%E5%8C%BA/">福利专区</a><span class="category-list-count">6</span></li>
                  <li class="category-list-item"><a class="category-list-link" href="/categories/%E8%81%8C%E4%BD%8D%E6%8E%A8%E8%8D%90/">职位推荐</a><span class="category-list-count">2</span></li>
                </ul>
              </div>
            </div>
            <div class="sidebar-panel sidebar-panel-friends sidebar-panel-active">
              <h4 class="name"> 友情链接 </h4>
              <ul class="friends">
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/j2dub.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.findhao.net/" target="_blank" rel="noopener">FindHao</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/ou6mm.jpg">
                  </span>
                  <span class="link">
                    <a href="https://diygod.me/" target="_blank" rel="noopener">DIYgod</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/6apxu.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.51dev.com/" target="_blank" rel="noopener">IT技术社区</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.jankl.com/img/titleshu.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.jankl.com/" target="_blank" rel="noopener">liberalist</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/bqlbs.png">
                  </span>
                  <span class="link">
                    <a href="http://www.urselect.com/" target="_blank" rel="noopener">优社电商</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/8s88c.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yuanrenxue.com/" target="_blank" rel="noopener">猿人学</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/4i7yf.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.lizenghai.com/" target="_blank" rel="noopener">Python量化投资</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/2wgg5.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.yunlifang.cn/" target="_blank" rel="noopener">云立方</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/shwr6.png">
                  </span>
                  <span class="link">
                    <a href="http://lanbing510.info/" target="_blank" rel="noopener">冰蓝</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/blvoh.jpg">
                  </span>
                  <span class="link">
                    <a href="https://lengyue.me/" target="_blank" rel="noopener">冷月</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="http://qianxunclub.com/favicon.png">
                  </span>
                  <span class="link">
                    <a href="http://qianxunclub.com/" target="_blank" rel="noopener">千寻啊千寻</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/0044u.jpg">
                  </span>
                  <span class="link">
                    <a href="http://kodcloud.com/" target="_blank" rel="noopener">可道云</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/ygnpn.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.kunkundashen.cn/" target="_blank" rel="noopener">坤坤大神</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/22uv1.png">
                  </span>
                  <span class="link">
                    <a href="http://www.cenchong.com/" target="_blank" rel="noopener">岑冲博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/ev9kl.png">
                  </span>
                  <span class="link">
                    <a href="http://www.zxiaoji.com/" target="_blank" rel="noopener">张小鸡</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.chrafz.com/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://www.chrafz.com/" target="_blank" rel="noopener">张弦先生</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.503error.com/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://www.503error.com/" target="_blank" rel="noopener">张志明个人博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://seofangfa.com/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://seofangfa.com/" target="_blank" rel="noopener">方法SEO</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/x714o.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.hubwiz.com/" target="_blank" rel="noopener">汇智网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/lfmj3.png">
                  </span>
                  <span class="link">
                    <a href="http://frankchen.xyz/" target="_blank" rel="noopener">不正经数据科学家</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/129d8.png">
                  </span>
                  <span class="link">
                    <a href="https://www.bysocket.com/" target="_blank" rel="noopener">泥瓦匠BYSocket</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://www.xiongge.club/favicon.ico">
                  </span>
                  <span class="link">
                    <a href="https://www.xiongge.club/" target="_blank" rel="noopener">熊哥club</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/3w4fe.png">
                  </span>
                  <span class="link">
                    <a href="https://zerlong.com/" target="_blank" rel="noopener">知语</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/262r1.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.ysir308.com/" target="_blank" rel="noopener">程序员虾说</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/44hxf.png">
                  </span>
                  <span class="link">
                    <a href="http://redstonewill.com/" target="_blank" rel="noopener">红色石头</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/8g1fk.jpg">
                  </span>
                  <span class="link">
                    <a href="http://www.laodong.me/" target="_blank" rel="noopener">老董博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/wkaus.jpg">
                  </span>
                  <span class="link">
                    <a href="https://zhaoshuai.me/" target="_blank" rel="noopener">碎念</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/pgo0r.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.chenwenguan.com/" target="_blank" rel="noopener">陈文管的博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/kk82a.jpg">
                  </span>
                  <span class="link">
                    <a href="https://www.lxlinux.net/" target="_blank" rel="noopener">良许Linux教程网</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/lj0t2.jpg">
                  </span>
                  <span class="link">
                    <a href="https://tanqingbo.cn/" target="_blank" rel="noopener">IT码农</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/i8cdr.png">
                  </span>
                  <span class="link">
                    <a href="https://junyiseo.com/" target="_blank" rel="noopener">均益个人博客</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/chwv2.png">
                  </span>
                  <span class="link">
                    <a href="https://brucedone.com/" target="_blank" rel="noopener">大鱼的鱼塘</a>
                  </span>
                </li>
                <li class="friend">
                  <span class="logo">
                    <img src="https://qiniu.cuiqingcai.com/2y43o.png">
                  </span>
                  <span class="link">
                    <a href="http://bbs.nightteam.cn/" target="_blank" rel="noopener">夜幕爬虫安全论坛</a>
                  </span>
                </li>
              </ul>
            </div>
          </div>
        </aside>
        <div id="sidebar-dimmer"></div>
      </div>
    </main>
    <footer class="footer">
      <div class="footer-inner">
        <div class="copyright"> &copy; <span itemprop="copyrightYear">2021</span>
          <span class="with-love">
            <i class="fa fa-heart"></i>
          </span>
          <span class="author" itemprop="copyrightHolder">崔庆才丨静觅</span>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-chart-area"></i>
          </span>
          <span title="站点总字数">2.5m</span>
          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-coffee"></i>
          </span>
          <span title="站点阅读时长">37:31</span>
        </div>
        <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动 </div>
        <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备18015597号-1 </a>
        </div>
        <script>
          (function ()
          {
            function leancloudSelector(url)
            {
              url = encodeURI(url);
              return document.getElementById(url).querySelector('.leancloud-visitors-count');
            }

            function addCount(Counter)
            {
              var visitors = document.querySelector('.leancloud_visitors');
              var url = decodeURI(visitors.id);
              var title = visitors.dataset.flagTitle;
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                if (results.length > 0)
                {
                  var counter = results[0];
                  leancloudSelector(url).innerText = counter.time + 1;
                  Counter('put', '/classes/Counter/' + counter.objectId,
                  {
                    time:
                    {
                      '__op': 'Increment',
                      'amount': 1
                    }
                  }).catch(error =>
                  {
                    console.error('Failed to save visitor count', error);
                  });
                }
                else
                {
                  Counter('post', '/classes/Counter',
                  {
                    title,
                    url,
                    time: 1
                  }).then(response => response.json()).then(() =>
                  {
                    leancloudSelector(url).innerText = 1;
                  }).catch(error =>
                  {
                    console.error('Failed to create', error);
                  });
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }

            function showTime(Counter)
            {
              var visitors = document.querySelectorAll('.leancloud_visitors');
              var entries = [...visitors].map(element =>
              {
                return decodeURI(element.id);
              });
              Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify(
              {
                url:
                {
                  '$in': entries
                }
              }))).then(response => response.json()).then((
              {
                results
              }) =>
              {
                for (let url of entries)
                {
                  let target = results.find(item => item.url === url);
                  leancloudSelector(url).innerText = target ? target.time : 0;
                }
              }).catch(error =>
              {
                console.error('LeanCloud Counter Error', error);
              });
            }
            let
            {
              app_id,
              app_key,
              server_url
            } = {
              "enable": true,
              "app_id": "6X5dRQ0pnPWJgYy8SXOg0uID-gzGzoHsz",
              "app_key": "ziLDVEy73ne5HtFTiGstzHMS",
              "server_url": null,
              "security": false
            };

            function fetchData(api_server)
            {
              var Counter = (method, url, data) =>
              {
                return fetch(`${api_server}/1.1${url}`,
                {
                  method,
                  headers:
                  {
                    'X-LC-Id': app_id,
                    'X-LC-Key': app_key,
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify(data)
                });
              };
              if (CONFIG.page.isPost)
              {
                if (CONFIG.hostname !== location.hostname) return;
                addCount(Counter);
              }
              else if (document.querySelectorAll('.post-title-link').length >= 1)
              {
                showTime(Counter);
              }
            }
            let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;
            if (api_server)
            {
              fetchData(api_server);
            }
            else
            {
              fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id).then(response => response.json()).then((
              {
                api_server
              }) =>
              {
                fetchData('https://' + api_server);
              });
            }
          })();

        </script>
      </div>
      <div class="footer-stat">
        <span id="cnzz_stat_icon_1279355174"></span>
        <script type="text/javascript">
          document.write(unescape("%3Cspan id='cnzz_stat_icon_1279355174'%3E%3C/span%3E%3Cscript src='https://v1.cnzz.com/z_stat.php%3Fid%3D1279355174%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));

        </script>
      </div>
    </footer>
  </div>
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/js/utils.js"></script>
  <script src="/.js"></script>
  <script src="/js/schemes/pisces.js"></script>
  <script src="/.js"></script>
  <script src="/js/next-boot.js"></script>
  <script src="/.js"></script>
  <script>
    (function ()
    {
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x = document.getElementsByTagName("link");
      //Find the last canonical URL
      if (x.length > 0)
      {
        for (i = 0; i < x.length; i++)
        {
          if (x[i].rel.toLowerCase() == 'canonical' && x[i].href)
          {
            canonicalURL = x[i].href;
          }
        }
      }
      //Get protocol
      if (!canonicalURL)
      {
        curProtocol = window.location.protocol.split(':')[0];
      }
      else
      {
        curProtocol = canonicalURL.split(':')[0];
      }
      //Get current URL if the canonical URL does not exist
      if (!canonicalURL) canonicalURL = window.location.href;
      //Assign script content. Replace current URL with the canonical URL
      ! function ()
      {
        var e = /([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,
          r = canonicalURL,
          t = document.referrer;
        if (!e.test(r))
        {
          var n = (String(curProtocol).toLowerCase() === 'https') ? "https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif" : "//api.share.baidu.com/s.gif";
          t ? (n += "?r=" + encodeURIComponent(document.referrer), r && (n += "&l=" + r)) : r && (n += "?l=" + r);
          var i = new Image;
          i.src = n
        }
      }(window);
    })();

  </script>
  <script src="/js/local-search.js"></script>
  <script src="/.js"></script>
</body>

</html>
